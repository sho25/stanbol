begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/* * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements.  See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the "License"); you may not use this file except in compliance with * the License.  You may obtain a copy of the License at * *     http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|lucenefstlinking
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|entitylinking
operator|.
name|config
operator|.
name|TextProcessingConfig
operator|.
name|UNICASE_SCRIPT_LANUAGES
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|EnumSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|TokenFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|TokenStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|CharTermAttribute
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|OffsetAttribute
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|entitylinking
operator|.
name|config
operator|.
name|LanguageProcessingConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|entitylinking
operator|.
name|config
operator|.
name|TextProcessingConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|entitylinking
operator|.
name|engine
operator|.
name|EntityLinkingEngine
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|entitylinking
operator|.
name|impl
operator|.
name|ProcessingState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|entitylinking
operator|.
name|impl
operator|.
name|SectionData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|entitylinking
operator|.
name|impl
operator|.
name|TokenData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|AnalysedText
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|Section
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|Sentence
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|Span
operator|.
name|SpanTypeEnum
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|Token
import|;
end_import

begin_import
import|import
name|org
operator|.
name|opensextant
operator|.
name|solrtexttagger
operator|.
name|TaggingAttribute
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/**  * Classifies Tokens in the Solr {@link TokenStream} with the {@link TaggingAttribute}  * based on NLP processing results present in the {@link AnalysedText}. This  * implementation Classifies Token similar to the {@link EntityLinkingEngine}.  * It uses the {@link TextProcessingConfig} for its configuration.<p>  *<b> Implementation Details</b><p>  * While this code does not directly use {@link ProcessingState} it serves a  * similar purpose.<p>  *<ul>  *<li>This code needs to deal with potential different tokenization present  * in the {@link AnalysedText} and the {@link TokenStream}. The implemented   * semantics does mark Tokens in the {@link TokenStream} as   *<code>{@link TaggingAttribute#isTaggable()} == ture</code> if the do overlap   * with a {@link TokenData#isLinkable} token in the {@link AnalysedText}.  *<li> {@link TokenData#isMatchable} tokens are also considered as  *<code>{@link TaggingAttribute#isTaggable()} == ture</code> if a   * {@link TokenData#isMatchable} token is following within two tokens of the  * {@link AnalysedText}. This Range is extended if other matchable tokens are  * within the lookahead range. However the range is never extended over a  * section border.  *</ul>  * @author Rupert Westenthaler  *  */
end_comment

begin_class
specifier|public
class|class
name|LinkableTokenFilterStream
extends|extends
name|TokenFilter
block|{
specifier|private
specifier|final
name|Logger
name|log
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|LinkableTokenFilterStream
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/**      * Required to use {@link SectionData}      */
specifier|private
specifier|static
specifier|final
name|Set
argument_list|<
name|SpanTypeEnum
argument_list|>
name|PROCESSED_SPAN_TYPES
init|=
name|EnumSet
operator|.
name|of
argument_list|(
name|SpanTypeEnum
operator|.
name|Chunk
argument_list|,
name|SpanTypeEnum
operator|.
name|Token
argument_list|)
decl_stmt|;
comment|/**      * The NLP processing results      */
specifier|private
name|AnalysedText
name|at
decl_stmt|;
comment|/**      * The language of the text      */
comment|//private String lang;
comment|/**      * If the language is unicase or not      */
specifier|private
name|boolean
name|isUnicaseLanguage
decl_stmt|;
comment|/**      * Defines how NLP processing results are processed to determine Words that      * need to be looked-up in the vocabulary      */
specifier|private
name|LanguageProcessingConfig
name|lpc
decl_stmt|;
comment|/**      * Iterator over all sections of the {@link AnalysedText}      */
specifier|private
name|Iterator
argument_list|<
name|?
extends|extends
name|Section
argument_list|>
name|sections
decl_stmt|;
comment|/**      * The current section      */
specifier|private
name|SectionData
name|sectionData
decl_stmt|;
comment|/**      * Iterator over all {@link Token}s in the current section      */
specifier|private
name|Iterator
argument_list|<
name|TokenData
argument_list|>
name|tokenIt
decl_stmt|;
comment|/**      * The current Token      */
specifier|private
name|TokenData
name|token
decl_stmt|;
specifier|private
name|int
name|lookupCount
init|=
literal|0
decl_stmt|;
specifier|private
name|int
name|incrementCount
init|=
literal|0
decl_stmt|;
specifier|private
specifier|final
name|CharTermAttribute
name|termAtt
init|=
name|addAttribute
argument_list|(
name|CharTermAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|OffsetAttribute
name|offset
init|=
name|addAttribute
argument_list|(
name|OffsetAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|TaggingAttribute
name|taggable
init|=
name|addAttribute
argument_list|(
name|TaggingAttribute
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|protected
name|LinkableTokenFilterStream
parameter_list|(
name|TokenStream
name|input
parameter_list|,
name|AnalysedText
name|at
parameter_list|,
name|String
name|lang
parameter_list|,
name|LanguageProcessingConfig
name|lpc
parameter_list|)
block|{
name|super
argument_list|(
name|input
argument_list|)
expr_stmt|;
name|this
operator|.
name|at
operator|=
name|at
expr_stmt|;
comment|//this.lang = lang;
name|this
operator|.
name|lpc
operator|=
name|lpc
expr_stmt|;
name|this
operator|.
name|isUnicaseLanguage
operator|=
name|lang
operator|!=
literal|null
operator|&&
operator|!
name|lang
operator|.
name|isEmpty
argument_list|()
operator|&&
name|UNICASE_SCRIPT_LANUAGES
operator|.
name|contains
argument_list|(
name|lang
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|reset
parameter_list|()
throws|throws
name|IOException
block|{
name|super
operator|.
name|reset
argument_list|()
expr_stmt|;
name|Iterator
argument_list|<
name|Sentence
argument_list|>
name|sentences
init|=
name|at
operator|.
name|getSentences
argument_list|()
decl_stmt|;
name|this
operator|.
name|sections
operator|=
name|sentences
operator|.
name|hasNext
argument_list|()
condition|?
name|sentences
else|:
name|Collections
operator|.
name|singleton
argument_list|(
name|at
argument_list|)
operator|.
name|iterator
argument_list|()
expr_stmt|;
name|sectionData
operator|=
literal|null
expr_stmt|;
name|tokenIt
operator|=
literal|null
expr_stmt|;
name|incrementCount
operator|=
literal|0
expr_stmt|;
name|lookupCount
operator|=
literal|0
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|incrementToken
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|input
operator|.
name|incrementToken
argument_list|()
condition|)
block|{
name|incrementCount
operator|++
expr_stmt|;
name|boolean
name|first
init|=
literal|true
decl_stmt|;
name|TokenData
name|token
decl_stmt|;
name|boolean
name|lookup
init|=
literal|false
decl_stmt|;
name|int
name|lastMatchable
init|=
operator|-
literal|1
decl_stmt|;
name|int
name|lastIndex
init|=
operator|-
literal|1
decl_stmt|;
while|while
condition|(
operator|(
name|token
operator|=
name|nextToken
argument_list|(
name|first
argument_list|)
operator|)
operator|!=
literal|null
condition|)
block|{
name|first
operator|=
literal|false
expr_stmt|;
if|if
condition|(
name|token
operator|.
name|isLinkable
condition|)
block|{
name|lookup
operator|=
literal|true
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|token
operator|.
name|isMatchable
condition|)
block|{
name|lastMatchable
operator|=
name|token
operator|.
name|index
expr_stmt|;
name|lastIndex
operator|=
name|lastMatchable
expr_stmt|;
block|}
comment|//else if(token.hasAlphaNumeric){
comment|//    lastIndex = token.index;
comment|//}
block|}
comment|//lookahead
if|if
condition|(
operator|!
name|lookup
operator|&&
name|lastIndex
operator|>=
literal|0
operator|&&
name|sectionData
operator|!=
literal|null
condition|)
block|{
name|List
argument_list|<
name|TokenData
argument_list|>
name|tokens
init|=
name|sectionData
operator|.
name|getTokens
argument_list|()
decl_stmt|;
name|int
name|maxLookahead
init|=
name|Math
operator|.
name|max
argument_list|(
name|lastIndex
argument_list|,
name|lastMatchable
operator|+
literal|3
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|lastIndex
operator|+
literal|1
init|;
operator|!
name|lookup
operator|&&
name|i
operator|<
name|maxLookahead
operator|&&
name|i
operator|<
name|tokens
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|token
operator|=
name|tokens
operator|.
name|get
argument_list|(
name|i
argument_list|)
expr_stmt|;
if|if
condition|(
name|token
operator|.
name|isLinkable
condition|)
block|{
name|lookup
operator|=
literal|true
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|token
operator|.
name|isMatchable
operator|&&
operator|(
name|i
operator|+
literal|1
operator|)
operator|==
name|maxLookahead
condition|)
block|{
name|maxLookahead
operator|++
expr_stmt|;
comment|//increase lookahead for matchable tokens
block|}
block|}
block|}
name|this
operator|.
name|taggable
operator|.
name|setTaggable
argument_list|(
name|lookup
argument_list|)
expr_stmt|;
if|if
condition|(
name|lookup
condition|)
block|{
if|if
condition|(
name|log
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|log
operator|.
name|trace
argument_list|(
literal|"Solr Token: [{},{}]: {}"
argument_list|,
operator|new
name|Object
index|[]
block|{
name|offset
operator|.
name|startOffset
argument_list|()
block|,
name|offset
operator|.
name|endOffset
argument_list|()
block|,
name|termAtt
block|}
argument_list|)
expr_stmt|;
block|}
name|lookupCount
operator|++
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
else|else
block|{
name|log
operator|.
name|debug
argument_list|(
literal|"lookup percentage: {}"
argument_list|,
name|lookupCount
operator|*
literal|100
operator|/
operator|(
name|float
operator|)
name|incrementCount
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
comment|/**      * Iterating over TokensData requires to iterate over two hierarchy levels:      * (1) sections (likely Sentences) and (2) Tokens<p>      *<b>NOTE</b> that this method modifies a lot of fields to update the      * state of the iteration accordingly. If the {@link #token} field is      *<code>null</code> after a call to this method this indicates that the      * end of the {@link Token} in the {@link AnalysedText} was reached.      * @param first is this the first call for the current {@link #offset} state?      * @return the token or<code>null</code> if there are no more tokens for      * the current {@link #offset}      */
specifier|private
name|TokenData
name|nextToken
parameter_list|(
name|boolean
name|first
parameter_list|)
block|{
specifier|final
name|boolean
name|isToken
decl_stmt|;
if|if
condition|(
name|token
operator|==
literal|null
operator|||
comment|//on the first call
operator|!
name|first
operator|||
comment|//not the first call within on #incrementToken()
comment|//current Token is before the current offset
name|token
operator|.
name|token
operator|.
name|getEnd
argument_list|()
operator|<=
name|offset
operator|.
name|startOffset
argument_list|()
condition|)
block|{
if|if
condition|(
name|incrementTokenData
argument_list|()
condition|)
block|{
comment|//get the next token
comment|//the next token still overlaps with the current offset
name|isToken
operator|=
name|token
operator|.
name|token
operator|.
name|getStart
argument_list|()
operator|<
name|offset
operator|.
name|endOffset
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|//end of stream
name|isToken
operator|=
literal|false
expr_stmt|;
block|}
block|}
else|else
block|{
comment|//check the current #token
name|isToken
operator|=
name|token
operator|.
name|token
operator|.
name|getStart
argument_list|()
operator|<
name|offset
operator|.
name|endOffset
argument_list|()
expr_stmt|;
block|}
return|return
name|isToken
condition|?
name|token
else|:
literal|null
return|;
block|}
comment|/**      * Increments the {@link #token} and - if necessary also the {@link #sectionData      * section}.      * @return<code>true</code> unless there are no more tokens      */
specifier|private
name|boolean
name|incrementTokenData
parameter_list|()
block|{
if|if
condition|(
name|tokenIt
operator|==
literal|null
operator|||
operator|!
name|tokenIt
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|sectionData
operator|=
literal|null
expr_stmt|;
name|tokenIt
operator|=
literal|null
expr_stmt|;
while|while
condition|(
name|sections
operator|.
name|hasNext
argument_list|()
operator|&&
operator|(
name|tokenIt
operator|==
literal|null
operator|||
operator|!
name|tokenIt
operator|.
name|hasNext
argument_list|()
operator|)
condition|)
block|{
comment|//analyse NLP results for the next Section
name|sectionData
operator|=
operator|new
name|SectionData
argument_list|(
name|lpc
argument_list|,
name|sections
operator|.
name|next
argument_list|()
argument_list|,
name|PROCESSED_SPAN_TYPES
argument_list|,
name|isUnicaseLanguage
argument_list|)
expr_stmt|;
name|tokenIt
operator|=
name|sectionData
operator|.
name|getTokens
argument_list|()
operator|.
name|iterator
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|tokenIt
operator|!=
literal|null
operator|&&
name|tokenIt
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|token
operator|=
name|tokenIt
operator|.
name|next
argument_list|()
expr_stmt|;
comment|//first token of the next section
return|return
literal|true
return|;
block|}
else|else
block|{
comment|//reached the end .. clean up
name|sectionData
operator|=
literal|null
expr_stmt|;
name|tokenIt
operator|=
literal|null
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
else|else
block|{
comment|//more token in the same section
name|token
operator|=
name|tokenIt
operator|.
name|next
argument_list|()
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
block|}
end_class

end_unit

