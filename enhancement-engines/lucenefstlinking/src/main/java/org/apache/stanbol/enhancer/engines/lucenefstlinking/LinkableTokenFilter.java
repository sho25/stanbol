begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/* * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements.  See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the "License"); you may not use this file except in compliance with * the License.  You may obtain a copy of the License at * *     http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|lucenefstlinking
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|entitylinking
operator|.
name|config
operator|.
name|TextProcessingConfig
operator|.
name|UNICASE_SCRIPT_LANUAGES
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|security
operator|.
name|AccessController
import|;
end_import

begin_import
import|import
name|java
operator|.
name|security
operator|.
name|PrivilegedAction
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|EnumSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|TokenFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|TokenStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|CharTermAttribute
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|OffsetAttribute
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|PositionIncrementAttribute
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|entitylinking
operator|.
name|config
operator|.
name|LanguageProcessingConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|entitylinking
operator|.
name|config
operator|.
name|TextProcessingConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|entitylinking
operator|.
name|engine
operator|.
name|EntityLinkingEngine
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|entitylinking
operator|.
name|impl
operator|.
name|ChunkData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|entitylinking
operator|.
name|impl
operator|.
name|ProcessingState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|entitylinking
operator|.
name|impl
operator|.
name|SectionData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|entitylinking
operator|.
name|impl
operator|.
name|TokenData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|AnalysedText
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|Chunk
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|Section
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|Sentence
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|SpanTypeEnum
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|Token
import|;
end_import

begin_import
import|import
name|org
operator|.
name|opensextant
operator|.
name|solrtexttagger
operator|.
name|TagClusterReducer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|opensextant
operator|.
name|solrtexttagger
operator|.
name|TagLL
import|;
end_import

begin_import
import|import
name|org
operator|.
name|opensextant
operator|.
name|solrtexttagger
operator|.
name|TaggingAttribute
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/**  * Class the ensures that only {@link TokenData#isLinkable linkable} Tokens  * are processed.<p>  * This is ensured on two places:<ol>  *<li> Classifies Tokens in the Solr {@link TokenStream} with the {@link TaggingAttribute}  * based on NLP processing results present in the {@link AnalysedText}. This  * implementation Classifies Token similar to the {@link EntityLinkingEngine}.  * It uses the {@link TextProcessingConfig} for its configuration.<p>  *<li> Implements {@link TagClusterReducer} to ensure that all {@link TagLL tags}  * that do not overlap with any {@link TokenData#isLinkable linkable} are  * removed from the Cluster.  *</ol>  *<b> Implementation Details</b><p>  * The {@link TokenStream} implementation of this class serves a similar  * purpose as the {@link ProcessingState} used by the EntityLinkingEngine.  * The main differences are:<p>  *<ul>  *<li>This code needs to deal with potential different tokenization present  * in the {@link AnalysedText} and the {@link TokenStream}. The implemented   * semantics does mark Tokens in the {@link TokenStream} as   *<code>{@link TaggingAttribute#isTaggable()} == ture</code> if the do overlap   * with a {@link TokenData#isLinkable} token in the {@link AnalysedText}.  *<li> {@link TokenData#isMatchable} tokens are also considered as  *<code>{@link TaggingAttribute#isTaggable()} == ture</code> if a   * {@link TokenData#isMatchable} token is following within two tokens of the  * {@link AnalysedText}. This Range is extended if other matchable tokens are  * within the lookahead range. However the range is never extended over a  * section border.  *</ul>  * The {@link TagClusterReducer} implementation keeps track of linkable tokens  * while iterating over the {@link TokenStream} and adds them to the end of a  * List. When {@link TagClusterReducer#reduce(TagLL[])} is called tags of the  * cluster are checked if they do overlap with any linkable Token at the start  * of the list. Tokens with earlier ends as the start of the tags are removed  * from the list.   * @author Rupert Westenthaler  *  */
end_comment

begin_class
specifier|public
specifier|final
class|class
name|LinkableTokenFilter
extends|extends
name|TokenFilter
implements|implements
name|TagClusterReducer
block|{
specifier|private
specifier|final
name|Logger
name|log
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|LinkableTokenFilter
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/**      * Required to use {@link SectionData}      */
specifier|private
specifier|static
specifier|final
name|Set
argument_list|<
name|SpanTypeEnum
argument_list|>
name|PROCESSED_SPAN_TYPES
init|=
name|EnumSet
operator|.
name|of
argument_list|(
name|SpanTypeEnum
operator|.
name|Chunk
argument_list|,
name|SpanTypeEnum
operator|.
name|Token
argument_list|)
decl_stmt|;
comment|/**      * The NLP processing results      */
specifier|private
name|AnalysedText
name|at
decl_stmt|;
comment|/**      * The language of the text      */
comment|//private String lang;
comment|/**      * If the language is unicase or not      */
specifier|private
name|boolean
name|isUnicaseLanguage
decl_stmt|;
comment|/**      * Defines how NLP processing results are processed to determine Words that      * need to be looked-up in the vocabulary      */
specifier|private
name|LanguageProcessingConfig
name|lpc
decl_stmt|;
comment|/**      * Iterator over all sections of the {@link AnalysedText}      */
specifier|private
name|Iterator
argument_list|<
name|?
extends|extends
name|Section
argument_list|>
name|sections
decl_stmt|;
comment|/**      * The current section      */
specifier|private
name|SectionData
name|sectionData
decl_stmt|;
comment|/**      * Iterator over all {@link Token}s in the current section      */
specifier|private
name|Iterator
argument_list|<
name|TokenData
argument_list|>
name|tokenIt
decl_stmt|;
comment|/**      * The current Token(s). {@link #incrementToken()} will add tokens to the      * end of the list and {@link #nextToken(boolean)} with<code>true</code>      * will remove earlier tokens as {@link #offset} from the list.<p>      * We need to hold multiple tokens because the TokenStream might parse      * multiple tokens with       *<code>{@link PositionIncrementAttribute#getClass() posInc} == 0</code>      * covering multiple {@link TokenData tokens}.      */
specifier|private
name|List
argument_list|<
name|TokenData
argument_list|>
name|tokens
init|=
operator|new
name|LinkedList
argument_list|<
name|TokenData
argument_list|>
argument_list|()
decl_stmt|;
comment|/**      * The cursor within the {@link #tokens} list of the currently active Token      */
specifier|private
name|int
name|tokensCursor
init|=
operator|-
literal|1
decl_stmt|;
comment|//the cursor within the tokens list
specifier|private
name|int
name|lookupCount
init|=
literal|0
decl_stmt|;
specifier|private
name|int
name|incrementCount
init|=
literal|0
decl_stmt|;
specifier|protected
specifier|final
name|CharTermAttribute
name|termAtt
decl_stmt|;
specifier|protected
specifier|final
name|OffsetAttribute
name|offset
decl_stmt|;
specifier|protected
specifier|final
name|TaggingAttribute
name|taggable
decl_stmt|;
comment|/**      * List with {@link TokenData#isLinkable linkable} {@link Token}s used by      * the {@link #reduce(TagLL[])} method to check if {@link TagLL tags}       * do overlap with any linkable token.      */
specifier|private
specifier|final
name|List
argument_list|<
name|LinkableTokenContext
argument_list|>
name|linkableTokens
init|=
operator|new
name|LinkedList
argument_list|<
name|LinkableTokenContext
argument_list|>
argument_list|()
decl_stmt|;
comment|/**      * The minimum score a tag needs to match processable tokens within a      * {@link Chunk} so that is is not omitted.       */
specifier|private
name|double
name|minChunkMatchScore
decl_stmt|;
comment|/**      * The minimum amount of matched (matchable) Tokens so that an Entity is      * considered. Only used within processable chunks      */
specifier|private
name|int
name|minFoundTokens
decl_stmt|;
specifier|protected
name|LinkableTokenFilter
parameter_list|(
name|TokenStream
name|input
parameter_list|,
name|AnalysedText
name|at
parameter_list|,
name|String
name|lang
parameter_list|,
name|LanguageProcessingConfig
name|lpc
parameter_list|,
name|double
name|minChunkMatchScore
parameter_list|,
name|int
name|minFoundTokens
parameter_list|)
block|{
name|super
argument_list|(
name|input
argument_list|)
expr_stmt|;
comment|//STANBOL-1177: add attributes in doPrivileged to avoid
comment|//AccessControlException: access denied ("java.lang.RuntimePermission" "getClassLoader")
name|termAtt
operator|=
name|AccessController
operator|.
name|doPrivileged
argument_list|(
operator|new
name|PrivilegedAction
argument_list|<
name|CharTermAttribute
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|CharTermAttribute
name|run
parameter_list|()
block|{
return|return
name|addAttribute
argument_list|(
name|CharTermAttribute
operator|.
name|class
argument_list|)
return|;
block|}
block|}
argument_list|)
expr_stmt|;
name|offset
operator|=
name|AccessController
operator|.
name|doPrivileged
argument_list|(
operator|new
name|PrivilegedAction
argument_list|<
name|OffsetAttribute
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|OffsetAttribute
name|run
parameter_list|()
block|{
return|return
name|addAttribute
argument_list|(
name|OffsetAttribute
operator|.
name|class
argument_list|)
return|;
block|}
block|}
argument_list|)
expr_stmt|;
name|taggable
operator|=
name|AccessController
operator|.
name|doPrivileged
argument_list|(
operator|new
name|PrivilegedAction
argument_list|<
name|TaggingAttribute
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|TaggingAttribute
name|run
parameter_list|()
block|{
return|return
name|addAttribute
argument_list|(
name|TaggingAttribute
operator|.
name|class
argument_list|)
return|;
block|}
block|}
argument_list|)
expr_stmt|;
name|this
operator|.
name|at
operator|=
name|at
expr_stmt|;
comment|//this.lang = lang;
name|this
operator|.
name|lpc
operator|=
name|lpc
expr_stmt|;
name|this
operator|.
name|isUnicaseLanguage
operator|=
name|lang
operator|!=
literal|null
operator|&&
operator|!
name|lang
operator|.
name|isEmpty
argument_list|()
operator|&&
name|UNICASE_SCRIPT_LANUAGES
operator|.
name|contains
argument_list|(
name|lang
argument_list|)
expr_stmt|;
name|this
operator|.
name|minChunkMatchScore
operator|=
name|minChunkMatchScore
expr_stmt|;
name|this
operator|.
name|minFoundTokens
operator|=
name|minFoundTokens
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|reset
parameter_list|()
throws|throws
name|IOException
block|{
name|super
operator|.
name|reset
argument_list|()
expr_stmt|;
name|Iterator
argument_list|<
name|Sentence
argument_list|>
name|sentences
init|=
name|at
operator|.
name|getSentences
argument_list|()
decl_stmt|;
name|this
operator|.
name|sections
operator|=
name|sentences
operator|.
name|hasNext
argument_list|()
condition|?
name|sentences
else|:
name|Collections
operator|.
name|singleton
argument_list|(
name|at
argument_list|)
operator|.
name|iterator
argument_list|()
expr_stmt|;
name|sectionData
operator|=
literal|null
expr_stmt|;
name|tokenIt
operator|=
literal|null
expr_stmt|;
name|incrementCount
operator|=
literal|0
expr_stmt|;
name|lookupCount
operator|=
literal|0
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|incrementToken
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|input
operator|.
name|incrementToken
argument_list|()
condition|)
block|{
name|incrementCount
operator|++
expr_stmt|;
name|boolean
name|first
init|=
literal|true
decl_stmt|;
name|TokenData
name|token
decl_stmt|;
name|boolean
name|lookup
init|=
literal|false
decl_stmt|;
name|int
name|lastMatchable
init|=
operator|-
literal|1
decl_stmt|;
name|int
name|lastIndex
init|=
operator|-
literal|1
decl_stmt|;
name|log
operator|.
name|trace
argument_list|(
literal|"> solr:[{},{}] {}"
argument_list|,
operator|new
name|Object
index|[]
block|{
name|offset
operator|.
name|startOffset
argument_list|()
block|,
name|offset
operator|.
name|endOffset
argument_list|()
block|,
name|termAtt
block|}
argument_list|)
expr_stmt|;
while|while
condition|(
operator|(
name|token
operator|=
name|nextToken
argument_list|(
name|first
argument_list|)
operator|)
operator|!=
literal|null
condition|)
block|{
name|log
operator|.
name|trace
argument_list|(
literal|"< [{},{}]:{} (link {}, match; {})"
argument_list|,
operator|new
name|Object
index|[]
block|{
name|token
operator|.
name|token
operator|.
name|getStart
argument_list|()
block|,
name|token
operator|.
name|token
operator|.
name|getEnd
argument_list|()
block|,
name|token
operator|.
name|getTokenText
argument_list|()
block|,
name|token
operator|.
name|isLinkable
block|,
name|token
operator|.
name|isMatchable
block|}
argument_list|)
expr_stmt|;
name|first
operator|=
literal|false
expr_stmt|;
if|if
condition|(
name|token
operator|.
name|isLinkable
condition|)
block|{
name|log
operator|.
name|trace
argument_list|(
literal|"  + lookup because {} is linkable"
argument_list|,
name|token
argument_list|)
expr_stmt|;
name|lookup
operator|=
literal|true
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|token
operator|.
name|isMatchable
condition|)
block|{
name|lastMatchable
operator|=
name|token
operator|.
name|index
expr_stmt|;
name|lastIndex
operator|=
name|lastMatchable
expr_stmt|;
block|}
comment|//special rules for processable chunks (typically noun phrases)
comment|//accept all tokens in processable chunks with a linkable or
comment|//multiple matchable tokens.
if|if
condition|(
operator|!
name|lookup
operator|&&
operator|(
operator|!
name|lpc
operator|.
name|isIgnoreChunks
argument_list|()
operator|)
operator|&&
name|token
operator|.
name|inChunk
operator|!=
literal|null
operator|&&
name|token
operator|.
name|inChunk
operator|.
name|isProcessable
condition|)
block|{
if|if
condition|(
name|token
operator|.
name|inChunk
operator|.
name|isNamedEntity
argument_list|()
condition|)
block|{
if|if
condition|(
name|log
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|log
operator|.
name|trace
argument_list|(
literal|"  + lookup because {} is part of Named Entity '{}'"
argument_list|,
name|token
operator|.
name|token
argument_list|,
name|token
operator|.
name|inChunk
operator|.
name|chunk
operator|.
name|getSpan
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|lookup
operator|=
literal|true
expr_stmt|;
block|}
if|if
condition|(
name|token
operator|.
name|inChunk
operator|.
name|hasLinkable
argument_list|()
operator|||
operator|(
name|lpc
operator|.
name|isLinkMultiMatchableTokensInChunk
argument_list|()
operator|&&
name|token
operator|.
name|inChunk
operator|.
name|getMatchableCount
argument_list|()
operator|>
literal|1
operator|)
condition|)
block|{
if|if
condition|(
name|log
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|log
operator|.
name|trace
argument_list|(
literal|"  + lookup because {} is part of a linkable chunk '{}'"
argument_list|,
name|token
operator|.
name|token
argument_list|,
name|token
operator|.
name|inChunk
operator|.
name|chunk
operator|.
name|getSpan
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|lookup
operator|=
literal|true
expr_stmt|;
block|}
block|}
block|}
comment|//lookahead
if|if
condition|(
operator|!
name|lookup
operator|&&
name|lastIndex
operator|>=
literal|0
operator|&&
name|sectionData
operator|!=
literal|null
condition|)
block|{
name|List
argument_list|<
name|TokenData
argument_list|>
name|tokens
init|=
name|sectionData
operator|.
name|getTokens
argument_list|()
decl_stmt|;
name|int
name|maxLookahead
init|=
name|Math
operator|.
name|max
argument_list|(
name|lastIndex
argument_list|,
name|lastMatchable
operator|+
literal|3
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|lastIndex
operator|+
literal|1
init|;
operator|!
name|lookup
operator|&&
name|i
operator|<
name|maxLookahead
operator|&&
name|i
operator|<
name|tokens
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|token
operator|=
name|tokens
operator|.
name|get
argument_list|(
name|i
argument_list|)
expr_stmt|;
if|if
condition|(
name|token
operator|.
name|isLinkable
condition|)
block|{
name|lookup
operator|=
literal|true
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|token
operator|.
name|isMatchable
operator|&&
operator|(
name|i
operator|+
literal|1
operator|)
operator|==
name|maxLookahead
condition|)
block|{
name|maxLookahead
operator|++
expr_stmt|;
comment|//increase lookahead for matchable tokens
block|}
block|}
block|}
name|this
operator|.
name|taggable
operator|.
name|setTaggable
argument_list|(
name|lookup
argument_list|)
expr_stmt|;
if|if
condition|(
name|lookup
condition|)
block|{
if|if
condition|(
name|log
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|TokenData
name|t
init|=
name|getToken
argument_list|()
decl_stmt|;
name|log
operator|.
name|trace
argument_list|(
literal|"lookup: token [{},{}]: {} | word [{},{}]:{}"
argument_list|,
operator|new
name|Object
index|[]
block|{
name|offset
operator|.
name|startOffset
argument_list|()
block|,
name|offset
operator|.
name|endOffset
argument_list|()
block|,
name|termAtt
block|,
name|t
operator|.
name|token
operator|.
name|getStart
argument_list|()
block|,
name|t
operator|.
name|token
operator|.
name|getEnd
argument_list|()
block|,
name|t
operator|.
name|getTokenText
argument_list|()
block|}
argument_list|)
expr_stmt|;
block|}
name|lookupCount
operator|++
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
else|else
block|{
name|log
operator|.
name|debug
argument_list|(
literal|"lookup percentage: {}"
argument_list|,
name|lookupCount
operator|*
literal|100
operator|/
operator|(
name|float
operator|)
name|incrementCount
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
comment|/**      * Iterating over TokensData requires to iterate over two hierarchy levels:      * (1) sections (likely Sentences) and (2) Tokens<p>      *<b>NOTE</b> that this method modifies a lot of fields to update the      * state of the iteration accordingly. If the {@link #token} field is      *<code>null</code> after a call to this method this indicates that the      * end of the {@link Token} in the {@link AnalysedText} was reached.      * @param first is this the first call for the current {@link #offset} state?      * @return the token or<code>null</code> if there are no more tokens for      * the current {@link #offset}      */
specifier|private
name|TokenData
name|nextToken
parameter_list|(
name|boolean
name|first
parameter_list|)
block|{
name|int
name|startOffset
init|=
name|offset
operator|.
name|startOffset
argument_list|()
decl_stmt|;
name|int
name|endOffset
init|=
name|offset
operator|.
name|endOffset
argument_list|()
decl_stmt|;
if|if
condition|(
name|first
condition|)
block|{
comment|//on the first call for a token
name|tokensCursor
operator|=
operator|-
literal|1
expr_stmt|;
comment|//reset cursor to zero
while|while
condition|(
operator|!
name|tokens
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|//remove tokens earlier as the current offset
if|if
condition|(
name|tokens
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|token
operator|.
name|getEnd
argument_list|()
operator|<=
name|startOffset
condition|)
block|{
name|tokens
operator|.
name|remove
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|//stop on the first overlapping token
break|break;
block|}
block|}
comment|//else nothing to do
block|}
if|if
condition|(
name|tokensCursor
operator|>=
name|tokens
operator|.
name|size
argument_list|()
operator|-
literal|1
condition|)
block|{
if|if
condition|(
operator|!
name|incrementTokenData
argument_list|()
condition|)
block|{
comment|//adds a new token to the list
return|return
literal|null
return|;
comment|//EoF
block|}
block|}
name|TokenData
name|cursorToken
init|=
name|tokens
operator|.
name|get
argument_list|(
name|tokensCursor
operator|+
literal|1
argument_list|)
decl_stmt|;
if|if
condition|(
name|cursorToken
operator|.
name|token
operator|.
name|getStart
argument_list|()
operator|<
name|endOffset
condition|)
block|{
name|tokensCursor
operator|++
expr_stmt|;
comment|//set the next token as current
return|return
name|cursorToken
return|;
comment|//and return it
block|}
else|else
block|{
return|return
literal|null
return|;
block|}
block|}
comment|/**      * Increments the {@link #token} and - if necessary also the {@link #sectionData      * section}.      * @return<code>true</code> unless there are no more tokens      */
specifier|private
name|boolean
name|incrementTokenData
parameter_list|()
block|{
if|if
condition|(
name|tokenIt
operator|==
literal|null
operator|||
operator|!
name|tokenIt
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|sectionData
operator|=
literal|null
expr_stmt|;
name|tokenIt
operator|=
literal|null
expr_stmt|;
while|while
condition|(
name|sections
operator|.
name|hasNext
argument_list|()
operator|&&
operator|(
name|tokenIt
operator|==
literal|null
operator|||
operator|!
name|tokenIt
operator|.
name|hasNext
argument_list|()
operator|)
condition|)
block|{
comment|//analyse NLP results for the next Section
name|sectionData
operator|=
operator|new
name|SectionData
argument_list|(
name|lpc
argument_list|,
name|sections
operator|.
name|next
argument_list|()
argument_list|,
name|PROCESSED_SPAN_TYPES
argument_list|,
name|isUnicaseLanguage
argument_list|)
expr_stmt|;
name|tokenIt
operator|=
name|sectionData
operator|.
name|getTokens
argument_list|()
operator|.
name|iterator
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|tokenIt
operator|!=
literal|null
operator|&&
name|tokenIt
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|addToken
argument_list|(
name|tokenIt
operator|.
name|next
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
else|else
block|{
comment|//reached the end .. clean up
name|sectionData
operator|=
literal|null
expr_stmt|;
name|tokenIt
operator|=
literal|null
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
else|else
block|{
comment|//more token in the same section
name|addToken
argument_list|(
name|tokenIt
operator|.
name|next
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
comment|/**      * Adds a token. Also cares about adding tokens to {@link #linkableTokens}      * @param token the tokens - MUST NOT be NULL.      */
specifier|private
name|void
name|addToken
parameter_list|(
name|TokenData
name|token
parameter_list|)
block|{
name|tokens
operator|.
name|add
argument_list|(
name|token
argument_list|)
expr_stmt|;
if|if
condition|(
name|token
operator|.
name|isLinkable
condition|)
block|{
comment|//add to the list of linkable for #reduce(TagLL[])
name|linkableTokens
operator|.
name|add
argument_list|(
operator|new
name|LinkableTokenContext
argument_list|(
name|token
argument_list|,
name|sectionData
operator|.
name|getTokens
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|token
operator|.
name|isMatchable
operator|&&
operator|!
name|lpc
operator|.
name|isIgnoreChunks
argument_list|()
operator|&&
comment|//matchable token
name|token
operator|.
name|inChunk
operator|!=
literal|null
operator|&&
comment|//in processable chunks with more
name|token
operator|.
name|inChunk
operator|.
name|isProcessable
operator|&&
comment|//as two matchable tokens
name|token
operator|.
name|inChunk
operator|.
name|getMatchableCount
argument_list|()
operator|>
literal|1
condition|)
block|{
comment|//matchable tokens
name|linkableTokens
operator|.
name|add
argument_list|(
operator|new
name|LinkableTokenContext
argument_list|(
name|token
argument_list|,
name|sectionData
operator|.
name|getTokens
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Getter for the current Token      * @return      */
specifier|private
name|TokenData
name|getToken
parameter_list|()
block|{
return|return
name|tokens
operator|.
name|isEmpty
argument_list|()
condition|?
literal|null
else|:
name|tokens
operator|.
name|get
argument_list|(
name|tokensCursor
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|reduce
parameter_list|(
name|TagLL
index|[]
name|head
parameter_list|)
block|{
comment|//this implements a two phase reduce
comment|//(1) reduce Tags with no linkable tokens and not matching enough of the
comment|//    current chunk.
comment|//(2) reduce remaining Tags in the cluster similar to TagClusterReducer
comment|//    but only considering the "matchable span" of the Tags. Meaning the
comment|//    span over matchable Tokens and not the full Text.
comment|//this map holds the matchable spans for Tags. Filled during phase (1) and
comment|//used for phase(2)
name|Map
argument_list|<
name|TagLL
argument_list|,
name|int
index|[]
argument_list|>
name|matchableTagSpan
init|=
operator|new
name|HashMap
argument_list|<
name|TagLL
argument_list|,
name|int
index|[]
argument_list|>
argument_list|()
decl_stmt|;
comment|//(1) reduce Tags based on link-/matchable tokens as well as chunks.
name|LinkableTokenContext
name|linkableTokenContext
decl_stmt|;
for|for
control|(
name|TagLL
name|tag
init|=
name|head
index|[
literal|0
index|]
init|;
name|tag
operator|!=
literal|null
condition|;
name|tag
operator|=
name|tag
operator|.
name|getNextTag
argument_list|()
control|)
block|{
name|int
name|start
init|=
name|tag
operator|.
name|getStartOffset
argument_list|()
decl_stmt|;
name|int
name|end
init|=
name|tag
operator|.
name|getEndOffset
argument_list|()
decl_stmt|;
name|linkableTokenContext
operator|=
name|linkableTokens
operator|.
name|isEmpty
argument_list|()
condition|?
literal|null
else|:
name|linkableTokens
operator|.
name|get
argument_list|(
literal|0
argument_list|)
expr_stmt|;
while|while
condition|(
name|linkableTokenContext
operator|!=
literal|null
operator|&&
name|linkableTokenContext
operator|.
name|linkableToken
operator|.
name|token
operator|.
name|getEnd
argument_list|()
operator|<=
name|start
condition|)
block|{
name|linkableTokens
operator|.
name|remove
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|linkableTokenContext
operator|=
name|linkableTokens
operator|.
name|isEmpty
argument_list|()
condition|?
literal|null
else|:
name|linkableTokens
operator|.
name|get
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|linkableTokenContext
operator|==
literal|null
operator|||
name|linkableTokenContext
operator|.
name|linkableToken
operator|.
name|token
operator|.
name|getStart
argument_list|()
operator|>=
name|end
condition|)
block|{
comment|//does not overlap any linkable token
name|tag
operator|.
name|removeLL
argument_list|()
expr_stmt|;
comment|//remove the tag from the cluster
if|if
condition|(
name|log
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|CharSequence
name|tagSequence
init|=
name|at
operator|.
name|getText
argument_list|()
operator|.
name|subSequence
argument_list|(
name|start
argument_list|,
name|end
argument_list|)
decl_stmt|;
name|log
operator|.
name|trace
argument_list|(
literal|"> reduce tag {} - no overlapp with linkable token"
argument_list|,
name|tagSequence
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|//if the tag overlaps a linkable token
name|TokenData
name|linkableToken
init|=
name|linkableTokenContext
operator|.
name|linkableToken
decl_stmt|;
name|List
argument_list|<
name|TokenData
argument_list|>
name|tokens
init|=
name|linkableTokenContext
operator|.
name|context
decl_stmt|;
comment|//calculate the matchable start/end span of the current TagLL
name|int
index|[]
name|mSpan
init|=
operator|new
name|int
index|[]
block|{
name|Math
operator|.
name|max
argument_list|(
name|start
argument_list|,
name|linkableToken
operator|.
name|token
operator|.
name|getStart
argument_list|()
argument_list|)
block|,
name|Math
operator|.
name|min
argument_list|(
name|end
argument_list|,
name|linkableToken
operator|.
name|token
operator|.
name|getEnd
argument_list|()
argument_list|)
block|}
decl_stmt|;
if|if
condition|(
name|mSpan
index|[
literal|0
index|]
operator|>
name|start
condition|)
block|{
for|for
control|(
name|int
name|i
init|=
name|linkableToken
operator|.
name|index
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
condition|;
name|i
operator|--
control|)
block|{
name|TokenData
name|token
init|=
name|tokens
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|int
name|tStart
init|=
name|token
operator|.
name|token
operator|.
name|getStart
argument_list|()
decl_stmt|;
if|if
condition|(
name|tStart
operator|<
name|start
condition|)
block|{
break|break;
block|}
elseif|else
if|if
condition|(
name|token
operator|.
name|isMatchable
condition|)
block|{
name|mSpan
index|[
literal|0
index|]
operator|=
name|tStart
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|mSpan
index|[
literal|1
index|]
operator|<
name|end
condition|)
block|{
for|for
control|(
name|int
name|i
init|=
name|linkableToken
operator|.
name|index
operator|+
literal|1
init|;
name|i
operator|<
name|tokens
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|TokenData
name|token
init|=
name|tokens
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|int
name|tEnd
init|=
name|token
operator|.
name|token
operator|.
name|getEnd
argument_list|()
decl_stmt|;
if|if
condition|(
name|tEnd
operator|>
name|end
condition|)
block|{
break|break;
block|}
elseif|else
if|if
condition|(
name|token
operator|.
name|isMatchable
condition|)
block|{
name|mSpan
index|[
literal|1
index|]
operator|=
name|tEnd
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|log
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|CharSequence
name|text
init|=
name|at
operator|.
name|getText
argument_list|()
decl_stmt|;
name|log
operator|.
name|trace
argument_list|(
literal|" - matchable Span {}{} for Tag {}[{},{}]"
argument_list|,
operator|new
name|Object
index|[]
block|{
name|text
operator|.
name|subSequence
argument_list|(
name|mSpan
index|[
literal|0
index|]
argument_list|,
name|mSpan
index|[
literal|1
index|]
argument_list|)
block|,
name|Arrays
operator|.
name|toString
argument_list|(
name|mSpan
argument_list|)
block|,
name|text
operator|.
name|subSequence
argument_list|(
name|start
argument_list|,
name|end
argument_list|)
block|,
name|start
block|,
name|end
block|}
argument_list|)
expr_stmt|;
block|}
name|matchableTagSpan
operator|.
name|put
argument_list|(
name|tag
argument_list|,
name|mSpan
argument_list|)
expr_stmt|;
name|ChunkData
name|cd
init|=
name|linkableToken
operator|.
name|inChunk
decl_stmt|;
comment|//check if it matches> 50% of the chunk
if|if
condition|(
operator|!
name|lpc
operator|.
name|isIgnoreChunks
argument_list|()
operator|&&
name|cd
operator|!=
literal|null
operator|&&
name|cd
operator|.
name|isProcessable
condition|)
block|{
name|int
name|cstart
init|=
name|cd
operator|.
name|getMatchableStartChar
argument_list|()
operator|>=
literal|0
condition|?
name|cd
operator|.
name|getMatchableStartChar
argument_list|()
else|:
name|start
decl_stmt|;
name|int
name|cend
init|=
name|cd
operator|.
name|getMatchableEndChar
argument_list|()
decl_stmt|;
if|if
condition|(
name|cstart
argument_list|<
name|start
operator|||
name|cend
argument_list|>
name|end
condition|)
block|{
comment|//if the tag does not cover the whole chunk
name|int
name|num
init|=
literal|0
decl_stmt|;
name|int
name|match
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|cd
operator|.
name|getMatchableStart
argument_list|()
init|;
name|i
operator|<=
name|cd
operator|.
name|getMatchableEnd
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|TokenData
name|td
init|=
name|tokens
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|td
operator|.
name|isMatchable
condition|)
block|{
name|num
operator|++
expr_stmt|;
if|if
condition|(
name|match
argument_list|<
literal|1
operator|&&
name|td
operator|.
name|token
operator|.
name|getStart
operator|(
operator|)
operator|>=
name|start
operator|||
name|match
argument_list|>
literal|0
operator|&&
name|td
operator|.
name|token
operator|.
name|getEnd
argument_list|()
operator|<=
name|end
condition|)
block|{
name|match
operator|++
expr_stmt|;
block|}
block|}
block|}
comment|//only accept tags with more as half of the matchable
comment|//tokens in the Chunk are matched!
if|if
condition|(
operator|(
operator|(
name|float
operator|)
name|match
operator|/
operator|(
name|float
operator|)
name|num
operator|)
operator|<
name|minChunkMatchScore
operator|&&
name|match
operator|<
name|minFoundTokens
condition|)
block|{
name|tag
operator|.
name|removeLL
argument_list|()
expr_stmt|;
comment|//ignore
name|matchableTagSpan
operator|.
name|remove
argument_list|(
name|tag
argument_list|)
expr_stmt|;
if|if
condition|(
name|log
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|CharSequence
name|text
init|=
name|at
operator|.
name|getText
argument_list|()
decl_stmt|;
name|log
operator|.
name|trace
argument_list|(
literal|" - reduce tag {}[{},{}] - does only match "
operator|+
literal|"{} of {} of matchable Chunk {}[{},{}]"
argument_list|,
operator|new
name|Object
index|[]
block|{
name|text
operator|.
name|subSequence
argument_list|(
name|start
argument_list|,
name|end
argument_list|)
block|,
name|start
block|,
name|end
block|,
name|match
block|,
name|num
block|,
name|text
operator|.
name|subSequence
argument_list|(
name|cstart
argument_list|,
name|cend
argument_list|)
block|,
name|cstart
block|,
name|cend
block|}
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|log
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|CharSequence
name|text
init|=
name|at
operator|.
name|getText
argument_list|()
decl_stmt|;
name|log
operator|.
name|trace
argument_list|(
literal|" + keep tag {}[{},{}] - matches {} of {} "
operator|+
literal|"matchable Tokens for matchable Chunk {}[{},{}]"
argument_list|,
operator|new
name|Object
index|[]
block|{
name|text
operator|.
name|subSequence
argument_list|(
name|start
argument_list|,
name|end
argument_list|)
block|,
name|start
block|,
name|end
block|,
name|match
block|,
name|num
block|,
name|text
operator|.
name|subSequence
argument_list|(
name|cstart
argument_list|,
name|cend
argument_list|)
block|,
name|cstart
block|,
name|cend
block|}
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|log
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|CharSequence
name|text
init|=
name|at
operator|.
name|getText
argument_list|()
decl_stmt|;
name|log
operator|.
name|trace
argument_list|(
literal|" + keep tag {}[{},{}] - matches whole Chunk {}[{},{}]"
argument_list|,
operator|new
name|Object
index|[]
block|{
name|text
operator|.
name|subSequence
argument_list|(
name|start
argument_list|,
name|end
argument_list|)
block|,
name|start
block|,
name|end
block|,
name|text
operator|.
name|subSequence
argument_list|(
name|cstart
argument_list|,
name|cend
argument_list|)
block|,
name|cstart
block|,
name|cend
block|}
argument_list|)
expr_stmt|;
block|}
block|}
block|}
elseif|else
if|if
condition|(
name|log
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|CharSequence
name|tagSequence
init|=
name|at
operator|.
name|getText
argument_list|()
operator|.
name|subSequence
argument_list|(
name|start
argument_list|,
name|end
argument_list|)
decl_stmt|;
name|log
operator|.
name|trace
argument_list|(
literal|" + keep tag {} - not in processable chunk"
argument_list|,
name|tagSequence
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|//(2) reduce Tags base on longest dominant right based on the matchable
comment|//    spans
comment|//NOTE: This is the same code as TagClusterReducer#LONGEST_DOMINANT_RIGHT
comment|//      but adapted to use the matchable spans instead of the full Tag
comment|//      spans
if|if
condition|(
name|head
operator|.
name|length
operator|==
literal|0
operator|||
name|head
index|[
literal|0
index|]
operator|==
literal|null
operator|||
name|head
index|[
literal|0
index|]
operator|.
name|getNextTag
argument_list|()
operator|==
literal|null
condition|)
block|{
return|return;
comment|//no tag left from phase one or single token optimization
block|}
name|Set
argument_list|<
name|TagLL
argument_list|>
name|marked
init|=
operator|new
name|HashSet
argument_list|<
name|TagLL
argument_list|>
argument_list|()
decl_stmt|;
comment|//can not use TagLL#mark
while|while
condition|(
literal|true
condition|)
block|{
comment|// --Find longest not already marked
name|TagLL
name|longest
init|=
literal|null
decl_stmt|;
name|int
name|longestMCharLen
init|=
operator|-
literal|1
decl_stmt|;
name|int
index|[]
name|longestMSpan
init|=
literal|null
decl_stmt|;
for|for
control|(
name|TagLL
name|t
init|=
name|head
index|[
literal|0
index|]
init|;
name|t
operator|!=
literal|null
condition|;
name|t
operator|=
name|t
operator|.
name|getNextTag
argument_list|()
control|)
block|{
name|int
index|[]
name|mSpan
init|=
name|matchableTagSpan
operator|.
name|get
argument_list|(
name|t
argument_list|)
decl_stmt|;
name|int
name|mCharLen
init|=
name|mSpan
index|[
literal|1
index|]
operator|-
name|mSpan
index|[
literal|0
index|]
decl_stmt|;
if|if
condition|(
operator|!
name|marked
operator|.
name|contains
argument_list|(
name|t
argument_list|)
operator|&&
operator|(
name|longest
operator|==
literal|null
operator|||
name|mCharLen
operator|>=
name|longestMCharLen
operator|)
condition|)
block|{
name|longest
operator|=
name|t
expr_stmt|;
name|longestMSpan
operator|=
name|mSpan
expr_stmt|;
name|longestMCharLen
operator|=
name|mCharLen
expr_stmt|;
block|}
block|}
if|if
condition|(
name|longest
operator|==
literal|null
condition|)
break|break;
comment|// --Mark longest (so we return it eventually)
name|marked
operator|.
name|add
argument_list|(
name|longest
argument_list|)
expr_stmt|;
comment|// --Remove tags overlapping this longest
for|for
control|(
name|TagLL
name|t
init|=
name|head
index|[
literal|0
index|]
init|;
name|t
operator|!=
literal|null
condition|;
name|t
operator|=
name|t
operator|.
name|getNextTag
argument_list|()
control|)
block|{
if|if
condition|(
name|marked
operator|.
name|contains
argument_list|(
name|t
argument_list|)
condition|)
block|{
continue|continue;
block|}
name|int
index|[]
name|mSpan
init|=
name|matchableTagSpan
operator|.
name|get
argument_list|(
name|t
argument_list|)
decl_stmt|;
name|boolean
name|overlaps
init|=
name|mSpan
index|[
literal|0
index|]
operator|<
name|longestMSpan
index|[
literal|0
index|]
condition|?
name|mSpan
index|[
literal|1
index|]
operator|>
name|longestMSpan
index|[
literal|1
index|]
else|:
name|mSpan
index|[
literal|0
index|]
operator|<
name|longestMSpan
index|[
literal|1
index|]
decl_stmt|;
if|if
condition|(
name|overlaps
condition|)
block|{
name|t
operator|.
name|removeLL
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|mSpan
index|[
literal|0
index|]
operator|>=
name|longestMSpan
index|[
literal|1
index|]
condition|)
block|{
break|break;
comment|// no subsequent can possibly overlap
block|}
block|}
block|}
comment|// loop
block|}
comment|/**      * Holds the context for a linkable {@link Token}s. This ensures that the      * list of Tokens of the current {@link Section} (typically a {@link Sentence})       * is still available even if the {@link LinkableTokenFilter#sectionData} does hold      * already tokens for the next section.<p>      * This is necessary as {@link LinkableTokenFilter#reduce(TagLL[])} can      * be called for the previous sentence in cases where a Tag cluster includes      * the last {@link Token} of a {@link Section}.      * @author Rupert Westenthaler      *      */
specifier|private
specifier|static
class|class
name|LinkableTokenContext
block|{
specifier|final
name|TokenData
name|linkableToken
decl_stmt|;
specifier|final
name|List
argument_list|<
name|TokenData
argument_list|>
name|context
decl_stmt|;
name|LinkableTokenContext
parameter_list|(
name|TokenData
name|linkableToken
parameter_list|,
name|List
argument_list|<
name|TokenData
argument_list|>
name|context
parameter_list|)
block|{
name|this
operator|.
name|linkableToken
operator|=
name|linkableToken
expr_stmt|;
name|this
operator|.
name|context
operator|=
name|context
expr_stmt|;
block|}
block|}
block|}
end_class

end_unit

