begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/* * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements.  See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the "License"); you may not use this file except in compliance with * the License.  You may obtain a copy of the License at * *     http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */
end_comment

begin_comment
comment|/**  *   */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|entitylinking
operator|.
name|impl
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|entitylinking
operator|.
name|config
operator|.
name|TextProcessingConfig
operator|.
name|UNICASE_SCRIPT_LANUAGES
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|EnumSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Locale
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|collections
operator|.
name|Predicate
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|collections
operator|.
name|iterators
operator|.
name|FilterIterator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|entitylinking
operator|.
name|config
operator|.
name|LanguageProcessingConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|AnalysedText
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|Section
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|Sentence
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|SpanTypeEnum
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|Token
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|pos
operator|.
name|Pos
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_class
specifier|public
class|class
name|ProcessingState
block|{
specifier|private
specifier|final
name|Logger
name|log
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|ProcessingState
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/**      * Iterator over the sentences (might be      * the whole {@link AnalysedText} if no sentences are      * defined).      */
specifier|private
specifier|final
name|Iterator
argument_list|<
name|?
extends|extends
name|Section
argument_list|>
name|sections
decl_stmt|;
comment|/**      * The sentence currently processed      */
specifier|private
name|Section
name|section
decl_stmt|;
comment|/**      * Holds the {@link Token}s of the current {@link #sentence}       * to allow fast index based access.      */
specifier|private
name|List
argument_list|<
name|TokenData
argument_list|>
name|tokens
init|=
operator|new
name|ArrayList
argument_list|<
name|TokenData
argument_list|>
argument_list|(
literal|64
argument_list|)
decl_stmt|;
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
specifier|private
name|Iterator
argument_list|<
name|TokenData
argument_list|>
name|processableTokensIterator
init|=
name|Collections
operator|.
name|EMPTY_LIST
operator|.
name|iterator
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|EnumSet
argument_list|<
name|SpanTypeEnum
argument_list|>
name|enclosedSpanTypes
decl_stmt|;
comment|/**      * The current token      */
specifier|private
name|TokenData
name|token
decl_stmt|;
comment|/**      * The position of the last consumed position      */
specifier|private
name|int
name|consumedIndex
init|=
operator|-
literal|1
decl_stmt|;
comment|/**      * Ensures that Tokens are not processed twice in case of multiple      * overlapping Sentence Annotations (e.g. if two NLP frameworks contributing      * Sentences do not agree with each other).      */
specifier|private
name|int
name|consumedSectionIndex
init|=
operator|-
literal|1
decl_stmt|;
comment|/**      * The language of the text      */
specifier|private
name|String
name|language
decl_stmt|;
specifier|protected
specifier|final
name|LanguageProcessingConfig
name|tpc
decl_stmt|;
comment|//protected final EntityLinkerConfig elc;
comment|//private AnalysedText at;
comment|/**      * If the language uses a unicase script and therefore upper case specific      * processing rules can not be used (see STANBOL-1049)      */
specifier|private
name|boolean
name|isUnicaseLanguage
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Predicate
name|PROCESSABLE_TOKEN_OREDICATE
init|=
operator|new
name|Predicate
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|evaluate
parameter_list|(
name|Object
name|object
parameter_list|)
block|{
return|return
operator|(
operator|(
name|TokenData
operator|)
name|object
operator|)
operator|.
name|isLinkable
return|;
block|}
block|}
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|Collection
argument_list|<
name|Pos
argument_list|>
name|SUB_SENTENCE_START_POS
init|=
name|EnumSet
operator|.
name|of
argument_list|(
name|Pos
operator|.
name|Quote
argument_list|)
decl_stmt|;
specifier|public
name|ProcessingState
parameter_list|(
name|AnalysedText
name|at
parameter_list|,
name|String
name|language
parameter_list|,
name|LanguageProcessingConfig
name|tpc
parameter_list|)
block|{
if|if
condition|(
name|at
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"The parsed AnalysedText MUST NOT be NULL!"
argument_list|)
throw|;
block|}
if|if
condition|(
name|language
operator|==
literal|null
operator|||
name|language
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"The parsed Language MUST NOT be NULL nor empty!"
argument_list|)
throw|;
block|}
if|if
condition|(
name|tpc
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"The parsed TextProcessingConfig MUST NOT be NULL!"
argument_list|)
throw|;
block|}
name|this
operator|.
name|tpc
operator|=
name|tpc
expr_stmt|;
name|enclosedSpanTypes
operator|=
name|EnumSet
operator|.
name|of
argument_list|(
name|SpanTypeEnum
operator|.
name|Token
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|tpc
operator|.
name|isIgnoreChunks
argument_list|()
condition|)
block|{
name|enclosedSpanTypes
operator|.
name|add
argument_list|(
name|SpanTypeEnum
operator|.
name|Chunk
argument_list|)
expr_stmt|;
block|}
comment|//this.at = at; //store as field (just used for logging)
name|this
operator|.
name|language
operator|=
name|language
expr_stmt|;
comment|//STANBOL-1049: we need now to know if a language uses a unicase script
comment|//ensure lower case and only use the language part
name|String
name|lookupLang
init|=
name|language
operator|.
name|toLowerCase
argument_list|(
name|Locale
operator|.
name|ROOT
argument_list|)
operator|.
name|split
argument_list|(
literal|"[_-]"
argument_list|)
index|[
literal|0
index|]
decl_stmt|;
name|this
operator|.
name|isUnicaseLanguage
operator|=
name|UNICASE_SCRIPT_LANUAGES
operator|.
name|contains
argument_list|(
name|lookupLang
argument_list|)
expr_stmt|;
comment|//prefer to iterate over sentences
name|Iterator
argument_list|<
name|Sentence
argument_list|>
name|sentences
init|=
name|at
operator|.
name|getSentences
argument_list|()
decl_stmt|;
name|this
operator|.
name|sections
operator|=
name|sentences
operator|.
name|hasNext
argument_list|()
condition|?
name|sentences
else|:
name|Collections
operator|.
name|singleton
argument_list|(
name|at
argument_list|)
operator|.
name|iterator
argument_list|()
expr_stmt|;
comment|//init the first sentence
comment|//initNextSentence();
block|}
comment|/**      * Getter for the current section. This is typically a {@link Sentence}      * but might also be the whole {@link AnalysedText} in case no sentence      * annotations are available      * @return the currently processed {@link Section}      */
specifier|public
specifier|final
name|Section
name|getSentence
parameter_list|()
block|{
return|return
name|section
return|;
block|}
comment|/**      * Getter for the current token      * @return the token for the currently processed word      */
specifier|public
name|TokenData
name|getToken
parameter_list|()
block|{
return|return
name|token
return|;
block|}
comment|/**      * Getter for the Tokens of the currently processed section      * @return the Tokens of the currently processed section      */
specifier|public
name|List
argument_list|<
name|TokenData
argument_list|>
name|getTokens
parameter_list|()
block|{
return|return
name|tokens
return|;
block|}
comment|/**      * Getter for the last consumed index      * @return the index of the last consumed token      */
specifier|public
specifier|final
name|int
name|getConsumedIndex
parameter_list|()
block|{
return|return
name|consumedIndex
return|;
block|}
comment|/**      * Getter for the language of the current Token (based on the current      * sentence)      * @return the language      */
specifier|public
specifier|final
name|String
name|getLanguage
parameter_list|()
block|{
return|return
name|language
return|;
block|}
comment|//    /**
comment|//     * Getter for the next {@link Token} to be processed. Calling {@link #next()}
comment|//     * is guaranteed to skip all tokens in between {@link #getTokenIndex()}
comment|//     * and {@link #getNextToken()}, but it might even skip more tokens (e.g.
comment|//     * in case that the token referenced by {@link #getNextToken()} is not
comment|//     * within a {@link Chunk}
comment|//     * @return the nextToken
comment|//     */
comment|//    public final int getNextToken() {
comment|//        return nextToken;
comment|//    }
comment|/**      * The index of an consumed Token. The consumed index MUST BE equals or      * greater as {@link #getTokenIndex()}. If the consumed index is set to a      * value greater that {@link #getTokenIndex()} than consumed tokens are      * skipped on the next call to {@link #next()}      * @param pos the position of the last consumed token.      */
specifier|public
name|void
name|setConsumed
parameter_list|(
name|int
name|pos
parameter_list|)
block|{
if|if
condition|(
name|pos
operator|>=
name|token
operator|.
name|index
condition|)
block|{
name|this
operator|.
name|consumedIndex
operator|=
name|pos
expr_stmt|;
comment|//            this.nextToken = pos+1;
block|}
else|else
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"The lastConsumedPos "
operator|+
name|pos
operator|+
literal|" MUST BE equals or gerater than the current Pos "
operator|+
name|token
operator|.
name|index
argument_list|)
throw|;
block|}
block|}
comment|/**      * Moves the state to next processable token after the index #nextToken      * @return<code>true</code> if there are further elements to process or      *<code>false</code> if there are no further elements to process.      */
specifier|public
name|boolean
name|next
parameter_list|()
block|{
while|while
condition|(
name|processableTokensIterator
operator|.
name|hasNext
argument_list|()
operator|||
name|initNextSentence
argument_list|()
condition|)
block|{
name|TokenData
name|token
init|=
name|processableTokensIterator
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|token
operator|.
name|index
operator|>
name|consumedIndex
condition|)
block|{
name|this
operator|.
name|token
operator|=
name|token
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
return|return
literal|false
return|;
block|}
comment|/**      * Correctly initialise {@link #sentence}, {@link #chunks}, {@link #chunk}      * and {@link #tokenIndex} for the next element of {@link #sections}. If      * no further sentences are to process it simple sets {@link #sentence},       * {@link #chunks}, {@link #chunk} and {@link #tokenIndex} to<code>null</code>      */
specifier|private
name|boolean
name|initNextSentence
parameter_list|()
block|{
name|section
operator|=
literal|null
expr_stmt|;
name|processableTokensIterator
operator|=
literal|null
expr_stmt|;
name|consumedIndex
operator|=
operator|-
literal|1
expr_stmt|;
name|boolean
name|foundLinkableToken
init|=
literal|false
decl_stmt|;
while|while
condition|(
operator|!
name|foundLinkableToken
operator|&&
name|sections
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|section
operator|=
name|sections
operator|.
name|next
argument_list|()
expr_stmt|;
if|if
condition|(
name|consumedSectionIndex
operator|>
name|section
operator|.
name|getStart
argument_list|()
condition|)
block|{
name|log
operator|.
name|debug
argument_list|(
literal|"> skipping {} because an other section until Index {} "
operator|+
literal|"was already processed. This is not an error, but indicates that"
operator|+
literal|"multiple NLP framewords do contribute divergating Sentence annotations"
argument_list|,
name|section
argument_list|,
name|consumedSectionIndex
argument_list|)
expr_stmt|;
continue|continue;
comment|//ignore this section
block|}
name|consumedSectionIndex
operator|=
name|section
operator|.
name|getEnd
argument_list|()
expr_stmt|;
name|SectionData
name|sectionData
init|=
operator|new
name|SectionData
argument_list|(
name|tpc
argument_list|,
name|section
argument_list|,
name|enclosedSpanTypes
argument_list|,
name|isUnicaseLanguage
argument_list|)
decl_stmt|;
comment|//TODO: It would be better to use a SectionData field instead
name|tokens
operator|=
name|sectionData
operator|.
name|getTokens
argument_list|()
expr_stmt|;
name|section
operator|=
name|sectionData
operator|.
name|section
expr_stmt|;
name|foundLinkableToken
operator|=
name|sectionData
operator|.
name|hasLinkableToken
argument_list|()
expr_stmt|;
block|}
name|processableTokensIterator
operator|=
operator|new
name|FilterIterator
argument_list|(
name|tokens
operator|.
name|iterator
argument_list|()
argument_list|,
name|PROCESSABLE_TOKEN_OREDICATE
argument_list|)
expr_stmt|;
return|return
name|foundLinkableToken
return|;
block|}
comment|/**      * Getter for the text covered by the next tokenCount tokens relative to      * {@link #token}. It uses the {@link #textCache} to lookup/store such texts.      * Given the Tokens      *<pre>      *    [This, is, an, Example]      *</pre>      * and the parameter<code>3</code> this method will return      *<pre>      *     This is an      *</pre>      * @param tokenCount the number of tokens to be included relative to       * {@link #tokenIndex}      * @return the text covered by the span start of {@link #token} to end of      * token at<code>{@link #tokenIndex}+tokenCount</code>.      */
specifier|public
name|String
name|getTokenText
parameter_list|(
name|int
name|start
parameter_list|,
name|int
name|tokenCount
parameter_list|)
block|{
name|int
name|offset
init|=
name|section
operator|.
name|getStart
argument_list|()
decl_stmt|;
return|return
name|section
operator|.
name|getSpan
argument_list|()
operator|.
name|substring
argument_list|(
name|tokens
operator|.
name|get
argument_list|(
name|start
argument_list|)
operator|.
name|token
operator|.
name|getStart
argument_list|()
operator|-
name|offset
argument_list|,
name|tokens
operator|.
name|get
argument_list|(
name|start
operator|+
operator|(
name|tokenCount
operator|-
literal|1
operator|)
argument_list|)
operator|.
name|token
operator|.
name|getEnd
argument_list|()
operator|-
name|offset
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|'['
argument_list|)
operator|.
name|append
argument_list|(
name|token
operator|.
name|index
argument_list|)
operator|.
name|append
argument_list|(
literal|','
argument_list|)
operator|.
name|append
argument_list|(
name|token
operator|.
name|token
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|"] chunk: "
argument_list|)
expr_stmt|;
if|if
condition|(
name|token
operator|.
name|inChunk
operator|==
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|"none"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|sb
operator|.
name|append
argument_list|(
name|token
operator|.
name|inChunk
operator|.
name|chunk
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|"| sentence: "
argument_list|)
expr_stmt|;
if|if
condition|(
name|section
operator|==
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|"none"
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|section
operator|.
name|getSpan
argument_list|()
operator|.
name|length
argument_list|()
operator|>
literal|45
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|section
operator|.
name|getSpan
argument_list|()
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
literal|45
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|" ..."
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|sb
operator|.
name|append
argument_list|(
name|section
operator|.
name|getSpan
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
block|}
end_class

end_unit

