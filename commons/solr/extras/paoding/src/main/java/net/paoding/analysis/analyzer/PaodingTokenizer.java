begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Copyright 2007 The Apache Software Foundation  *  * Licensed under the Apache License, Version 2.0 (the "License");  * you may not use this file except in compliance with the License.  * You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|net
operator|.
name|paoding
operator|.
name|analysis
operator|.
name|analyzer
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Reader
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|net
operator|.
name|paoding
operator|.
name|analysis
operator|.
name|analyzer
operator|.
name|impl
operator|.
name|MostWordsTokenCollector
import|;
end_import

begin_import
import|import
name|net
operator|.
name|paoding
operator|.
name|analysis
operator|.
name|knife
operator|.
name|Beef
import|;
end_import

begin_import
import|import
name|net
operator|.
name|paoding
operator|.
name|analysis
operator|.
name|knife
operator|.
name|Collector
import|;
end_import

begin_import
import|import
name|net
operator|.
name|paoding
operator|.
name|analysis
operator|.
name|knife
operator|.
name|Knife
import|;
end_import

begin_import
import|import
name|net
operator|.
name|paoding
operator|.
name|analysis
operator|.
name|knife
operator|.
name|Paoding
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|Token
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|Tokenizer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|OffsetAttribute
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|TermAttribute
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|tokenattributes
operator|.
name|TypeAttribute
import|;
end_import

begin_comment
comment|/**  * PaodingTokenizer是基于“庖丁解牛”框架的TokenStream实现，为PaodingAnalyzer使用。  *<p>  *   * @author Zhiliang Wang [qieqie.wang@gmail.com]  *   * @see Beef  * @see Knife  * @see Paoding  * @see Tokenizer  * @see PaodingAnalyzer  *   * @see Collector  * @see TokenCollector  * @see MAxTokenCollector  * @see MostWordsTokenCollector  *   * @since 1.0  */
end_comment

begin_class
specifier|public
specifier|final
class|class
name|PaodingTokenizer
extends|extends
name|Tokenizer
implements|implements
name|Collector
block|{
comment|// -------------------------------------------------
comment|/** 	 * 从input读入的总字符数 	 */
specifier|private
name|int
name|inputLength
decl_stmt|;
comment|/** 	 *  	 */
specifier|private
specifier|static
specifier|final
name|int
name|bufferLength
init|=
literal|128
decl_stmt|;
comment|/** 	 * 接收来自{@link #input}的文本字符 	 *  	 * @see #next() 	 */
specifier|private
specifier|final
name|char
index|[]
name|buffer
init|=
operator|new
name|char
index|[
name|bufferLength
index|]
decl_stmt|;
comment|/** 	 * {@link buffer}[0]在{@link #input}中的偏移 	 *  	 * @see #collect(String, int, int) 	 * @see #next() 	 */
specifier|private
name|int
name|offset
decl_stmt|;
comment|/** 	 *  	 */
specifier|private
specifier|final
name|Beef
name|beef
init|=
operator|new
name|Beef
argument_list|(
name|buffer
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
decl_stmt|;
comment|/** 	 *  	 */
specifier|private
name|int
name|dissected
decl_stmt|;
comment|/** 	 * 用于分解beef中的文本字符，由PaodingAnalyzer提供 	 *  	 * @see #next() 	 */
specifier|private
name|Knife
name|knife
decl_stmt|;
comment|/** 	 *  	 */
specifier|private
name|TokenCollector
name|tokenCollector
decl_stmt|;
comment|/** 	 * tokens迭代器，用于next()方法顺序读取tokens中的Token对象 	 *  	 * @see #tokens 	 * @see #next() 	 */
specifier|private
name|Iterator
argument_list|<
name|Token
argument_list|>
name|tokenIteractor
decl_stmt|;
specifier|private
name|TermAttribute
name|termAtt
decl_stmt|;
specifier|private
name|OffsetAttribute
name|offsetAtt
decl_stmt|;
specifier|private
name|TypeAttribute
name|typeAtt
decl_stmt|;
comment|// -------------------------------------------------
comment|/** 	 *  	 * @param input 	 * @param knife 	 * @param tokenCollector 	 */
specifier|public
name|PaodingTokenizer
parameter_list|(
name|Reader
name|input
parameter_list|,
name|Knife
name|knife
parameter_list|,
name|TokenCollector
name|tokenCollector
parameter_list|)
block|{
name|this
operator|.
name|input
operator|=
name|input
expr_stmt|;
name|this
operator|.
name|knife
operator|=
name|knife
expr_stmt|;
name|this
operator|.
name|tokenCollector
operator|=
name|tokenCollector
expr_stmt|;
name|init
argument_list|()
expr_stmt|;
block|}
specifier|private
name|void
name|init
parameter_list|()
block|{
name|termAtt
operator|=
name|addAttribute
argument_list|(
name|TermAttribute
operator|.
name|class
argument_list|)
expr_stmt|;
name|offsetAtt
operator|=
name|addAttribute
argument_list|(
name|OffsetAttribute
operator|.
name|class
argument_list|)
expr_stmt|;
name|typeAtt
operator|=
name|addAttribute
argument_list|(
name|TypeAttribute
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
comment|// -------------------------------------------------
specifier|public
name|TokenCollector
name|getTokenCollector
parameter_list|()
block|{
return|return
name|tokenCollector
return|;
block|}
specifier|public
name|void
name|setTokenCollector
parameter_list|(
name|TokenCollector
name|tokenCollector
parameter_list|)
block|{
name|this
operator|.
name|tokenCollector
operator|=
name|tokenCollector
expr_stmt|;
block|}
comment|// -------------------------------------------------
specifier|public
name|void
name|collect
parameter_list|(
name|String
name|word
parameter_list|,
name|int
name|offset
parameter_list|,
name|int
name|end
parameter_list|)
block|{
name|tokenCollector
operator|.
name|collect
argument_list|(
name|word
argument_list|,
name|this
operator|.
name|offset
operator|+
name|offset
argument_list|,
name|this
operator|.
name|offset
operator|+
name|end
argument_list|)
expr_stmt|;
block|}
comment|// -------------------------------------------------
specifier|public
name|int
name|getInputLength
parameter_list|()
block|{
return|return
name|inputLength
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|incrementToken
parameter_list|()
throws|throws
name|IOException
block|{
comment|// 已经穷尽tokensIteractor的Token对象，则继续请求reader流入数据
while|while
condition|(
name|tokenIteractor
operator|==
literal|null
operator|||
operator|!
name|tokenIteractor
operator|.
name|hasNext
argument_list|()
condition|)
block|{
comment|// System.out.println(dissected);
name|int
name|read
init|=
literal|0
decl_stmt|;
name|int
name|remainning
init|=
operator|-
literal|1
decl_stmt|;
comment|// 重新从reader读入字符前，buffer中还剩下的字符数，负数表示当前暂不需要从reader中读入字符
if|if
condition|(
name|dissected
operator|>=
name|beef
operator|.
name|length
argument_list|()
condition|)
block|{
name|remainning
operator|=
literal|0
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|dissected
operator|<
literal|0
condition|)
block|{
name|remainning
operator|=
name|bufferLength
operator|+
name|dissected
expr_stmt|;
block|}
if|if
condition|(
name|remainning
operator|>=
literal|0
condition|)
block|{
if|if
condition|(
name|remainning
operator|>
literal|0
condition|)
block|{
name|System
operator|.
name|arraycopy
argument_list|(
name|buffer
argument_list|,
operator|-
name|dissected
argument_list|,
name|buffer
argument_list|,
literal|0
argument_list|,
name|remainning
argument_list|)
expr_stmt|;
block|}
name|read
operator|=
name|input
operator|.
name|read
argument_list|(
name|buffer
argument_list|,
name|remainning
argument_list|,
name|bufferLength
operator|-
name|remainning
argument_list|)
expr_stmt|;
name|inputLength
operator|+=
name|read
expr_stmt|;
name|int
name|charCount
init|=
name|remainning
operator|+
name|read
decl_stmt|;
if|if
condition|(
name|charCount
operator|<
literal|0
condition|)
block|{
comment|// reader已尽，按接口next()要求返回null.
return|return
literal|false
return|;
block|}
if|if
condition|(
name|charCount
operator|<
name|bufferLength
condition|)
block|{
name|buffer
index|[
name|charCount
operator|++
index|]
operator|=
literal|0
expr_stmt|;
block|}
comment|// 构造“牛”，并使用knife“解”之
name|beef
operator|.
name|set
argument_list|(
literal|0
argument_list|,
name|charCount
argument_list|)
expr_stmt|;
name|offset
operator|+=
name|Math
operator|.
name|abs
argument_list|(
name|dissected
argument_list|)
expr_stmt|;
comment|// offset -= remainning;
name|dissected
operator|=
literal|0
expr_stmt|;
block|}
name|dissected
operator|=
name|knife
operator|.
name|dissect
argument_list|(
operator|(
name|Collector
operator|)
name|this
argument_list|,
name|beef
argument_list|,
name|dissected
argument_list|)
expr_stmt|;
comment|// offset += read;// !!!
name|tokenIteractor
operator|=
name|tokenCollector
operator|.
name|iterator
argument_list|()
expr_stmt|;
block|}
comment|// 返回tokensIteractor下一个Token对象
name|Token
name|token
init|=
name|tokenIteractor
operator|.
name|next
argument_list|()
decl_stmt|;
name|termAtt
operator|.
name|setTermBuffer
argument_list|(
name|token
operator|.
name|term
argument_list|()
argument_list|)
expr_stmt|;
name|offsetAtt
operator|.
name|setOffset
argument_list|(
name|correctOffset
argument_list|(
name|token
operator|.
name|startOffset
argument_list|()
argument_list|)
argument_list|,
name|correctOffset
argument_list|(
name|token
operator|.
name|endOffset
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|typeAtt
operator|.
name|setType
argument_list|(
literal|"paoding"
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|reset
parameter_list|()
throws|throws
name|IOException
block|{
name|super
operator|.
name|reset
argument_list|()
expr_stmt|;
name|offset
operator|=
literal|0
expr_stmt|;
name|inputLength
operator|=
literal|0
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|reset
parameter_list|(
name|Reader
name|input
parameter_list|)
throws|throws
name|IOException
block|{
name|super
operator|.
name|reset
argument_list|(
name|input
argument_list|)
expr_stmt|;
name|reset
argument_list|()
expr_stmt|;
block|}
block|}
end_class

end_unit

