begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_package
package|package
name|eu
operator|.
name|iksproject
operator|.
name|rick
operator|.
name|indexing
operator|.
name|rdf
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Dictionary
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Enumeration
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|zip
operator|.
name|GZIPInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|compress
operator|.
name|archivers
operator|.
name|zip
operator|.
name|ZipArchiveEntry
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|compress
operator|.
name|archivers
operator|.
name|zip
operator|.
name|ZipFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|compress
operator|.
name|compressors
operator|.
name|bzip2
operator|.
name|BZip2CompressorInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|openjena
operator|.
name|riot
operator|.
name|Lang
import|;
end_import

begin_import
import|import
name|org
operator|.
name|openjena
operator|.
name|riot
operator|.
name|RiotReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|datatypes
operator|.
name|BaseDatatype
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|datatypes
operator|.
name|DatatypeFormatException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|datatypes
operator|.
name|RDFDatatype
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|datatypes
operator|.
name|xsd
operator|.
name|XSDDateTime
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|datatypes
operator|.
name|xsd
operator|.
name|XSDDuration
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|graph
operator|.
name|Node
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|graph
operator|.
name|Triple
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|graph
operator|.
name|impl
operator|.
name|LiteralLabel
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|query
operator|.
name|Query
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|query
operator|.
name|QueryExecutionFactory
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|query
operator|.
name|QueryFactory
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|query
operator|.
name|QuerySolution
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|query
operator|.
name|ResultSet
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|query
operator|.
name|Syntax
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|rdf
operator|.
name|model
operator|.
name|Literal
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|rdf
operator|.
name|model
operator|.
name|Model
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|rdf
operator|.
name|model
operator|.
name|ModelFactory
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|rdf
operator|.
name|model
operator|.
name|RDFNode
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|tdb
operator|.
name|TDBFactory
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|tdb
operator|.
name|TDBLoader
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|tdb
operator|.
name|base
operator|.
name|file
operator|.
name|Location
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|tdb
operator|.
name|store
operator|.
name|DatasetGraphTDB
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|tdb
operator|.
name|store
operator|.
name|bulkloader
operator|.
name|BulkLoader
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|tdb
operator|.
name|store
operator|.
name|bulkloader
operator|.
name|Destination
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|tdb
operator|.
name|store
operator|.
name|bulkloader
operator|.
name|LoadMonitor
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|tdb
operator|.
name|store
operator|.
name|bulkloader
operator|.
name|LoaderNodeTupleTable
import|;
end_import

begin_import
import|import
name|com
operator|.
name|hp
operator|.
name|hpl
operator|.
name|jena
operator|.
name|util
operator|.
name|iterator
operator|.
name|ExtendedIterator
import|;
end_import

begin_import
import|import
name|eu
operator|.
name|iksproject
operator|.
name|rick
operator|.
name|core
operator|.
name|mapping
operator|.
name|DefaultFieldMapperImpl
import|;
end_import

begin_import
import|import
name|eu
operator|.
name|iksproject
operator|.
name|rick
operator|.
name|core
operator|.
name|mapping
operator|.
name|FieldMappingUtils
import|;
end_import

begin_import
import|import
name|eu
operator|.
name|iksproject
operator|.
name|rick
operator|.
name|core
operator|.
name|mapping
operator|.
name|ValueConverterFactory
import|;
end_import

begin_import
import|import
name|eu
operator|.
name|iksproject
operator|.
name|rick
operator|.
name|core
operator|.
name|site
operator|.
name|CacheUtils
import|;
end_import

begin_import
import|import
name|eu
operator|.
name|iksproject
operator|.
name|rick
operator|.
name|core
operator|.
name|utils
operator|.
name|ModelUtils
import|;
end_import

begin_import
import|import
name|eu
operator|.
name|iksproject
operator|.
name|rick
operator|.
name|servicesapi
operator|.
name|mapping
operator|.
name|FieldMapper
import|;
end_import

begin_import
import|import
name|eu
operator|.
name|iksproject
operator|.
name|rick
operator|.
name|servicesapi
operator|.
name|mapping
operator|.
name|FieldMapping
import|;
end_import

begin_import
import|import
name|eu
operator|.
name|iksproject
operator|.
name|rick
operator|.
name|servicesapi
operator|.
name|model
operator|.
name|Representation
import|;
end_import

begin_import
import|import
name|eu
operator|.
name|iksproject
operator|.
name|rick
operator|.
name|servicesapi
operator|.
name|model
operator|.
name|ValueFactory
import|;
end_import

begin_import
import|import
name|eu
operator|.
name|iksproject
operator|.
name|rick
operator|.
name|servicesapi
operator|.
name|model
operator|.
name|rdf
operator|.
name|RdfResourceEnum
import|;
end_import

begin_import
import|import
name|eu
operator|.
name|iksproject
operator|.
name|rick
operator|.
name|servicesapi
operator|.
name|yard
operator|.
name|Yard
import|;
end_import

begin_import
import|import
name|eu
operator|.
name|iksproject
operator|.
name|rick
operator|.
name|servicesapi
operator|.
name|yard
operator|.
name|YardException
import|;
end_import

begin_comment
comment|/**  * This Class indexes Entities based on Information provided in a RDF Graph  *   * Features (currently Brainstorming)<ul>  *<li> Parse also Archive Files (nobody likes to extract such stuff)  *<li> Parse different RDF formats (esay with Clerezza)  *<li> Replace/Append Mode: In replace Mode existing data for an Entity are  *      replaced in the Yard. In the Append Mode first Data for a found Entity  *      are loaded and than new data are added. The Append Mode is important when  *      working with dumps that split up data not by entity but by properties  *<li> Support for the RICK Representation Mapping Infrastructure (currently  *      this means using the {@link FieldMapper}  *<li> Support for filtering Entities based on rdf:type (will be in future   *      version supported by the RICK Representation Mapping Infrastructure)  *<li> Entity Rank support: It is not feasible to calculate the rankings in a  *      generic fashion. Therefore this implementation supports two different  *      ways. First it uses {@link RdfResourceEnum#signRank} relations in the  *      parsed RDF Data and secondly it allows to provide entity rank information  *      by parsing a map with the id as key and the rank as value by using the  *      {@link #KEY_ENTITY_RANKINGS} in the configuration. Mappings parsed by the  *      map will override mappings in the RDF data.  *<li>  *<li>  *<li>  *</ul>  *  Implementation Notes:<ul>  *<li> The Idea was to use the Clerezza TdbTcProvider and the JenaParserProvider  *      outside of an OSGI Environment and than use the Clerezza Yard to  *      access Resources to be indexed directly as Representations to perform  *      the field mappings by using the parsed {@link FieldMapper}.  *<li> I am a bit worried with the ParsingProvide} because the interface  *      allows no streaming. One needs to check if this causes problems for  *      very big RDF files.<br>  *    	After looking into the source code of Clerezza, I am even more worried!  *      The Parser creates an SimpleMGraph and wrapped it with an  *      Jena Adapter. Than all Triples are parsed into memory. So I do not only  *      have the triples in memory but also the instances of the jena adapter.  *<li> Maybe it is better to directly use Jena, because Clerezza does not support  *      COUNT(..) for SPARQL queries. Without that feature it would be hard to  *      support page ranks!<br>  *      Maybe I can use both, because using a Clerezza wrapper over Jena would  *      have the advantage to directly use the ClerezzaYard for creating  *      RDF Representations for resource to be indexed!<br>  *      Parsing and especially SPARQL queries would be better to do directly  *      via the Jena API!<p>  *      This should be no problem, because indexing is a read only operation!  *<li> However based on this findings I plan now to implement the loading of the   *      RDF data to directly use the Jena TDB API because Clerezza seams not to  *      be designed to handle the loading of RDF datasets that can not be   *      kept in memory.<br>  *</ul>  *   * @author Rupert Westenthaler  * @author ogrisel (as parts of that code is taken from iks-autotagger)  *  */
end_comment

begin_class
specifier|public
class|class
name|RdfIndexer
block|{
comment|/** 	 * The indexing mode defines if the RDF data are appended to existing 	 * {@link Representation}s in the target {@link Yard} or if {@link Representation} 	 * are replaced with RDF data used for indexing! 	 * @author Rupert Westenthaler 	 * 	 */
specifier|public
specifier|static
enum|enum
name|IndexingMode
block|{
name|REPLACE
block|,
name|APPEND
block|}
specifier|public
specifier|static
specifier|final
name|String
name|RDF_XML
init|=
literal|"application/rdf+xml"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|TURTLE
init|=
literal|"text/turtle"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|X_TURTLE
init|=
literal|"application/x-turtle"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|N_TRIPLE
init|=
literal|"text/rdf+nt"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|N3
init|=
literal|"text/rdf+n3"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|RDF_JSON
init|=
literal|"application/rdf+json"
decl_stmt|;
comment|//both html and xhtml can be rdf formats with RDFa
specifier|public
specifier|static
specifier|final
name|String
name|XHTML
init|=
literal|"application/xhtml+xml"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|HTML
init|=
literal|"text/html"
decl_stmt|;
specifier|protected
specifier|static
specifier|final
name|String
name|resourceQuery
decl_stmt|;
static|static
block|{
name|StringBuilder
name|cqb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|cqb
operator|.
name|append
argument_list|(
literal|"SELECT ?field ?value "
argument_list|)
expr_stmt|;
comment|//, count(distinct ?incoming) AS ?count ");
name|cqb
operator|.
name|append
argument_list|(
literal|"{ "
argument_list|)
expr_stmt|;
name|cqb
operator|.
name|append
argument_list|(
literal|"<%s> ?field ?value ."
argument_list|)
expr_stmt|;
comment|//	    cqb.append("  OPTIONAL {?incoming ?relationship<%s> . } .");
name|cqb
operator|.
name|append
argument_list|(
literal|"} "
argument_list|)
expr_stmt|;
name|resourceQuery
operator|=
name|cqb
operator|.
name|toString
argument_list|()
expr_stmt|;
block|}
name|Logger
name|log
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|RdfIndexer
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/** 	 * Key used to parse the Yard used for indexing 	 */
specifier|public
specifier|static
specifier|final
name|String
name|KEY_YARD
init|=
literal|"eu.iksproject.rick.indexing.yard"
decl_stmt|;
comment|/** 	 * Key used to parse reference(s) to the RDF files to be indexed!<p> 	 * This supports both single values as well as {@link Iterable}s over several 	 * values. All parsed sources are loaded within one TripleStore and are 	 * indexed at once! Use several {@link RdfIndexer} instances to index them 	 * one after the other. 	 */
specifier|public
specifier|static
specifier|final
name|String
name|KEY_RDF_FILES
init|=
literal|"eu.iksproject.rick.indexing.rdf.rdfFiles"
decl_stmt|;
comment|/** 	 * Key used to configure the fieldMappings used to determine what properties 	 * are indexed for entities. Values must implement {@link Iterable} and the 	 * {@link Object#toString()} is used to parse the different mappings. 	 */
specifier|public
specifier|static
specifier|final
name|String
name|KEY_FIELD_MAPPINGS
init|=
literal|"eu.iksproject.rick.indexing.rdf.fieldMappings"
decl_stmt|;
comment|/** 	 * Key used to configure the directory to store RDF data needed during the 	 * indexing process. This data might be reused when resuming an indexing 	 * process. 	 */
specifier|public
specifier|static
specifier|final
name|String
name|KEY_RDF_STORE_DIR
init|=
literal|"eu.iksproject.rick.indexing.rdf.indexingDir"
decl_stmt|;
comment|/** 	 * Key used to configure the name of the model used to store the parsed 	 * RDF data before the indexing process. Parsing this name can be used to 	 * resume indexing based on previously parsed RDF data. 	 */
specifier|public
specifier|static
specifier|final
name|String
name|KEY_MODEL_NAME
init|=
literal|"eu.iksproject.rick.indexing.rdf.modelName"
decl_stmt|;
comment|/** 	 * Key used to parse the Iterable over all the rdf:types to be indexed. If 	 * not parsed or set to<code>null</code> or an empty list, than all Resources are 	 * accepted! 	 * The {@link Object#toString()} method is used on elements to get the actual type! 	 */
specifier|public
specifier|static
specifier|final
name|String
name|KEY_RDF_TYPES
init|=
literal|"eu.iksproject.rick.indexing.rdf.indexedTypes"
decl_stmt|;
comment|/** 	 * Key used to parse the indexing mode. Values should be of instance {@link IndexingMode} 	 * or the {@link Object#toString()} value should be a member of this enum! 	 */
specifier|public
specifier|static
specifier|final
name|String
name|KEY_INDEXING_MODE
init|=
literal|"eu.iksproject.rick.indexing.rdf.indexingMode"
decl_stmt|;
comment|/** 	 * If<code>true</code> than no RDF data are loaded. Instead it is assumed, that 	 * the Graph of the parsed {@link #KEY_MODEL_NAME} already contains all the needed 	 * data!<p> 	 * This can be useful if one first wants to index rdf:type A and than rdf:type B 	 * based on the same set of data 	 */
specifier|public
specifier|static
specifier|final
name|String
name|KEY_SKIP_READ
init|=
literal|"eu.iksproject.rick.indexing.rdf.skipRead"
decl_stmt|;
comment|/** 	 * The number of {@link Representation}s stored at once in the SolrYard! 	 */
specifier|public
specifier|static
specifier|final
name|String
name|KEY_CHUNK_SIZE
init|=
literal|"eu.iksproject.rick.indexing.rdf.chunkSize"
decl_stmt|;
comment|/** 	 * Can be used to parse a map with {@link String} entity id, {@link Float} rank 	 * for entities.<p> 	 * Such values are added to Representations for the {@link RdfResourceEnum#signRank} 	 * field. 	 */
specifier|public
specifier|static
specifier|final
name|String
name|KEY_ENTITY_RANKINGS
init|=
literal|"eu.iksproject.rick.indexing.rdf.entityRankings"
decl_stmt|;
comment|/** 	 * Can be used to activate ignoring of Entities without a page rank 	 */
specifier|public
specifier|static
specifier|final
name|String
name|KEY_IGNORE_ENTITIES_WITHOUT_ENTITY_RANKING
init|=
literal|"eu.iksproject.rick.indexing.rdf.ignoreEntitiesWithoutRankings"
decl_stmt|;
comment|/** 	 * If set to a value>= 0 this is used to exclude Entities with a lower or  	 * missing entity rank 	 */
specifier|public
specifier|static
specifier|final
name|String
name|KEY_REQUIRED_ENTITY_RANKING
init|=
literal|"eu.iksproject.rick.indexing.rdf.requiredRanking"
decl_stmt|;
comment|/** 	 * The rank for entities with a missing rank. This takes only effect if 	 * {@link #KEY_IGNORE_ENTITIES_WITHOUT_ENTITY_RANKING} is set to<code>false</code> 	 * (the default) 	 */
specifier|public
specifier|static
specifier|final
name|String
name|KEY_DEFAULT_ENTITY_RANKING
init|=
literal|"eu.iksproject.rick.indexing.rdf.defaultRanking"
decl_stmt|;
comment|/** 	 * Expert only: This allows to enable indexing based on the keys in the map parsed with the 	 * entity rankings. This will only index entities that are keys in that map. 	 * If no Map is parsed by {@link #KEY_ENTITY_RANKINGS}, than activating this mode 	 * will not be successful and a warning will be written.<p> 	 * This mode is about 50% slower than the usual indexing mode. Therefore this 	 * mode makes only sense id less than 50% of the entities are indexed. 	 */
specifier|public
specifier|static
specifier|final
name|String
name|KEY_ENTITY_RANKING_BASED_INDEXING_MODE
init|=
literal|"eu.iksproject.rick.indexing.rdf.rankingBasedIndexingMode"
decl_stmt|;
comment|/** 	 * The resume Mode first checks if a Resource is already present in the parsed 	 * Yard. If this is the case, than the representation is not indexes again.<p> 	 * This mode is intended to resume indexing after stopping a previous call before 	 * finished. The default value = false. 	 */
specifier|public
specifier|static
specifier|final
name|String
name|KEY_RESUME_MODE
init|=
literal|"eu.iksproject.rick.indexing.rdf.resumeMode"
decl_stmt|;
specifier|private
specifier|final
name|IndexingMode
name|indexingMode
decl_stmt|;
specifier|private
specifier|final
name|Yard
name|yard
decl_stmt|;
specifier|private
specifier|final
name|ValueFactory
name|vf
decl_stmt|;
specifier|private
specifier|final
name|List
argument_list|<
name|File
argument_list|>
name|rdfFiles
decl_stmt|;
specifier|private
specifier|final
name|File
name|indexingDir
decl_stmt|;
specifier|private
specifier|final
name|String
name|modelName
decl_stmt|;
comment|//	private final ParsingProvider parser = new JenaParserProvider();
comment|//private final WeightedTcProvider provider;
specifier|private
specifier|final
name|FieldMapper
name|mapper
decl_stmt|;
specifier|private
specifier|final
name|Set
argument_list|<
name|String
argument_list|>
name|types
decl_stmt|;
comment|//private MGraph indexingGraph;
specifier|private
specifier|final
name|DatasetGraphTDB
name|indexingDataset
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|skipRead
decl_stmt|;
specifier|private
name|Location
name|modelLocation
decl_stmt|;
specifier|private
name|int
name|indexingChunkSize
init|=
literal|1000
decl_stmt|;
comment|//vars for entity rankings
specifier|private
name|Map
argument_list|<
name|String
argument_list|,
name|Float
argument_list|>
name|entityRankings
init|=
literal|null
decl_stmt|;
specifier|private
name|boolean
name|ignoreEntitiesWithoutRank
init|=
literal|false
decl_stmt|;
specifier|private
name|float
name|defaultEntityRanking
init|=
operator|-
literal|1
decl_stmt|;
specifier|private
name|String
name|entityRankingField
init|=
name|RdfResourceEnum
operator|.
name|signRank
operator|.
name|getUri
argument_list|()
decl_stmt|;
specifier|private
name|float
name|minimumRequiredEntityRanking
init|=
operator|-
literal|1
decl_stmt|;
specifier|private
name|boolean
name|rankingMode
decl_stmt|;
specifier|private
name|boolean
name|resumeMode
decl_stmt|;
specifier|public
name|RdfIndexer
parameter_list|(
name|Dictionary
argument_list|<
name|String
argument_list|,
name|Object
argument_list|>
name|config
parameter_list|)
block|{
name|this
operator|.
name|yard
operator|=
operator|(
name|Yard
operator|)
name|config
operator|.
name|get
argument_list|(
name|KEY_YARD
argument_list|)
expr_stmt|;
if|if
condition|(
name|yard
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Parsed config MUST CONTAIN a Yard. Use the key "
operator|+
name|KEY_YARD
operator|+
literal|" to parse the YardInstance used to store the geonames.org index!"
argument_list|)
throw|;
block|}
else|else
block|{
name|log
operator|.
name|info
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Using Yard %s (id=%s) to index parsed RDF data"
argument_list|,
name|yard
operator|.
name|getName
argument_list|()
argument_list|,
name|yard
operator|.
name|getId
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|vf
operator|=
name|yard
operator|.
name|getValueFactory
argument_list|()
expr_stmt|;
name|Object
name|rdfFiles
init|=
name|config
operator|.
name|get
argument_list|(
name|KEY_RDF_FILES
argument_list|)
decl_stmt|;
if|if
condition|(
name|rdfFiles
operator|instanceof
name|Iterable
argument_list|<
name|?
argument_list|>
condition|)
block|{
name|this
operator|.
name|rdfFiles
operator|=
operator|new
name|ArrayList
argument_list|<
name|File
argument_list|>
argument_list|()
expr_stmt|;
for|for
control|(
name|Object
name|value
operator|:
operator|(
name|Iterable
argument_list|<
name|?
argument_list|>
operator|)
name|rdfFiles
control|)
block|{
name|this
operator|.
name|rdfFiles
operator|.
name|add
argument_list|(
name|checkFile
argument_list|(
name|value
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|this
operator|.
name|rdfFiles
operator|=
name|Collections
operator|.
name|singletonList
argument_list|(
name|checkFile
argument_list|(
name|rdfFiles
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|Object
name|indexingDir
init|=
name|config
operator|.
name|get
argument_list|(
name|KEY_RDF_STORE_DIR
argument_list|)
decl_stmt|;
if|if
condition|(
name|indexingDir
operator|==
literal|null
condition|)
block|{
name|indexingDir
operator|=
literal|"indexingData"
expr_stmt|;
name|config
operator|.
name|put
argument_list|(
name|KEY_RDF_STORE_DIR
argument_list|,
name|indexingDir
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|indexingDir
operator|=
name|checkFile
argument_list|(
name|indexingDir
operator|.
name|toString
argument_list|()
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|Object
name|modelName
init|=
name|config
operator|.
name|get
argument_list|(
name|KEY_MODEL_NAME
argument_list|)
decl_stmt|;
if|if
condition|(
name|modelName
operator|==
literal|null
condition|)
block|{
name|modelName
operator|=
literal|"indexingModel-"
operator|+
name|ModelUtils
operator|.
name|randomUUID
argument_list|()
operator|.
name|toString
argument_list|()
expr_stmt|;
name|config
operator|.
name|put
argument_list|(
name|KEY_MODEL_NAME
argument_list|,
name|modelName
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|modelName
operator|=
name|modelName
operator|.
name|toString
argument_list|()
expr_stmt|;
comment|//init the types!
name|Iterable
argument_list|<
name|?
argument_list|>
name|types
init|=
operator|(
name|Iterable
argument_list|<
name|?
argument_list|>
operator|)
name|config
operator|.
name|get
argument_list|(
name|KEY_RDF_TYPES
argument_list|)
decl_stmt|;
if|if
condition|(
name|types
operator|!=
literal|null
condition|)
block|{
name|Set
argument_list|<
name|String
argument_list|>
name|typeSet
init|=
operator|new
name|HashSet
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|Object
name|type
range|:
name|types
control|)
block|{
if|if
condition|(
name|type
operator|!=
literal|null
condition|)
block|{
name|typeSet
operator|.
name|add
argument_list|(
name|type
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|log
operator|.
name|info
argument_list|(
literal|"  - adding Resoures with rdf:type "
operator|+
name|type
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|typeSet
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|log
operator|.
name|info
argument_list|(
literal|"  - adding all Types (no rdf:type based restriction for RDF Reseource present)"
argument_list|)
expr_stmt|;
name|this
operator|.
name|types
operator|=
literal|null
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|types
operator|=
name|typeSet
expr_stmt|;
block|}
block|}
else|else
block|{
name|log
operator|.
name|info
argument_list|(
literal|"  - adding all Types (no rdf:type based restriction for RDF Reseource present)"
argument_list|)
expr_stmt|;
name|this
operator|.
name|types
operator|=
literal|null
expr_stmt|;
comment|//null or an iterable with one or more elements!
block|}
comment|//init the indexing mode
name|Object
name|indexingMode
init|=
name|config
operator|.
name|get
argument_list|(
name|KEY_INDEXING_MODE
argument_list|)
decl_stmt|;
if|if
condition|(
name|indexingMode
operator|==
literal|null
condition|)
block|{
name|this
operator|.
name|indexingMode
operator|=
name|IndexingMode
operator|.
name|REPLACE
expr_stmt|;
comment|//default to replace
block|}
elseif|else
if|if
condition|(
name|indexingMode
operator|instanceof
name|IndexingMode
condition|)
block|{
name|this
operator|.
name|indexingMode
operator|=
operator|(
name|IndexingMode
operator|)
name|indexingMode
expr_stmt|;
block|}
else|else
block|{
try|try
block|{
name|this
operator|.
name|indexingMode
operator|=
name|IndexingMode
operator|.
name|valueOf
argument_list|(
name|indexingMode
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IllegalArgumentException
name|e
parameter_list|)
block|{
comment|//catch and re-throw with a better message!
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Values of KEY \"%s\" MUST BE of Type %s or the toString() value MUST BE a member of this Enumeration. If the Key is missing %s is used!"
argument_list|,
name|KEY_INDEXING_MODE
argument_list|,
name|IndexingMode
operator|.
name|class
argument_list|,
name|IndexingMode
operator|.
name|REPLACE
argument_list|)
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|//init the fieldMapper
name|Iterable
argument_list|<
name|?
argument_list|>
name|mappings
init|=
operator|(
name|Iterable
argument_list|<
name|?
argument_list|>
operator|)
name|config
operator|.
name|get
argument_list|(
name|KEY_FIELD_MAPPINGS
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|FieldMapping
argument_list|>
name|fieldMappings
decl_stmt|;
if|if
condition|(
name|mappings
operator|!=
literal|null
condition|)
block|{
name|fieldMappings
operator|=
operator|new
name|ArrayList
argument_list|<
name|FieldMapping
argument_list|>
argument_list|()
expr_stmt|;
for|for
control|(
name|Object
name|mappingString
range|:
name|mappings
control|)
block|{
if|if
condition|(
name|mappingString
operator|!=
literal|null
condition|)
block|{
name|FieldMapping
name|fieldMapping
init|=
name|FieldMappingUtils
operator|.
name|parseFieldMapping
argument_list|(
name|mappingString
operator|.
name|toString
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|fieldMapping
operator|!=
literal|null
condition|)
block|{
name|fieldMappings
operator|.
name|add
argument_list|(
name|fieldMapping
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
operator|!
name|fieldMappings
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|this
operator|.
name|mapper
operator|=
operator|new
name|DefaultFieldMapperImpl
argument_list|(
name|ValueConverterFactory
operator|.
name|getInstance
argument_list|(
name|vf
argument_list|)
argument_list|)
expr_stmt|;
for|for
control|(
name|FieldMapping
name|mapping
range|:
name|fieldMappings
control|)
block|{
name|mapper
operator|.
name|addMapping
argument_list|(
name|mapping
argument_list|)
expr_stmt|;
block|}
comment|//we need to add a mapping for the field rankings (if a mapper is present)
name|mapper
operator|.
name|addMapping
argument_list|(
operator|new
name|FieldMapping
argument_list|(
name|this
operator|.
name|entityRankingField
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|mapper
operator|=
literal|null
expr_stmt|;
block|}
block|}
else|else
block|{
name|this
operator|.
name|mapper
operator|=
literal|null
expr_stmt|;
block|}
name|File
name|modelDir
init|=
operator|new
name|File
argument_list|(
name|this
operator|.
name|indexingDir
argument_list|,
name|this
operator|.
name|modelName
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|modelDir
operator|.
name|exists
argument_list|()
condition|)
block|{
name|modelDir
operator|.
name|mkdir
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|modelDir
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"A directory for %s already exists but is not a directory!"
argument_list|,
name|modelDir
operator|.
name|getAbsoluteFile
argument_list|()
argument_list|)
argument_list|)
throw|;
block|}
comment|//else exists and is a dir -> nothing to do
name|Object
name|skipRead
init|=
name|config
operator|.
name|get
argument_list|(
name|KEY_SKIP_READ
argument_list|)
decl_stmt|;
if|if
condition|(
name|skipRead
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|skipRead
operator|instanceof
name|Boolean
condition|)
block|{
name|this
operator|.
name|skipRead
operator|=
operator|(
operator|(
name|Boolean
operator|)
name|skipRead
operator|)
operator|.
name|booleanValue
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|skipRead
operator|=
name|Boolean
operator|.
name|parseBoolean
argument_list|(
name|skipRead
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|this
operator|.
name|skipRead
operator|=
literal|false
expr_stmt|;
block|}
name|Integer
name|chunkSize
init|=
operator|(
name|Integer
operator|)
name|config
operator|.
name|get
argument_list|(
name|KEY_CHUNK_SIZE
argument_list|)
decl_stmt|;
if|if
condition|(
name|chunkSize
operator|!=
literal|null
operator|&&
name|chunkSize
operator|>
literal|0
condition|)
block|{
name|this
operator|.
name|indexingChunkSize
operator|=
name|chunkSize
expr_stmt|;
block|}
comment|//else use default value of 1000
name|this
operator|.
name|modelLocation
operator|=
operator|new
name|Location
argument_list|(
name|modelDir
operator|.
name|getAbsolutePath
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|indexingDataset
operator|=
name|TDBFactory
operator|.
name|createDatasetGraph
argument_list|(
name|modelLocation
argument_list|)
expr_stmt|;
comment|//this.provider = new IndexingModelProvider(this.indexingDir);
comment|//init entity Ranking
try|try
block|{
name|this
operator|.
name|entityRankings
operator|=
operator|(
name|Map
argument_list|<
name|String
argument_list|,
name|Float
argument_list|>
operator|)
name|config
operator|.
name|get
argument_list|(
name|KEY_ENTITY_RANKINGS
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|RuntimeException
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"Parsed Entity Rankings MUST use the form Map<String,Float>"
argument_list|)
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
name|Object
name|ignore
init|=
name|config
operator|.
name|get
argument_list|(
name|KEY_IGNORE_ENTITIES_WITHOUT_ENTITY_RANKING
argument_list|)
decl_stmt|;
if|if
condition|(
name|ignore
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|ignore
operator|instanceof
name|Boolean
condition|)
block|{
name|this
operator|.
name|ignoreEntitiesWithoutRank
operator|=
operator|(
name|Boolean
operator|)
name|ignore
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|ignoreEntitiesWithoutRank
operator|=
name|Boolean
operator|.
name|parseBoolean
argument_list|(
name|ignore
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|Object
name|defaultRankingObject
init|=
name|config
operator|.
name|get
argument_list|(
name|KEY_DEFAULT_ENTITY_RANKING
argument_list|)
decl_stmt|;
if|if
condition|(
name|defaultRankingObject
operator|!=
literal|null
condition|)
block|{
name|float
name|defaultranking
init|=
operator|-
literal|1
decl_stmt|;
if|if
condition|(
name|defaultRankingObject
operator|instanceof
name|Float
condition|)
block|{
name|defaultranking
operator|=
operator|(
name|Float
operator|)
name|defaultRankingObject
expr_stmt|;
block|}
else|else
block|{
try|try
block|{
name|defaultranking
operator|=
name|Float
operator|.
name|parseFloat
argument_list|(
name|defaultRankingObject
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"Unable to parse Float value for the Default Entity Ranking from the value parsed for the KEY_DEFAULT_ENTITY_RANKING key (value: "
operator|+
name|defaultRankingObject
operator|+
literal|")"
argument_list|)
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
block|}
name|this
operator|.
name|defaultEntityRanking
operator|=
name|defaultranking
expr_stmt|;
block|}
name|Object
name|minimumRequiredRankingObject
init|=
name|config
operator|.
name|get
argument_list|(
name|KEY_REQUIRED_ENTITY_RANKING
argument_list|)
decl_stmt|;
if|if
condition|(
name|minimumRequiredRankingObject
operator|!=
literal|null
condition|)
block|{
name|float
name|minRanking
init|=
operator|-
literal|1
decl_stmt|;
if|if
condition|(
name|minimumRequiredRankingObject
operator|instanceof
name|Float
condition|)
block|{
name|minRanking
operator|=
operator|(
name|Float
operator|)
name|minimumRequiredRankingObject
expr_stmt|;
block|}
else|else
block|{
try|try
block|{
name|minRanking
operator|=
name|Float
operator|.
name|parseFloat
argument_list|(
name|minimumRequiredRankingObject
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"Unable to parse Float value for the Minimum Required Entity Ranking from the value parsed for the KEY_DEFAULT_ENTITY_RANKING key (value: "
operator|+
name|minimumRequiredRankingObject
operator|+
literal|")"
argument_list|)
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|minRanking
operator|>=
literal|0
condition|)
block|{
comment|//setting a valid required ranking automatically
comment|//means that entities without a rank should be ignored!
name|this
operator|.
name|ignoreEntitiesWithoutRank
operator|=
literal|true
expr_stmt|;
block|}
name|this
operator|.
name|minimumRequiredEntityRanking
operator|=
name|minRanking
expr_stmt|;
block|}
name|Object
name|rankingMode
init|=
name|config
operator|.
name|get
argument_list|(
name|KEY_ENTITY_RANKING_BASED_INDEXING_MODE
argument_list|)
decl_stmt|;
if|if
condition|(
name|rankingMode
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|rankingMode
operator|instanceof
name|Boolean
condition|)
block|{
name|this
operator|.
name|rankingMode
operator|=
operator|(
name|Boolean
operator|)
name|rankingMode
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|rankingMode
operator|=
name|Boolean
operator|.
name|parseBoolean
argument_list|(
name|rankingMode
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|this
operator|.
name|rankingMode
operator|&&
name|this
operator|.
name|entityRankings
operator|==
literal|null
condition|)
block|{
name|log
operator|.
name|warn
argument_list|(
literal|"The Entity Ranking based Indexing Mode can not be activated if no EntityRankings are parsed! -> deactivate Ranking Mode (intertes over all Resources in the RDF Data)"
argument_list|)
expr_stmt|;
name|this
operator|.
name|rankingMode
operator|=
literal|false
expr_stmt|;
block|}
name|Object
name|resumeMode
init|=
name|config
operator|.
name|get
argument_list|(
name|KEY_RESUME_MODE
argument_list|)
decl_stmt|;
if|if
condition|(
name|resumeMode
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|resumeMode
operator|instanceof
name|Boolean
condition|)
block|{
name|this
operator|.
name|resumeMode
operator|=
operator|(
name|Boolean
operator|)
name|resumeMode
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|resumeMode
operator|=
name|Boolean
operator|.
name|parseBoolean
argument_list|(
name|resumeMode
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|this
operator|.
name|resumeMode
operator|=
literal|false
expr_stmt|;
block|}
block|}
end_class

begin_function
specifier|public
name|void
name|index
parameter_list|()
throws|throws
name|YardException
block|{
name|log
operator|.
name|info
argument_list|(
literal|"initialize ..."
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|skipRead
condition|)
block|{
name|loadRdfFiles
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|log
operator|.
name|info
argument_list|(
literal|" ... skiping loading of RDF data"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|rankingMode
condition|)
block|{
name|indexRanked
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|indexResources
argument_list|()
expr_stmt|;
block|}
name|writeCacheBaseConfiguration
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/** 	 * This Method is used to process the RDF Data if all Resource can be indexed, 	 * because it provides the best performance. Mainly because it reads everything 	 * from a single stream and therefore gives the OS the best opportunities to 	 * optimise file access. 	 * @throws YardException 	 */
end_comment

begin_function
specifier|private
name|void
name|indexResources
parameter_list|()
throws|throws
name|YardException
block|{
name|StringBuilder
name|qb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
comment|/*          * NOTES:          *  - selects all triples form the TDB store          *  - GROUP BY is not needed because iteration order is anyway based          *    on the resource (TDB uses internally a tree structure based on the          *    subject          *  - This is about tree times faster than first selecting all resource          *    and than filtering for all triples with the resource. Mainly because          *    hard disc  access is much more efficient.          */
name|qb
operator|.
name|append
argument_list|(
literal|"SELECT ?resource ?field ?value"
argument_list|)
expr_stmt|;
name|qb
operator|.
name|append
argument_list|(
literal|"{ "
argument_list|)
expr_stmt|;
name|qb
operator|.
name|append
argument_list|(
literal|" ?resource ?field ?value . "
argument_list|)
expr_stmt|;
comment|//        qb.append(" OPTIONAL { ?incoming ?relationship ?resource . } . ");
comment|//qb.append(" FILTER ( isURI(?resource) ) . ");
name|qb
operator|.
name|append
argument_list|(
literal|"} "
argument_list|)
expr_stmt|;
comment|//        qb.append("GROUP BY ?resource "); //needed because the count counts by GROUP BY
comment|//        qb.append("ORDER BY DESC ( ?count ) ");
comment|//        qb.append(String.format("OFFSET 0 LIMIT %d", maxTopResources));
name|Query
name|q
init|=
name|QueryFactory
operator|.
name|create
argument_list|(
name|qb
operator|.
name|toString
argument_list|()
argument_list|,
name|Syntax
operator|.
name|syntaxARQ
argument_list|)
decl_stmt|;
specifier|final
name|ResultSet
name|resultSet
init|=
name|QueryExecutionFactory
operator|.
name|create
argument_list|(
name|q
argument_list|,
name|indexingDataset
operator|.
name|toDataset
argument_list|()
argument_list|)
operator|.
name|execSelect
argument_list|()
decl_stmt|;
name|long
name|count
init|=
literal|0
decl_stmt|;
name|long
name|indexed
init|=
literal|0
decl_stmt|;
name|long
name|lastIndexed
init|=
literal|0
decl_stmt|;
name|long
name|stdCount
init|=
literal|0
decl_stmt|;
name|long
name|indexedStdCount
init|=
literal|0
decl_stmt|;
name|long
name|repStdCount
init|=
literal|0
decl_stmt|;
empty_stmt|;
name|long
name|start
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|long
name|startCurrent
init|=
name|start
decl_stmt|;
name|String
name|current
init|=
literal|null
decl_stmt|;
name|Representation
name|source
init|=
literal|null
decl_stmt|;
while|while
condition|(
name|resultSet
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|stdCount
operator|++
expr_stmt|;
name|repStdCount
operator|++
expr_stmt|;
name|QuerySolution
name|solution
init|=
name|resultSet
operator|.
name|next
argument_list|()
decl_stmt|;
name|RDFNode
name|subject
init|=
name|solution
operator|.
name|get
argument_list|(
literal|"resource"
argument_list|)
decl_stmt|;
if|if
condition|(
name|subject
operator|.
name|isURIResource
argument_list|()
condition|)
block|{
name|String
name|resource
init|=
name|subject
operator|.
name|asResource
argument_list|()
operator|.
name|toString
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|resource
operator|.
name|equals
argument_list|(
name|current
argument_list|)
condition|)
block|{
comment|//start of next resource -> index current
name|count
operator|++
expr_stmt|;
if|if
condition|(
name|count
operator|%
literal|10000
operator|==
literal|0
condition|)
block|{
name|long
name|thisOne
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|startCurrent
decl_stmt|;
name|long
name|all
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|start
decl_stmt|;
name|log
operator|.
name|info
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"processed %d resources (%dall %dlast indexed) in %dms (%sms/last | avg: %sms/indexed) std/resource (%s indexed| %s non indexed)"
argument_list|,
name|count
argument_list|,
name|indexed
argument_list|,
name|indexed
operator|-
name|lastIndexed
argument_list|,
name|thisOne
argument_list|,
operator|(
name|float
operator|)
name|thisOne
operator|/
operator|(
name|indexed
operator|-
name|lastIndexed
operator|)
argument_list|,
operator|(
name|float
operator|)
name|all
operator|/
name|indexed
argument_list|,
operator|(
name|float
operator|)
name|indexedStdCount
operator|/
name|indexed
argument_list|,
operator|(
operator|(
name|float
operator|)
name|stdCount
operator|-
name|indexedStdCount
operator|)
operator|/
operator|(
name|count
operator|-
name|indexed
operator|)
argument_list|)
argument_list|)
expr_stmt|;
name|startCurrent
operator|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
expr_stmt|;
name|lastIndexed
operator|=
name|indexed
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|processRanking
argument_list|(
name|source
argument_list|)
condition|)
block|{
if|if
condition|(
name|resumeMode
operator|&&
name|yard
operator|.
name|isRepresentation
argument_list|(
name|source
operator|.
name|getId
argument_list|()
argument_list|)
condition|)
block|{
comment|//resume mode check
comment|//log.info("S<source Resource:\n"+ModelUtils.getRepresentationInfo(source));
name|indexed
operator|++
expr_stmt|;
name|indexedStdCount
operator|=
name|indexedStdCount
operator|+
name|repStdCount
expr_stmt|;
name|storeRepresentation
argument_list|(
name|source
argument_list|)
expr_stmt|;
comment|//here we need todo the indexing!
block|}
comment|//else already indexed -> nothing to do
block|}
comment|// else rankging to low -> do not index
block|}
comment|//else the first item to index -> ignore
comment|//init next resource
name|source
operator|=
name|vf
operator|.
name|createRepresentation
argument_list|(
name|resource
argument_list|)
expr_stmt|;
name|current
operator|=
name|resource
expr_stmt|;
name|repStdCount
operator|=
literal|0
expr_stmt|;
block|}
name|RDFNode
name|fieldNode
init|=
name|solution
operator|.
name|get
argument_list|(
literal|"field"
argument_list|)
decl_stmt|;
if|if
condition|(
name|fieldNode
operator|.
name|isURIResource
argument_list|()
condition|)
block|{
name|String
name|field
init|=
name|fieldNode
operator|.
name|asResource
argument_list|()
operator|.
name|getURI
argument_list|()
decl_stmt|;
name|RDFNode
name|value
init|=
name|solution
operator|.
name|get
argument_list|(
literal|"value"
argument_list|)
decl_stmt|;
if|if
condition|(
name|value
operator|.
name|isURIResource
argument_list|()
condition|)
block|{
name|source
operator|.
name|addReference
argument_list|(
name|field
argument_list|,
name|value
operator|.
name|asResource
argument_list|()
operator|.
name|getURI
argument_list|()
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|value
operator|.
name|isLiteral
argument_list|()
condition|)
block|{
name|Literal
name|literal
init|=
name|value
operator|.
name|asLiteral
argument_list|()
decl_stmt|;
if|if
condition|(
name|literal
operator|.
name|getDatatype
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|Object
name|literalValue
decl_stmt|;
try|try
block|{
name|literalValue
operator|=
name|literal
operator|.
name|getValue
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|DatatypeFormatException
name|e
parameter_list|)
block|{
name|log
operator|.
name|warn
argument_list|(
literal|" Unable to convert "
operator|+
name|literal
operator|.
name|getLexicalForm
argument_list|()
operator|+
literal|" to "
operator|+
name|literal
operator|.
name|getDatatype
argument_list|()
operator|+
literal|"-> use lecicalForm"
argument_list|)
expr_stmt|;
name|literalValue
operator|=
name|literal
operator|.
name|getLexicalForm
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|literalValue
operator|instanceof
name|BaseDatatype
operator|.
name|TypedValue
condition|)
block|{
name|source
operator|.
name|add
argument_list|(
name|field
argument_list|,
operator|(
operator|(
name|BaseDatatype
operator|.
name|TypedValue
operator|)
name|literalValue
operator|)
operator|.
name|lexicalValue
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|literalValue
operator|instanceof
name|XSDDateTime
condition|)
block|{
name|source
operator|.
name|add
argument_list|(
name|field
argument_list|,
operator|(
operator|(
name|XSDDateTime
operator|)
name|literalValue
operator|)
operator|.
name|asCalendar
argument_list|()
operator|.
name|getTime
argument_list|()
argument_list|)
expr_stmt|;
comment|//Rick uses the time
block|}
elseif|else
if|if
condition|(
name|literalValue
operator|instanceof
name|XSDDuration
condition|)
block|{
name|source
operator|.
name|add
argument_list|(
name|field
argument_list|,
name|literalValue
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|source
operator|.
name|add
argument_list|(
name|field
argument_list|,
name|literalValue
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|String
name|lang
init|=
name|literal
operator|.
name|getLanguage
argument_list|()
decl_stmt|;
if|if
condition|(
name|lang
operator|!=
literal|null
operator|&&
name|lang
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|lang
operator|=
literal|null
expr_stmt|;
block|}
name|source
operator|.
name|addNaturalText
argument_list|(
name|field
argument_list|,
name|literal
operator|.
name|getLexicalForm
argument_list|()
argument_list|,
name|lang
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
else|else
block|{
name|log
operator|.
name|warn
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Current Subject %s is not a URI Resource -> ignored"
argument_list|,
name|subject
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|//end while
name|long
name|end
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|log
operator|.
name|info
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"%d in %dms (%sms/item | %sstd/resource)"
argument_list|,
name|count
argument_list|,
name|end
operator|-
name|start
argument_list|,
literal|""
operator|+
operator|(
operator|(
name|float
operator|)
name|end
operator|-
name|start
operator|)
operator|/
name|count
argument_list|,
literal|""
operator|+
operator|(
name|float
operator|)
name|stdCount
operator|/
name|count
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|private
name|boolean
name|processRanking
parameter_list|(
name|Representation
name|source
parameter_list|)
block|{
name|Float
name|ranking
init|=
name|entityRankings
operator|==
literal|null
condition|?
literal|null
else|:
name|entityRankings
operator|.
name|get
argument_list|(
name|source
operator|.
name|getId
argument_list|()
argument_list|)
decl_stmt|;
comment|//ignore values lower than 0
if|if
condition|(
name|ranking
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|ranking
operator|<
literal|0
condition|)
block|{
name|ranking
operator|=
literal|null
expr_stmt|;
block|}
block|}
if|if
condition|(
name|ranking
operator|!=
literal|null
operator|&&
name|ranking
operator|>
literal|1
condition|)
block|{
name|log
operator|.
name|warn
argument_list|(
literal|"Parse Ranking Map contains Entity Ranking> 1 (ranking="
operator|+
name|ranking
operator|+
literal|") for Entity "
operator|+
name|source
operator|.
name|getId
argument_list|()
operator|+
literal|" -> use 1.0 as Ranking!"
argument_list|)
expr_stmt|;
name|ranking
operator|=
literal|1f
expr_stmt|;
block|}
if|if
condition|(
name|ranking
operator|==
literal|null
condition|)
block|{
for|for
control|(
name|Iterator
argument_list|<
name|Object
argument_list|>
name|values
init|=
name|source
operator|.
name|get
argument_list|(
name|entityRankingField
argument_list|)
init|;
name|values
operator|.
name|hasNext
argument_list|()
operator|&&
name|ranking
operator|==
literal|null
condition|;
control|)
block|{
name|Object
name|value
init|=
name|values
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|value
operator|instanceof
name|Float
condition|)
block|{
name|ranking
operator|=
operator|(
name|Float
operator|)
name|value
expr_stmt|;
block|}
else|else
block|{
try|try
block|{
name|ranking
operator|=
name|Float
operator|.
name|parseFloat
argument_list|(
name|value
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NumberFormatException
name|e
parameter_list|)
block|{
name|log
operator|.
name|warn
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Unable to parse the Entity Ranking from field %s=%s[type=%s] -> The Document Boost MUST BE a Float value!"
argument_list|,
name|entityRankingField
argument_list|,
name|value
argument_list|,
name|value
operator|.
name|getClass
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
else|else
block|{
name|source
operator|.
name|set
argument_list|(
name|entityRankingField
argument_list|,
name|ranking
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|ranking
operator|!=
literal|null
operator|&&
name|ranking
operator|>
literal|1
condition|)
block|{
name|log
operator|.
name|warn
argument_list|(
literal|"Parse RDF data include a entity ranking> 1 (ranking="
operator|+
name|ranking
operator|+
literal|") for Entity "
operator|+
name|source
operator|.
name|getId
argument_list|()
operator|+
literal|" and Field "
operator|+
name|entityRankingField
operator|+
literal|"-> use 1.0 as Ranking!"
argument_list|)
expr_stmt|;
name|ranking
operator|=
literal|1f
expr_stmt|;
block|}
if|if
condition|(
name|ranking
operator|==
literal|null
operator|&&
name|this
operator|.
name|defaultEntityRanking
operator|>=
literal|0
condition|)
block|{
comment|//set to default
name|ranking
operator|=
name|defaultEntityRanking
expr_stmt|;
name|source
operator|.
name|set
argument_list|(
name|entityRankingField
argument_list|,
name|ranking
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|ranking
operator|==
literal|null
condition|)
block|{
return|return
operator|!
name|ignoreEntitiesWithoutRank
return|;
comment|//return false to ignore
block|}
else|else
block|{
return|return
name|ranking
operator|>
name|minimumRequiredEntityRanking
return|;
block|}
block|}
end_function

begin_function
specifier|private
name|File
name|checkFile
parameter_list|(
name|String
name|value
parameter_list|)
block|{
return|return
name|checkFile
argument_list|(
name|value
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|)
return|;
block|}
end_function

begin_function
specifier|private
name|File
name|checkFile
parameter_list|(
name|String
name|value
parameter_list|,
name|boolean
name|file
parameter_list|,
name|boolean
name|create
parameter_list|)
block|{
if|if
condition|(
name|value
operator|.
name|startsWith
argument_list|(
name|File
operator|.
name|pathSeparator
argument_list|)
condition|)
block|{
comment|//remove leading path separators!
name|value
operator|=
name|value
operator|.
name|substring
argument_list|(
name|File
operator|.
name|pathSeparator
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|File
name|testFile
init|=
operator|new
name|File
argument_list|(
name|value
operator|.
name|toString
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|testFile
operator|.
name|exists
argument_list|()
condition|)
block|{
if|if
condition|(
name|create
condition|)
block|{
comment|//create
if|if
condition|(
name|file
condition|)
block|{
try|try
block|{
name|testFile
operator|.
name|createNewFile
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Unable to create File "
operator|+
name|testFile
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
else|else
block|{
if|if
condition|(
operator|!
name|testFile
operator|.
name|mkdir
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Unable to create Directory "
operator|+
name|testFile
argument_list|)
throw|;
block|}
block|}
block|}
else|else
block|{
comment|//not found
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"File "
operator|+
name|testFile
operator|.
name|getAbsolutePath
argument_list|()
operator|+
literal|" does not exist!"
argument_list|)
throw|;
block|}
block|}
if|if
condition|(
name|file
operator|&&
operator|!
name|testFile
operator|.
name|isFile
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"parsed file "
operator|+
name|value
operator|+
literal|"is not a file!"
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|file
operator|&&
operator|!
name|testFile
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"parsed file "
operator|+
name|value
operator|+
literal|"is not a directory!"
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|testFile
operator|.
name|canRead
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Unable to read File "
operator|+
name|value
operator|+
literal|"!"
argument_list|)
throw|;
block|}
return|return
name|testFile
return|;
block|}
end_function

begin_function
specifier|private
name|void
name|loadRdfFiles
parameter_list|()
block|{
comment|//TcProvider provider = new IndexingModelProvider(indexingDir);
name|long
name|start
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|log
operator|.
name|info
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Loding RDF %d File%s ..."
argument_list|,
name|rdfFiles
operator|.
name|size
argument_list|()
argument_list|,
name|rdfFiles
operator|.
name|size
argument_list|()
operator|>
literal|1
condition|?
literal|"s"
else|:
literal|""
argument_list|)
argument_list|)
expr_stmt|;
for|for
control|(
name|File
name|modelFile
range|:
name|rdfFiles
control|)
block|{
name|long
name|startFile
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|log
operator|.
name|info
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"> loading '%s' into model '%s'..."
argument_list|,
name|modelFile
argument_list|,
name|modelName
argument_list|)
argument_list|)
expr_stmt|;
name|String
name|name
init|=
name|modelFile
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|name
operator|.
name|endsWith
argument_list|(
literal|".zip"
argument_list|)
condition|)
block|{
name|log
operator|.
name|info
argument_list|(
literal|"  - processing Zip-Archive Entries:"
argument_list|)
expr_stmt|;
try|try
block|{
name|ZipFile
name|zipArchive
init|=
operator|new
name|ZipFile
argument_list|(
name|modelFile
argument_list|)
decl_stmt|;
name|Enumeration
argument_list|<
name|ZipArchiveEntry
argument_list|>
name|entries
init|=
name|zipArchive
operator|.
name|getEntries
argument_list|()
decl_stmt|;
while|while
condition|(
name|entries
operator|.
name|hasMoreElements
argument_list|()
condition|)
block|{
name|ZipArchiveEntry
name|entry
init|=
name|entries
operator|.
name|nextElement
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|entry
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
name|String
name|entryName
init|=
name|entry
operator|.
name|getName
argument_list|()
decl_stmt|;
name|log
operator|.
name|info
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"     o entry '%s' into model '%s'..."
argument_list|,
name|entryName
argument_list|,
name|modelName
argument_list|)
argument_list|)
expr_stmt|;
name|importRdfData
argument_list|(
name|zipArchive
operator|.
name|getInputStream
argument_list|(
name|entry
argument_list|)
argument_list|,
name|entryName
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
else|else
block|{
name|InputStream
name|is
decl_stmt|;
try|try
block|{
name|is
operator|=
operator|new
name|FileInputStream
argument_list|(
name|modelFile
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
comment|//during init it is checked that files exists and are files and there is read access
comment|//so this can only happen if someone deletes the file inbetween
throw|throw
operator|new
name|IllegalStateException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|importRdfData
argument_list|(
name|is
argument_list|,
name|name
argument_list|)
expr_stmt|;
block|}
comment|//add the parsed Triples to the indexing graph!
comment|//QUESTION: Does that load the whole file into memory?
comment|//            indexingGraph.addAll(parser.parse(is, format, null));
name|log
operator|.
name|info
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"   - completed in %d seconds"
argument_list|,
operator|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|startFile
operator|)
operator|/
literal|1000
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|log
operator|.
name|info
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|" ... %d files imported in %d seconds"
argument_list|,
name|rdfFiles
operator|.
name|size
argument_list|()
argument_list|,
operator|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|start
operator|)
operator|/
literal|1000
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/** 	 * This method imports the data from an input stream. The name is used to 	 * guess the RDF format used. The stream may be come directly form a file, 	 * an archive, an URL or an entry in an ZIP file 	 * @param is 	 * @param name 	 */
end_comment

begin_function
specifier|private
name|void
name|importRdfData
parameter_list|(
name|InputStream
name|is
parameter_list|,
name|String
name|name
parameter_list|)
block|{
if|if
condition|(
name|name
operator|.
name|endsWith
argument_list|(
literal|".gz"
argument_list|)
condition|)
block|{
try|try
block|{
name|is
operator|=
operator|new
name|GZIPInputStream
argument_list|(
name|is
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|//during init it is checked that files exists and are files and there is read access
comment|//so this can only happen if someone deletes the file inbetween
throw|throw
operator|new
name|IllegalStateException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|name
operator|=
name|name
operator|.
name|replaceFirst
argument_list|(
literal|"\\.gz$"
argument_list|,
literal|""
argument_list|)
expr_stmt|;
name|log
operator|.
name|info
argument_list|(
literal|"   - from GZIP Archive"
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|name
operator|.
name|endsWith
argument_list|(
literal|".bz2"
argument_list|)
condition|)
block|{
try|try
block|{
name|is
operator|=
operator|new
name|BZip2CompressorInputStream
argument_list|(
name|is
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|//during init it is checked that files exists and are files and there is read access
comment|//so this can only happen if someone deletes the file inbetween
throw|throw
operator|new
name|IllegalStateException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|name
operator|=
name|name
operator|.
name|replaceFirst
argument_list|(
literal|"\\.bz2$"
argument_list|,
literal|""
argument_list|)
expr_stmt|;
name|log
operator|.
name|info
argument_list|(
literal|"   - from BZip2 Archive"
argument_list|)
expr_stmt|;
block|}
comment|//TODO: No Zip Files inside Zip Files supported :o( ^^
name|Lang
name|format
init|=
name|Lang
operator|.
name|guess
argument_list|(
name|name
argument_list|)
decl_stmt|;
comment|//		if (name.endsWith(".nt")) {
comment|//			format = Lang.NTRIPLES;
comment|//		} else if (name.endsWith(".n3")) {
comment|//		    format = Lang.N3;
comment|//		} else {// XML is the default format
comment|//			format = Lang.RDFXML;
comment|//		}
comment|//For N-Triple we can use the TDBLoader
if|if
condition|(
name|format
operator|==
name|Lang
operator|.
name|NTRIPLES
condition|)
block|{
name|TDBLoader
operator|.
name|load
argument_list|(
name|indexingDataset
argument_list|,
name|is
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|format
operator|!=
name|Lang
operator|.
name|RDFXML
condition|)
block|{
comment|//use RIOT to parse the format but with a special configuration
comment|//RiotReader!
name|TDBLoader
name|loader
init|=
operator|new
name|TDBLoader
argument_list|()
decl_stmt|;
name|loader
operator|.
name|setShowProgress
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|Destination
argument_list|<
name|Triple
argument_list|>
name|dest
init|=
name|createDestination
argument_list|()
decl_stmt|;
name|dest
operator|.
name|start
argument_list|()
expr_stmt|;
name|RiotReader
operator|.
name|parseTriples
argument_list|(
name|is
argument_list|,
name|format
argument_list|,
literal|null
argument_list|,
name|dest
argument_list|)
expr_stmt|;
name|dest
operator|.
name|finish
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|//RDFXML
comment|//in that case we need to use ARP
name|Model
name|model
init|=
name|ModelFactory
operator|.
name|createModelForGraph
argument_list|(
name|indexingDataset
operator|.
name|getDefaultGraph
argument_list|()
argument_list|)
decl_stmt|;
name|model
operator|.
name|read
argument_list|(
name|is
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/** 	 * Creates a triple destination for the default dataset of the  	 * {@link #indexingDataset}. 	 * This code is based on how Destinations are created in the {@link BulkLoader}, 	 * implementation. Note that  	 * {@link BulkLoader#loadDefaultGraph(DatasetGraphTDB, InputStream, boolean)} 	 * can not be used for formats other than {@link Lang#NTRIPLES} because it 	 * hard codes this format for loading data form the parsed InputStream. 	 * @return the destination! 	 */
end_comment

begin_function
specifier|private
name|Destination
argument_list|<
name|Triple
argument_list|>
name|createDestination
parameter_list|()
block|{
name|LoadMonitor
name|monitor
init|=
operator|new
name|LoadMonitor
argument_list|(
name|indexingDataset
argument_list|,
name|log
argument_list|,
literal|"triples"
argument_list|,
literal|50000
argument_list|,
literal|100000
argument_list|)
decl_stmt|;
specifier|final
name|LoaderNodeTupleTable
name|loaderTriples
init|=
operator|new
name|LoaderNodeTupleTable
argument_list|(
name|indexingDataset
operator|.
name|getTripleTable
argument_list|()
operator|.
name|getNodeTupleTable
argument_list|()
argument_list|,
literal|"triples"
argument_list|,
name|monitor
argument_list|)
decl_stmt|;
name|Destination
argument_list|<
name|Triple
argument_list|>
name|sink
init|=
operator|new
name|Destination
argument_list|<
name|Triple
argument_list|>
argument_list|()
block|{
name|long
name|count
init|=
literal|0
decl_stmt|;
specifier|final
specifier|public
name|void
name|start
parameter_list|()
block|{
name|loaderTriples
operator|.
name|loadStart
argument_list|()
expr_stmt|;
name|loaderTriples
operator|.
name|loadDataStart
argument_list|()
expr_stmt|;
block|}
specifier|final
specifier|public
name|void
name|send
parameter_list|(
name|Triple
name|triple
parameter_list|)
block|{
name|loaderTriples
operator|.
name|load
argument_list|(
name|triple
operator|.
name|getSubject
argument_list|()
argument_list|,
name|triple
operator|.
name|getPredicate
argument_list|()
argument_list|,
name|triple
operator|.
name|getObject
argument_list|()
argument_list|)
expr_stmt|;
name|count
operator|++
expr_stmt|;
block|}
specifier|final
specifier|public
name|void
name|flush
parameter_list|()
block|{ }
specifier|public
name|void
name|close
parameter_list|()
block|{ }
specifier|final
specifier|public
name|void
name|finish
parameter_list|()
block|{
name|loaderTriples
operator|.
name|loadDataFinish
argument_list|()
expr_stmt|;
name|loaderTriples
operator|.
name|loadIndexStart
argument_list|()
expr_stmt|;
name|loaderTriples
operator|.
name|loadIndexFinish
argument_list|()
expr_stmt|;
name|loaderTriples
operator|.
name|loadFinish
argument_list|()
expr_stmt|;
block|}
block|}
decl_stmt|;
return|return
name|sink
return|;
block|}
end_function

begin_comment
comment|/** 	 * The List used to cache up to {@link #indexingChunkSize} Representations 	 * before they are stored in the Yard.  	 */
end_comment

begin_decl_stmt
specifier|private
name|List
argument_list|<
name|Representation
argument_list|>
name|chunkCache
init|=
operator|new
name|ArrayList
argument_list|<
name|Representation
argument_list|>
argument_list|(
name|this
operator|.
name|indexingChunkSize
argument_list|)
decl_stmt|;
end_decl_stmt

begin_function
specifier|private
name|void
name|storeRepresentation
parameter_list|(
name|Representation
name|source
parameter_list|)
throws|throws
name|YardException
block|{
if|if
condition|(
name|source
operator|!=
literal|null
condition|)
block|{
name|chunkCache
operator|.
name|add
argument_list|(
name|mapper
operator|==
literal|null
condition|?
name|source
else|:
comment|//if no mappings -> store the source
comment|//else process the field mappings
name|mapper
operator|.
name|applyMappings
argument_list|(
name|source
argument_list|,
name|vf
operator|.
name|createRepresentation
argument_list|(
name|source
operator|.
name|getId
argument_list|()
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|chunkCache
operator|.
name|size
argument_list|()
operator|>=
name|indexingChunkSize
condition|)
block|{
name|yard
operator|.
name|store
argument_list|(
name|chunkCache
argument_list|)
expr_stmt|;
name|chunkCache
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/** 	 * As the last step we need to create the baseMappings configuration 	 * needed to used the Index as RICK full cache! 	 * @throws YardException would be really bad if after successfully indexing 	 * about 8 millions of documents we get an error from the yard at the 	 * last possible opportunity :( 	 */
end_comment

begin_function
specifier|private
name|void
name|writeCacheBaseConfiguration
parameter_list|()
throws|throws
name|YardException
block|{
name|log
operator|.
name|info
argument_list|(
literal|"Write BaseMappings for geonames.org Cache"
argument_list|)
expr_stmt|;
if|if
condition|(
name|mapper
operator|!=
literal|null
condition|)
block|{
name|CacheUtils
operator|.
name|storeBaseMappingsConfiguration
argument_list|(
name|yard
argument_list|,
name|mapper
argument_list|)
expr_stmt|;
block|}
name|log
operator|.
name|info
argument_list|(
literal|"< completed"
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|//------------------------------------------------------------------------------
end_comment

begin_comment
comment|// Other implemented variants with less performance than indexResource3!
end_comment

begin_comment
comment|//------------------------------------------------------------------------------
end_comment

begin_comment
comment|//	private void indexResource2(Resource resource){
end_comment

begin_comment
comment|//        Query q = QueryFactory.create(String.format(resourceQuery,resource.getURI(),resource.getURI()), Syntax.syntaxARQ);
end_comment

begin_comment
comment|//        final ResultSet resultSet = QueryExecutionFactory.create(q, indexingDataset.toDataset()).execSelect();
end_comment

begin_comment
comment|//		Representation source = vf.createRepresentation(resource.getURI());
end_comment

begin_comment
comment|//		while(resultSet.hasNext()){
end_comment

begin_comment
comment|//			QuerySolution solution =resultSet.next();
end_comment

begin_comment
comment|//			RDFNode fieldNode = solution.get("field");
end_comment

begin_comment
comment|//			if(fieldNode.isURIResource()){
end_comment

begin_comment
comment|//				String field = fieldNode.asResource().getURI();
end_comment

begin_comment
comment|//				RDFNode value = solution.get("value");
end_comment

begin_comment
comment|//				if(value.isURIResource()){
end_comment

begin_comment
comment|//					source.addReference(field, value.asResource().getURI());
end_comment

begin_comment
comment|//				} else if(value.isLiteral()){
end_comment

begin_comment
comment|//					Literal literal = value.asLiteral();
end_comment

begin_comment
comment|//					if(literal.getDatatype() != null){
end_comment

begin_comment
comment|//						Object literalValue;
end_comment

begin_comment
comment|//						try {
end_comment

begin_comment
comment|//							literalValue = literal.getValue();
end_comment

begin_comment
comment|//						} catch (DatatypeFormatException e) {
end_comment

begin_comment
comment|//							log.warn(" Unable to convert "+literal.getLexicalForm()+" to "+literal.getDatatype()+"-> use lecicalForm");
end_comment

begin_comment
comment|//							literalValue = literal.getLexicalForm();
end_comment

begin_comment
comment|//						}
end_comment

begin_comment
comment|//						if(literalValue instanceof BaseDatatype.TypedValue){
end_comment

begin_comment
comment|//							source.add(field, literal.getLexicalForm());
end_comment

begin_comment
comment|//						} else {
end_comment

begin_comment
comment|//							source.add(field, literal.getValue());
end_comment

begin_comment
comment|//						}
end_comment

begin_comment
comment|//					} else {
end_comment

begin_comment
comment|//						String lang = literal.getLanguage();
end_comment

begin_comment
comment|//						if(lang != null&& lang.isEmpty()){
end_comment

begin_comment
comment|//							lang = null;
end_comment

begin_comment
comment|//						}
end_comment

begin_comment
comment|//						source.addNaturalText(field, literal.getLexicalForm(),lang);
end_comment

begin_comment
comment|//					}
end_comment

begin_comment
comment|//				}
end_comment

begin_comment
comment|//			}
end_comment

begin_comment
comment|//		}
end_comment

begin_comment
comment|//		//log.info("S<source Resource:\n"+ModelUtils.getRepresentationInfo(source));
end_comment

begin_comment
comment|//	}
end_comment

begin_function
specifier|private
name|void
name|indexRanked
parameter_list|()
throws|throws
name|YardException
block|{
if|if
condition|(
name|entityRankings
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Unable to index with Etity Ranking Mode if no Entity Rankings are present!"
argument_list|)
throw|;
block|}
name|long
name|count
init|=
literal|0
decl_stmt|;
name|long
name|alreadyIndexed
init|=
literal|0
decl_stmt|;
name|long
name|stdCount
init|=
literal|0
decl_stmt|;
name|long
name|notFound
init|=
literal|0
decl_stmt|;
name|long
name|start
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|long
name|startCurrent
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
for|for
control|(
name|Entry
argument_list|<
name|String
argument_list|,
name|Float
argument_list|>
name|entry
range|:
name|entityRankings
operator|.
name|entrySet
argument_list|()
control|)
block|{
if|if
condition|(
name|entry
operator|.
name|getValue
argument_list|()
operator|<
name|minimumRequiredEntityRanking
condition|)
block|{
continue|continue;
comment|//ignore entities with rank< the min required one
block|}
name|count
operator|++
expr_stmt|;
if|if
condition|(
name|count
operator|%
literal|1000
operator|==
literal|0
condition|)
block|{
name|long
name|thisOne
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|startCurrent
decl_stmt|;
name|long
name|all
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|start
decl_stmt|;
name|log
operator|.
name|info
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"processed %s resources %s indexed in %sms (%sms/item | avg: %sms/item) %s std/resourc | %s not found"
argument_list|,
name|count
argument_list|,
name|count
operator|-
name|alreadyIndexed
argument_list|,
name|thisOne
argument_list|,
operator|(
name|float
operator|)
name|thisOne
operator|/
literal|1000
argument_list|,
operator|(
name|float
operator|)
name|all
operator|/
name|count
argument_list|,
operator|(
name|float
operator|)
name|stdCount
operator|/
operator|(
name|count
operator|-
name|alreadyIndexed
operator|)
argument_list|,
name|notFound
argument_list|)
argument_list|)
expr_stmt|;
name|startCurrent
operator|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|resumeMode
operator|&&
name|yard
operator|.
name|isRepresentation
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
condition|)
block|{
name|alreadyIndexed
operator|++
expr_stmt|;
continue|continue;
block|}
name|Representation
name|source
init|=
name|vf
operator|.
name|createRepresentation
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
decl_stmt|;
name|Node
name|resource
init|=
name|Node
operator|.
name|createURI
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
decl_stmt|;
name|ExtendedIterator
argument_list|<
name|Triple
argument_list|>
name|outgoing
init|=
name|indexingDataset
operator|.
name|getDefaultGraph
argument_list|()
operator|.
name|find
argument_list|(
name|resource
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|boolean
name|found
init|=
name|outgoing
operator|.
name|hasNext
argument_list|()
decl_stmt|;
while|while
condition|(
name|outgoing
operator|.
name|hasNext
argument_list|()
condition|)
block|{
comment|//iterate over the statements for that resource
name|stdCount
operator|++
expr_stmt|;
name|Triple
name|statement
init|=
name|outgoing
operator|.
name|next
argument_list|()
decl_stmt|;
name|Node
name|predicate
init|=
name|statement
operator|.
name|getPredicate
argument_list|()
decl_stmt|;
if|if
condition|(
name|predicate
operator|==
literal|null
operator|||
operator|!
name|predicate
operator|.
name|isURI
argument_list|()
condition|)
block|{
name|log
operator|.
name|warn
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Ignore field %s for resource %s because it is null or not an URI!"
argument_list|,
name|predicate
argument_list|,
name|resource
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|String
name|field
init|=
name|statement
operator|.
name|getPredicate
argument_list|()
operator|.
name|getURI
argument_list|()
decl_stmt|;
name|Node
name|object
init|=
name|statement
operator|.
name|getObject
argument_list|()
decl_stmt|;
if|if
condition|(
name|object
operator|==
literal|null
condition|)
block|{
name|log
operator|.
name|warn
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Encountered NULL value for field %s and resource %s"
argument_list|,
name|predicate
argument_list|,
name|resource
argument_list|)
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|object
operator|.
name|isURI
argument_list|()
condition|)
block|{
comment|//add a reference
name|source
operator|.
name|addReference
argument_list|(
name|field
argument_list|,
name|object
operator|.
name|getURI
argument_list|()
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|object
operator|.
name|isLiteral
argument_list|()
condition|)
block|{
comment|//add a value or a text depending on the dataType
name|LiteralLabel
name|ll
init|=
name|object
operator|.
name|getLiteral
argument_list|()
decl_stmt|;
comment|//if the dataType == null , than we can expect a plain literal
name|RDFDatatype
name|dataType
init|=
name|ll
operator|.
name|getDatatype
argument_list|()
decl_stmt|;
if|if
condition|(
name|dataType
operator|!=
literal|null
condition|)
block|{
comment|//add a value
name|Object
name|literalValue
decl_stmt|;
try|try
block|{
name|literalValue
operator|=
name|ll
operator|.
name|getValue
argument_list|()
expr_stmt|;
if|if
condition|(
name|literalValue
operator|instanceof
name|BaseDatatype
operator|.
name|TypedValue
condition|)
block|{
comment|//used for unknown data types
comment|// -> in such cases yust use the lecial type
name|source
operator|.
name|add
argument_list|(
name|field
argument_list|,
operator|(
operator|(
name|BaseDatatype
operator|.
name|TypedValue
operator|)
name|literalValue
operator|)
operator|.
name|lexicalValue
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|literalValue
operator|instanceof
name|XSDDateTime
condition|)
block|{
name|source
operator|.
name|add
argument_list|(
name|field
argument_list|,
operator|(
operator|(
name|XSDDateTime
operator|)
name|literalValue
operator|)
operator|.
name|asCalendar
argument_list|()
operator|.
name|getTime
argument_list|()
argument_list|)
expr_stmt|;
comment|//Rick uses the time
block|}
elseif|else
if|if
condition|(
name|literalValue
operator|instanceof
name|XSDDuration
condition|)
block|{
name|source
operator|.
name|add
argument_list|(
name|field
argument_list|,
name|literalValue
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|source
operator|.
name|add
argument_list|(
name|field
argument_list|,
name|literalValue
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|DatatypeFormatException
name|e
parameter_list|)
block|{
name|log
operator|.
name|warn
argument_list|(
literal|" Unable to convert "
operator|+
name|ll
operator|.
name|getLexicalForm
argument_list|()
operator|+
literal|" to "
operator|+
name|ll
operator|.
name|getDatatype
argument_list|()
operator|+
literal|"-> use lecicalForm"
argument_list|)
expr_stmt|;
name|literalValue
operator|=
name|ll
operator|.
name|getLexicalForm
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
comment|//add a text
name|String
name|language
init|=
name|ll
operator|.
name|language
argument_list|()
decl_stmt|;
if|if
condition|(
name|language
operator|!=
literal|null
operator|&&
name|language
operator|.
name|length
argument_list|()
operator|<
literal|1
condition|)
block|{
name|language
operator|=
literal|null
expr_stmt|;
block|}
name|source
operator|.
name|addNaturalText
argument_list|(
name|field
argument_list|,
name|ll
operator|.
name|getLexicalForm
argument_list|()
argument_list|,
name|language
argument_list|)
expr_stmt|;
block|}
comment|// "" is parsed if there is no language
block|}
else|else
block|{
if|if
condition|(
name|object
operator|.
name|isBlank
argument_list|()
condition|)
block|{
name|log
operator|.
name|info
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"ignoreing blank node value %s for field %s and Resource %s!"
argument_list|,
name|object
argument_list|,
name|field
argument_list|,
name|resource
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|log
operator|.
name|warn
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"ignoreing value %s for field %s and Resource %s because it is of an unsupported type!"
argument_list|,
name|object
argument_list|,
name|field
argument_list|,
name|resource
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|//end different value node type
block|}
comment|//end else predicate != null
block|}
comment|//end iteration over resource triple
if|if
condition|(
name|found
condition|)
block|{
name|storeRepresentation
argument_list|(
name|source
argument_list|)
expr_stmt|;
comment|//log.info("Resource: \n"+ModelUtils.getRepresentationInfo(source));
block|}
else|else
block|{
comment|//log.info("No Statements found for "+entry.getKey()+" (ranking="+entry.getValue()+")!");
name|notFound
operator|++
expr_stmt|;
block|}
block|}
block|}
end_function

unit|}
end_unit

