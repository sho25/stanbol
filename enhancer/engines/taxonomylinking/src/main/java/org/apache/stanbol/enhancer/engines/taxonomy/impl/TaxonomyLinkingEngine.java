begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/* * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements.  See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the "License"); you may not use this file except in compliance with * the License.  You may obtain a copy of the License at * *     http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|taxonomy
operator|.
name|impl
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|servicesapi
operator|.
name|rdf
operator|.
name|Properties
operator|.
name|NIE_PLAINTEXTCONTENT
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Dictionary
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeSet
import|;
end_import

begin_import
import|import
name|opennlp
operator|.
name|tools
operator|.
name|chunker
operator|.
name|Chunker
import|;
end_import

begin_import
import|import
name|opennlp
operator|.
name|tools
operator|.
name|chunker
operator|.
name|ChunkerME
import|;
end_import

begin_import
import|import
name|opennlp
operator|.
name|tools
operator|.
name|chunker
operator|.
name|ChunkerModel
import|;
end_import

begin_import
import|import
name|opennlp
operator|.
name|tools
operator|.
name|postag
operator|.
name|POSModel
import|;
end_import

begin_import
import|import
name|opennlp
operator|.
name|tools
operator|.
name|postag
operator|.
name|POSTagger
import|;
end_import

begin_import
import|import
name|opennlp
operator|.
name|tools
operator|.
name|postag
operator|.
name|POSTaggerME
import|;
end_import

begin_import
import|import
name|opennlp
operator|.
name|tools
operator|.
name|sentdetect
operator|.
name|SentenceDetector
import|;
end_import

begin_import
import|import
name|opennlp
operator|.
name|tools
operator|.
name|sentdetect
operator|.
name|SentenceDetectorME
import|;
end_import

begin_import
import|import
name|opennlp
operator|.
name|tools
operator|.
name|sentdetect
operator|.
name|SentenceModel
import|;
end_import

begin_import
import|import
name|opennlp
operator|.
name|tools
operator|.
name|tokenize
operator|.
name|SimpleTokenizer
import|;
end_import

begin_import
import|import
name|opennlp
operator|.
name|tools
operator|.
name|tokenize
operator|.
name|Tokenizer
import|;
end_import

begin_import
import|import
name|opennlp
operator|.
name|tools
operator|.
name|util
operator|.
name|Span
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|clerezza
operator|.
name|rdf
operator|.
name|core
operator|.
name|LiteralFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|clerezza
operator|.
name|rdf
operator|.
name|core
operator|.
name|MGraph
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|clerezza
operator|.
name|rdf
operator|.
name|core
operator|.
name|Triple
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|clerezza
operator|.
name|rdf
operator|.
name|core
operator|.
name|UriRef
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|clerezza
operator|.
name|rdf
operator|.
name|core
operator|.
name|impl
operator|.
name|PlainLiteralImpl
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|clerezza
operator|.
name|rdf
operator|.
name|core
operator|.
name|impl
operator|.
name|TripleImpl
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|io
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|Activate
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|Component
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|ConfigurationPolicy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|Deactivate
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|Property
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|servicesapi
operator|.
name|model
operator|.
name|Entity
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|servicesapi
operator|.
name|model
operator|.
name|Reference
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|servicesapi
operator|.
name|model
operator|.
name|Text
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|ReferenceCardinality
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|ReferencePolicy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|ReferenceStrategy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|Service
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|commons
operator|.
name|opennlp
operator|.
name|OpenNLP
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|commons
operator|.
name|stanboltools
operator|.
name|offline
operator|.
name|OfflineMode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|servicesapi
operator|.
name|ContentItem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|servicesapi
operator|.
name|EngineException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|servicesapi
operator|.
name|EnhancementEngine
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|servicesapi
operator|.
name|InvalidContentException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|servicesapi
operator|.
name|ServiceProperties
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|servicesapi
operator|.
name|helper
operator|.
name|EnhancementEngineHelper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|servicesapi
operator|.
name|rdf
operator|.
name|OntologicalClasses
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|servicesapi
operator|.
name|rdf
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|servicesapi
operator|.
name|Entityhub
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|servicesapi
operator|.
name|EntityhubException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|servicesapi
operator|.
name|defaults
operator|.
name|NamespaceEnum
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|servicesapi
operator|.
name|model
operator|.
name|Representation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|servicesapi
operator|.
name|query
operator|.
name|FieldQuery
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|servicesapi
operator|.
name|query
operator|.
name|QueryResultList
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|servicesapi
operator|.
name|query
operator|.
name|TextConstraint
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|servicesapi
operator|.
name|site
operator|.
name|ReferencedSite
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|servicesapi
operator|.
name|site
operator|.
name|ReferencedSiteManager
import|;
end_import

begin_comment
comment|//removed annotations until engine actually does something
end_comment

begin_comment
comment|//@Component(configurationFactory = true, policy = ConfigurationPolicy.REQUIRE, // the baseUri is required!
end_comment

begin_comment
comment|//    specVersion = "1.1", metatype = true, immediate = true)
end_comment

begin_comment
comment|//@Service
end_comment

begin_import
import|import
name|org
operator|.
name|osgi
operator|.
name|service
operator|.
name|cm
operator|.
name|ConfigurationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|osgi
operator|.
name|service
operator|.
name|component
operator|.
name|ComponentContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/**  * This is the first try of an EnhancementEngine that finds concepts present within   * an taxonomy (controlled vocabulary) within content.<p>  * Currently users should not use this engine but use the KeywordLinkingEngine  * (org.apache.stanbol.enhancer.engine.keywordextraction bundle) instead.<p>  * It is planed to re-introduce this engine with additional features specific to  * taxonomies (such as support for concept hierarchies).  * @deprecated  * @author Rupert Westenthaler  *  */
end_comment

begin_class
annotation|@
name|Component
argument_list|(
name|configurationFactory
operator|=
literal|true
argument_list|,
name|policy
operator|=
name|ConfigurationPolicy
operator|.
name|REQUIRE
argument_list|,
comment|// the baseUri is required!
name|specVersion
operator|=
literal|"1.1"
argument_list|,
name|metatype
operator|=
literal|true
argument_list|,
name|immediate
operator|=
literal|true
argument_list|)
annotation|@
name|Service
annotation|@
name|Deprecated
specifier|public
class|class
name|TaxonomyLinkingEngine
implements|implements
name|EnhancementEngine
implements|,
name|ServiceProperties
block|{
specifier|private
specifier|static
name|Logger
name|log
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|TaxonomyLinkingEngine
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|boolean
name|DEFAULT_SIMPLE_TOKENIZER_STATE
init|=
literal|true
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_MIN_SEARCH_TOKEN_LENGTH
init|=
literal|3
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|boolean
name|DEFAULT_USE_CHUNKER_STATE
init|=
literal|false
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|DEFAULT_NAME_FIELD
init|=
literal|"rdfs:label"
decl_stmt|;
comment|/**      * The default number for the maximum number of terms suggested for a word      */
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_SUGGESTIONS
init|=
literal|3
decl_stmt|;
comment|/**      * Default value for the number of tokens that must be contained in      * suggested terms.      */
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_MIN_FOUND_TOKENS
init|=
literal|2
decl_stmt|;
annotation|@
name|Property
specifier|public
specifier|static
specifier|final
name|String
name|REFERENCED_SITE_ID
init|=
literal|"org.apache.stanbol.enhancer.engines.taxonomy.referencedSiteId"
decl_stmt|;
annotation|@
name|Property
argument_list|(
name|value
operator|=
name|DEFAULT_NAME_FIELD
argument_list|)
specifier|public
specifier|static
specifier|final
name|String
name|NAME_FIELD
init|=
literal|"org.apache.stanbol.enhancer.engines.taxonomy.nameField"
decl_stmt|;
annotation|@
name|Property
argument_list|(
name|boolValue
operator|=
name|DEFAULT_SIMPLE_TOKENIZER_STATE
argument_list|)
specifier|public
specifier|static
specifier|final
name|String
name|SIMPLE_TOKENIZER
init|=
literal|"org.apache.stanbol.enhancer.engines.taxonomy.simpleTokenizer"
decl_stmt|;
annotation|@
name|Property
argument_list|(
name|intValue
operator|=
name|DEFAULT_MIN_SEARCH_TOKEN_LENGTH
argument_list|)
specifier|public
specifier|static
specifier|final
name|String
name|MIN_SEARCH_TOKEN_LENGTH
init|=
literal|"org.apache.stanbol.enhancer.engines.taxonomy.minSearchTokenLength"
decl_stmt|;
annotation|@
name|Property
argument_list|(
name|boolValue
operator|=
name|DEFAULT_USE_CHUNKER_STATE
argument_list|)
specifier|public
specifier|static
specifier|final
name|String
name|ENABLE_CHUNKER
init|=
literal|"org.apache.stanbol.enhancer.engines.taxonomy.enableChunker"
decl_stmt|;
annotation|@
name|Property
argument_list|(
name|intValue
operator|=
name|DEFAULT_SUGGESTIONS
argument_list|)
specifier|public
specifier|static
specifier|final
name|String
name|MAX_SUGGESTIONS
init|=
literal|"org.apache.stanbol.enhancer.engines.taxonomy.maxSuggestions"
decl_stmt|;
annotation|@
name|Property
argument_list|(
name|intValue
operator|=
name|DEFAULT_MIN_FOUND_TOKENS
argument_list|)
specifier|public
specifier|static
specifier|final
name|String
name|MIN_FOUND_TOKENS
init|=
literal|"org.apache.stanbol.enhancer.engines.taxonomy.minFoundTokens"
decl_stmt|;
specifier|protected
specifier|static
specifier|final
name|String
name|TEXT_PLAIN_MIMETYPE
init|=
literal|"text/plain"
decl_stmt|;
comment|/**      * The default value for the Execution of this Engine. Currently set to      * {@link ServiceProperties#ORDERING_EXTRACTION_ENHANCEMENT} + 10. It should run after Metaxa and LangId.      */
specifier|public
specifier|static
specifier|final
name|Integer
name|defaultOrder
init|=
name|ServiceProperties
operator|.
name|ORDERING_EXTRACTION_ENHANCEMENT
operator|+
literal|10
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|UriRef
argument_list|>
name|DEFAULT_ENTITY_TYPE_MAPPINGS
decl_stmt|;
static|static
block|{
comment|//the default mappings for the three types used by the Stanbol Enhancement Structure
name|Map
argument_list|<
name|String
argument_list|,
name|UriRef
argument_list|>
name|mappings
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|UriRef
argument_list|>
argument_list|()
decl_stmt|;
name|mappings
operator|.
name|put
argument_list|(
name|OntologicalClasses
operator|.
name|DBPEDIA_ORGANISATION
operator|.
name|getUnicodeString
argument_list|()
argument_list|,
name|OntologicalClasses
operator|.
name|DBPEDIA_ORGANISATION
argument_list|)
expr_stmt|;
name|mappings
operator|.
name|put
argument_list|(
name|NamespaceEnum
operator|.
name|dbpediaOnt
operator|+
literal|"Newspaper"
argument_list|,
name|OntologicalClasses
operator|.
name|DBPEDIA_ORGANISATION
argument_list|)
expr_stmt|;
name|mappings
operator|.
name|put
argument_list|(
name|NamespaceEnum
operator|.
name|schema
operator|+
literal|"Organization"
argument_list|,
name|OntologicalClasses
operator|.
name|DBPEDIA_ORGANISATION
argument_list|)
expr_stmt|;
name|mappings
operator|.
name|put
argument_list|(
name|OntologicalClasses
operator|.
name|DBPEDIA_PERSON
operator|.
name|getUnicodeString
argument_list|()
argument_list|,
name|OntologicalClasses
operator|.
name|DBPEDIA_PERSON
argument_list|)
expr_stmt|;
name|mappings
operator|.
name|put
argument_list|(
name|NamespaceEnum
operator|.
name|foaf
operator|+
literal|"Person"
argument_list|,
name|OntologicalClasses
operator|.
name|DBPEDIA_PERSON
argument_list|)
expr_stmt|;
name|mappings
operator|.
name|put
argument_list|(
name|NamespaceEnum
operator|.
name|schema
operator|+
literal|"Person"
argument_list|,
name|OntologicalClasses
operator|.
name|DBPEDIA_PERSON
argument_list|)
expr_stmt|;
name|mappings
operator|.
name|put
argument_list|(
name|OntologicalClasses
operator|.
name|DBPEDIA_PLACE
operator|.
name|getUnicodeString
argument_list|()
argument_list|,
name|OntologicalClasses
operator|.
name|DBPEDIA_PLACE
argument_list|)
expr_stmt|;
name|mappings
operator|.
name|put
argument_list|(
name|NamespaceEnum
operator|.
name|schema
operator|+
literal|"Place"
argument_list|,
name|OntologicalClasses
operator|.
name|DBPEDIA_PLACE
argument_list|)
expr_stmt|;
name|mappings
operator|.
name|put
argument_list|(
name|OntologicalClasses
operator|.
name|SKOS_CONCEPT
operator|.
name|getUnicodeString
argument_list|()
argument_list|,
name|OntologicalClasses
operator|.
name|SKOS_CONCEPT
argument_list|)
expr_stmt|;
name|DEFAULT_ENTITY_TYPE_MAPPINGS
operator|=
name|Collections
operator|.
name|unmodifiableMap
argument_list|(
name|mappings
argument_list|)
expr_stmt|;
block|}
annotation|@
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|Reference
specifier|private
name|OpenNLP
name|openNLP
decl_stmt|;
comment|/**      * Allow to force the use of the {@link SimpleTokenizer}      */
specifier|private
name|boolean
name|useSimpleTokenizer
init|=
name|DEFAULT_SIMPLE_TOKENIZER_STATE
decl_stmt|;
comment|/**      * The minimum length of labels that are looked-up in the directory      */
specifier|private
name|int
name|minSearchTokenLength
init|=
name|DEFAULT_MIN_SEARCH_TOKEN_LENGTH
decl_stmt|;
comment|/**      * Allows to activate/deactivate the use of an {@link Chunker}      */
specifier|private
name|boolean
name|useChunker
init|=
name|DEFAULT_USE_CHUNKER_STATE
decl_stmt|;
comment|/**      * The field used to search for the names of entities part of the dictionary      */
specifier|private
name|String
name|nameField
init|=
name|NamespaceEnum
operator|.
name|getFullName
argument_list|(
name|DEFAULT_NAME_FIELD
argument_list|)
decl_stmt|;
comment|/**      * The the maximum number of terms suggested for a word      */
specifier|private
name|int
name|maxSuggestions
init|=
name|DEFAULT_SUGGESTIONS
decl_stmt|;
comment|/**      * If several words are selected from the text to search for an Entity in the      * Dictionary (e.g. if a {@link Chunker} is used or if the {@link POSTagger}      * detects several connected nouns) that entities found for the such chunks      * MUST define a label (with no or the correct lanugage) that contains at      * least this number of tokens to be accepted.<p>      * TODO: make configurable      */
specifier|private
name|int
name|minFoundTokens
init|=
name|DEFAULT_MIN_FOUND_TOKENS
decl_stmt|;
comment|/**      * Service of the Entityhub that manages all the active referenced Site. This Service is used to lookup the      * configured Referenced Site when we need to enhance a content item.      */
annotation|@
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|Reference
specifier|protected
name|ReferencedSiteManager
name|siteManager
decl_stmt|;
comment|/**      * Used to lookup Entities if the {@link #REFERENCED_SITE_ID} property is      * set to "entityhub" or "local"      */
annotation|@
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|Reference
specifier|protected
name|Entityhub
name|entityhub
decl_stmt|;
comment|/**      * This holds the id of the {@link ReferencedSite} used to lookup Entities      * or<code>null</code> if the {@link Entityhub} is used.       */
specifier|protected
name|String
name|referencedSiteID
decl_stmt|;
comment|/**      * Default constructor used by OSGI      */
specifier|public
name|TaxonomyLinkingEngine
parameter_list|()
block|{}
comment|/**      * The RDF LiteralFactory used for typed literals      */
specifier|private
name|LiteralFactory
name|literalFactory
init|=
name|LiteralFactory
operator|.
name|getInstance
argument_list|()
decl_stmt|;
comment|/**      * Constructor used for unit tests outside of an OSGI environment      * @param openNLP      */
specifier|protected
name|TaxonomyLinkingEngine
parameter_list|(
name|OpenNLP
name|openNLP
parameter_list|)
block|{
if|if
condition|(
name|openNLP
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"The parsed OpenNLP instance MUST NOT be NULL"
argument_list|)
throw|;
block|}
name|this
operator|.
name|openNLP
operator|=
name|openNLP
expr_stmt|;
block|}
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
annotation|@
name|Activate
specifier|protected
name|void
name|activate
parameter_list|(
name|ComponentContext
name|context
parameter_list|)
throws|throws
name|ConfigurationException
block|{
name|Dictionary
argument_list|<
name|String
argument_list|,
name|Object
argument_list|>
name|config
init|=
name|context
operator|.
name|getProperties
argument_list|()
decl_stmt|;
comment|//lookup the referenced site used as dictionary
name|Object
name|referencedSiteID
init|=
name|config
operator|.
name|get
argument_list|(
name|REFERENCED_SITE_ID
argument_list|)
decl_stmt|;
if|if
condition|(
name|referencedSiteID
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|ConfigurationException
argument_list|(
name|REFERENCED_SITE_ID
argument_list|,
literal|"The ID of the Referenced Site is a required Parameter and MUST NOT be NULL!"
argument_list|)
throw|;
block|}
name|this
operator|.
name|referencedSiteID
operator|=
name|referencedSiteID
operator|.
name|toString
argument_list|()
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|referencedSiteID
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|ConfigurationException
argument_list|(
name|REFERENCED_SITE_ID
argument_list|,
literal|"The ID of the Referenced Site is a required Parameter and MUST NOT be an empty String!"
argument_list|)
throw|;
block|}
if|if
condition|(
name|Entityhub
operator|.
name|ENTITYHUB_IDS
operator|.
name|contains
argument_list|(
name|this
operator|.
name|referencedSiteID
operator|.
name|toLowerCase
argument_list|()
argument_list|)
condition|)
block|{
name|log
operator|.
name|info
argument_list|(
literal|"Init NamedEntityTaggingEngine instance for the Entityhub"
argument_list|)
expr_stmt|;
name|this
operator|.
name|referencedSiteID
operator|=
literal|null
expr_stmt|;
block|}
comment|//parse the other configurations
name|Object
name|value
init|=
name|config
operator|.
name|get
argument_list|(
name|ENABLE_CHUNKER
argument_list|)
decl_stmt|;
if|if
condition|(
name|value
operator|instanceof
name|Boolean
condition|)
block|{
name|useChunker
operator|=
operator|(
operator|(
name|Boolean
operator|)
name|value
operator|)
operator|.
name|booleanValue
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|value
operator|!=
literal|null
condition|)
block|{
name|useChunker
operator|=
name|Boolean
operator|.
name|parseBoolean
argument_list|(
name|value
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|value
operator|=
name|config
operator|.
name|get
argument_list|(
name|MIN_SEARCH_TOKEN_LENGTH
argument_list|)
expr_stmt|;
if|if
condition|(
name|value
operator|instanceof
name|Number
condition|)
block|{
name|minSearchTokenLength
operator|=
operator|(
operator|(
name|Number
operator|)
name|value
operator|)
operator|.
name|intValue
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|value
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|minSearchTokenLength
operator|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|value
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NumberFormatException
name|e
parameter_list|)
block|{
name|log
operator|.
name|warn
argument_list|(
literal|"Unable to parse value for the minimum search token length."
operator|+
literal|"Use the default value "
operator|+
name|minSearchTokenLength
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
name|value
operator|=
name|config
operator|.
name|get
argument_list|(
name|SIMPLE_TOKENIZER
argument_list|)
expr_stmt|;
if|if
condition|(
name|value
operator|instanceof
name|Boolean
condition|)
block|{
name|useSimpleTokenizer
operator|=
operator|(
operator|(
name|Boolean
operator|)
name|value
operator|)
operator|.
name|booleanValue
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|value
operator|!=
literal|null
condition|)
block|{
name|useSimpleTokenizer
operator|=
name|Boolean
operator|.
name|parseBoolean
argument_list|(
name|value
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|value
operator|=
name|config
operator|.
name|get
argument_list|(
name|NAME_FIELD
argument_list|)
expr_stmt|;
if|if
condition|(
name|value
operator|!=
literal|null
operator|&&
operator|!
name|value
operator|.
name|toString
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|this
operator|.
name|nameField
operator|=
name|NamespaceEnum
operator|.
name|getFullName
argument_list|(
name|value
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Deactivate
specifier|protected
name|void
name|deactivate
parameter_list|(
name|ComponentContext
name|context
parameter_list|)
block|{
name|referencedSiteID
operator|=
literal|null
expr_stmt|;
comment|//reset optional properties to the default
name|nameField
operator|=
name|DEFAULT_NAME_FIELD
expr_stmt|;
name|useChunker
operator|=
name|DEFAULT_USE_CHUNKER_STATE
expr_stmt|;
name|minSearchTokenLength
operator|=
name|DEFAULT_MIN_SEARCH_TOKEN_LENGTH
expr_stmt|;
name|useSimpleTokenizer
operator|=
name|DEFAULT_SIMPLE_TOKENIZER_STATE
expr_stmt|;
name|minFoundTokens
operator|=
name|DEFAULT_MIN_FOUND_TOKENS
expr_stmt|;
name|maxSuggestions
operator|=
name|DEFAULT_SUGGESTIONS
expr_stmt|;
block|}
comment|/**      * The {@link OfflineMode} is used by Stanbol to indicate that no external service should be referenced.      * For this engine that means it is necessary to check if the used {@link ReferencedSite} can operate      * offline or not.      *       * @see #enableOfflineMode(OfflineMode)      * @see #disableOfflineMode(OfflineMode)      */
annotation|@
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|Reference
argument_list|(
name|cardinality
operator|=
name|ReferenceCardinality
operator|.
name|OPTIONAL_UNARY
argument_list|,
name|policy
operator|=
name|ReferencePolicy
operator|.
name|DYNAMIC
argument_list|,
name|bind
operator|=
literal|"enableOfflineMode"
argument_list|,
name|unbind
operator|=
literal|"disableOfflineMode"
argument_list|,
name|strategy
operator|=
name|ReferenceStrategy
operator|.
name|EVENT
argument_list|)
specifier|private
name|OfflineMode
name|offlineMode
decl_stmt|;
specifier|private
name|RedirectProcessingState
name|redirectState
init|=
name|RedirectProcessingState
operator|.
name|FOLLOW
decl_stmt|;
comment|/**      * Called by the ConfigurationAdmin to bind the {@link #offlineMode} if the service becomes available      *       * @param mode      */
specifier|protected
specifier|final
name|void
name|enableOfflineMode
parameter_list|(
name|OfflineMode
name|mode
parameter_list|)
block|{
name|this
operator|.
name|offlineMode
operator|=
name|mode
expr_stmt|;
block|}
comment|/**      * Called by the ConfigurationAdmin to unbind the {@link #offlineMode} if the service becomes unavailable      *       * @param mode      */
specifier|protected
specifier|final
name|void
name|disableOfflineMode
parameter_list|(
name|OfflineMode
name|mode
parameter_list|)
block|{
name|this
operator|.
name|offlineMode
operator|=
literal|null
expr_stmt|;
block|}
comment|/**      * Returns<code>true</code> only if Stanbol operates in {@link OfflineMode}.      *       * @return the offline state      */
specifier|protected
specifier|final
name|boolean
name|isOfflineMode
parameter_list|()
block|{
return|return
name|offlineMode
operator|!=
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|canEnhance
parameter_list|(
name|ContentItem
name|ci
parameter_list|)
throws|throws
name|EngineException
block|{
name|String
name|mimeType
init|=
name|ci
operator|.
name|getMimeType
argument_list|()
operator|.
name|split
argument_list|(
literal|";"
argument_list|,
literal|2
argument_list|)
index|[
literal|0
index|]
decl_stmt|;
if|if
condition|(
name|TEXT_PLAIN_MIMETYPE
operator|.
name|equalsIgnoreCase
argument_list|(
name|mimeType
argument_list|)
condition|)
block|{
return|return
name|ENHANCE_SYNCHRONOUS
return|;
block|}
comment|// check for existence of textual content in metadata
name|UriRef
name|subj
init|=
name|ci
operator|.
name|getUri
argument_list|()
decl_stmt|;
name|Iterator
argument_list|<
name|Triple
argument_list|>
name|it
init|=
name|ci
operator|.
name|getMetadata
argument_list|()
operator|.
name|filter
argument_list|(
name|subj
argument_list|,
name|NIE_PLAINTEXTCONTENT
argument_list|,
literal|null
argument_list|)
decl_stmt|;
if|if
condition|(
name|it
operator|.
name|hasNext
argument_list|()
condition|)
block|{
return|return
name|ENHANCE_SYNCHRONOUS
return|;
block|}
return|return
name|CANNOT_ENHANCE
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|computeEnhancements
parameter_list|(
name|ContentItem
name|ci
parameter_list|)
throws|throws
name|EngineException
block|{
specifier|final
name|ReferencedSite
name|site
decl_stmt|;
if|if
condition|(
name|referencedSiteID
operator|!=
literal|null
condition|)
block|{
comment|//lookup the referenced site
name|site
operator|=
name|siteManager
operator|.
name|getReferencedSite
argument_list|(
name|referencedSiteID
argument_list|)
expr_stmt|;
comment|//ensure that it is present
if|if
condition|(
name|site
operator|==
literal|null
condition|)
block|{
name|String
name|msg
init|=
name|String
operator|.
name|format
argument_list|(
literal|"Unable to enhance %s because Referenced Site %s is currently not active!"
argument_list|,
name|ci
operator|.
name|getUri
argument_list|()
operator|.
name|getUnicodeString
argument_list|()
argument_list|,
name|referencedSiteID
argument_list|)
decl_stmt|;
name|log
operator|.
name|warn
argument_list|(
name|msg
argument_list|)
expr_stmt|;
comment|// TODO: throwing Exceptions is currently deactivated. We need a more clear
comment|// policy what do to in such situations
comment|// throw new EngineException(msg);
return|return;
block|}
comment|//and that it supports offline mode if required
if|if
condition|(
name|isOfflineMode
argument_list|()
operator|&&
operator|!
name|site
operator|.
name|supportsLocalMode
argument_list|()
condition|)
block|{
name|log
operator|.
name|warn
argument_list|(
literal|"Unable to enhance ci {} because OfflineMode is not supported by ReferencedSite {}."
argument_list|,
name|ci
operator|.
name|getUri
argument_list|()
operator|.
name|getUnicodeString
argument_list|()
argument_list|,
name|site
operator|.
name|getId
argument_list|()
argument_list|)
expr_stmt|;
return|return;
block|}
block|}
else|else
block|{
comment|// null indicates to use the Entityhub to lookup Entities
name|site
operator|=
literal|null
expr_stmt|;
block|}
name|String
name|mimeType
init|=
name|ci
operator|.
name|getMimeType
argument_list|()
operator|.
name|split
argument_list|(
literal|";"
argument_list|,
literal|2
argument_list|)
index|[
literal|0
index|]
decl_stmt|;
name|String
name|text
decl_stmt|;
if|if
condition|(
name|TEXT_PLAIN_MIMETYPE
operator|.
name|equals
argument_list|(
name|mimeType
argument_list|)
condition|)
block|{
try|try
block|{
name|text
operator|=
name|IOUtils
operator|.
name|toString
argument_list|(
name|ci
operator|.
name|getStream
argument_list|()
argument_list|,
literal|"UTF-8"
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|InvalidContentException
argument_list|(
name|this
argument_list|,
name|ci
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
else|else
block|{
comment|//TODO: change that as soon the Adapter Pattern is used for multiple
comment|// mimetype support.
name|StringBuilder
name|textBuilder
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|Iterator
argument_list|<
name|Triple
argument_list|>
name|it
init|=
name|ci
operator|.
name|getMetadata
argument_list|()
operator|.
name|filter
argument_list|(
name|ci
operator|.
name|getUri
argument_list|()
argument_list|,
name|NIE_PLAINTEXTCONTENT
argument_list|,
literal|null
argument_list|)
decl_stmt|;
while|while
condition|(
name|it
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|textBuilder
operator|.
name|append
argument_list|(
name|it
operator|.
name|next
argument_list|()
operator|.
name|getObject
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|text
operator|=
name|textBuilder
operator|.
name|toString
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|text
operator|.
name|trim
argument_list|()
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
comment|// TODO: make the length of the data a field of the ContentItem
comment|// interface to be able to filter out empty items in the canEnhance
comment|// method
name|log
operator|.
name|warn
argument_list|(
literal|"nothing to extract knowledge from in ContentItem {}"
argument_list|,
name|ci
argument_list|)
expr_stmt|;
return|return;
block|}
comment|//TODO: determin the language
name|String
name|language
init|=
literal|"en"
decl_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"computeEnhancements for ContentItem {} language {} text={}"
argument_list|,
operator|new
name|Object
index|[]
block|{
name|ci
operator|.
name|getUri
argument_list|()
operator|.
name|getUnicodeString
argument_list|()
block|,
name|language
block|,
name|StringUtils
operator|.
name|abbreviate
argument_list|(
name|text
argument_list|,
literal|100
argument_list|)
block|}
argument_list|)
expr_stmt|;
comment|//first get the models
name|Tokenizer
name|tokenizer
init|=
name|initTokenizer
argument_list|(
name|language
argument_list|)
decl_stmt|;
name|SentenceDetector
name|sentenceDetector
init|=
name|initSentence
argument_list|(
name|language
argument_list|)
decl_stmt|;
name|POSTaggerME
name|posTagger
decl_stmt|;
if|if
condition|(
name|sentenceDetector
operator|!=
literal|null
condition|)
block|{
comment|//sentence detection is requirement
name|posTagger
operator|=
name|initTagger
argument_list|(
name|language
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|posTagger
operator|=
literal|null
expr_stmt|;
block|}
name|ChunkerME
name|chunker
decl_stmt|;
if|if
condition|(
name|posTagger
operator|!=
literal|null
operator|&&
name|useChunker
condition|)
block|{
comment|//pos tags requirement
name|chunker
operator|=
name|initChunker
argument_list|(
name|language
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|chunker
operator|=
literal|null
expr_stmt|;
block|}
name|Map
argument_list|<
name|String
argument_list|,
name|Suggestion
argument_list|>
name|suggestionCache
init|=
operator|new
name|TreeMap
argument_list|<
name|String
argument_list|,
name|Suggestion
argument_list|>
argument_list|()
decl_stmt|;
if|if
condition|(
name|sentenceDetector
operator|!=
literal|null
condition|)
block|{
comment|//add dots for multiple line breaks
name|text
operator|=
name|text
operator|.
name|replaceAll
argument_list|(
literal|"\\n\\n"
argument_list|,
literal|".\n"
argument_list|)
expr_stmt|;
name|Span
index|[]
name|sentenceSpans
init|=
name|sentenceDetector
operator|.
name|sentPosDetect
argument_list|(
name|text
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|sentenceSpans
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|String
name|sentence
init|=
name|sentenceSpans
index|[
name|i
index|]
operator|.
name|getCoveredText
argument_list|(
name|text
argument_list|)
operator|.
name|toString
argument_list|()
decl_stmt|;
name|Span
index|[]
name|tokenSpans
init|=
name|tokenizer
operator|.
name|tokenizePos
argument_list|(
name|sentence
argument_list|)
decl_stmt|;
name|String
index|[]
name|tokens
init|=
name|getTokensForSpans
argument_list|(
name|sentence
argument_list|,
name|tokenSpans
argument_list|)
decl_stmt|;
name|String
index|[]
name|pos
decl_stmt|;
name|double
index|[]
name|posProbs
decl_stmt|;
if|if
condition|(
name|posTagger
operator|!=
literal|null
condition|)
block|{
name|pos
operator|=
name|posTagger
operator|.
name|tag
argument_list|(
name|tokens
argument_list|)
expr_stmt|;
name|posProbs
operator|=
name|posTagger
operator|.
name|probs
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|pos
operator|=
literal|null
expr_stmt|;
name|posProbs
operator|=
literal|null
expr_stmt|;
block|}
name|Span
index|[]
name|chunkSpans
decl_stmt|;
name|double
index|[]
name|chunkProps
decl_stmt|;
if|if
condition|(
name|chunker
operator|!=
literal|null
condition|)
block|{
name|chunkSpans
operator|=
name|chunker
operator|.
name|chunkAsSpans
argument_list|(
name|tokens
argument_list|,
name|pos
argument_list|)
expr_stmt|;
name|chunkProps
operator|=
name|chunker
operator|.
name|probs
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|chunkSpans
operator|=
literal|null
expr_stmt|;
name|chunkProps
operator|=
literal|null
expr_stmt|;
block|}
name|enhance
argument_list|(
name|suggestionCache
argument_list|,
name|site
argument_list|,
name|ci
argument_list|,
name|language
argument_list|,
comment|//the site, metadata and lang
name|sentenceSpans
index|[
name|i
index|]
operator|.
name|getStart
argument_list|()
argument_list|,
name|sentence
argument_list|,
comment|//offset and sentence
name|tokenSpans
argument_list|,
name|tokens
argument_list|,
comment|//the tokens
name|pos
argument_list|,
name|posProbs
argument_list|,
comment|// the pos tags (might be null)
name|chunkSpans
argument_list|,
name|chunkProps
argument_list|)
expr_stmt|;
comment|//the chunks (might be null)
block|}
block|}
else|else
block|{
name|Span
index|[]
name|tokenSpans
init|=
name|tokenizer
operator|.
name|tokenizePos
argument_list|(
name|text
argument_list|)
decl_stmt|;
name|String
index|[]
name|tokens
init|=
name|getTokensForSpans
argument_list|(
name|text
argument_list|,
name|tokenSpans
argument_list|)
decl_stmt|;
name|enhance
argument_list|(
name|suggestionCache
argument_list|,
name|site
argument_list|,
name|ci
argument_list|,
name|language
argument_list|,
literal|0
argument_list|,
name|text
argument_list|,
name|tokenSpans
argument_list|,
name|tokens
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
comment|//finally write the entity enhancements
name|this
operator|.
name|wirteEntityEnhancements
argument_list|(
name|suggestionCache
argument_list|,
name|ci
argument_list|,
name|nameField
argument_list|,
name|language
argument_list|)
expr_stmt|;
block|}
comment|/**      * @param sentence      * @param tokenSpans      * @return      */
specifier|private
name|String
index|[]
name|getTokensForSpans
parameter_list|(
name|String
name|sentence
parameter_list|,
name|Span
index|[]
name|tokenSpans
parameter_list|)
block|{
name|String
index|[]
name|tokens
init|=
operator|new
name|String
index|[
name|tokenSpans
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|ti
init|=
literal|0
init|;
name|ti
operator|<
name|tokenSpans
operator|.
name|length
condition|;
name|ti
operator|++
control|)
block|{
name|tokens
index|[
name|ti
index|]
operator|=
name|tokenSpans
index|[
name|ti
index|]
operator|.
name|getCoveredText
argument_list|(
name|sentence
argument_list|)
operator|.
name|toString
argument_list|()
expr_stmt|;
block|}
return|return
name|tokens
return|;
block|}
specifier|private
name|void
name|enhance
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|Suggestion
argument_list|>
name|suggestionCache
parameter_list|,
name|ReferencedSite
name|site
parameter_list|,
name|ContentItem
name|ci
parameter_list|,
name|String
name|language
parameter_list|,
name|int
name|offset
parameter_list|,
name|String
name|sentence
parameter_list|,
name|Span
index|[]
name|tokenSpans
parameter_list|,
name|String
index|[]
name|tokens
parameter_list|,
name|String
index|[]
name|pos
parameter_list|,
name|double
index|[]
name|posProbs
parameter_list|,
name|Span
index|[]
name|chunkSpans
parameter_list|,
name|double
index|[]
name|chunkProps
parameter_list|)
throws|throws
name|EngineException
block|{
comment|//Iterate over tokens. Note that a single iteration may consume multiple
comment|//tokens in case a suggestion is found for a chunk.
name|int
name|consumed
init|=
operator|-
literal|1
decl_stmt|;
name|int
name|chunkPos
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|currentToken
init|=
literal|0
init|;
name|currentToken
operator|<
name|tokenSpans
operator|.
name|length
condition|;
name|currentToken
operator|++
control|)
block|{
name|Span
name|current
decl_stmt|;
comment|//the current chunk to be processed
comment|//in case POS tags are available process only tokens with
comment|//specific types. If no POS tags are available process all tokens
if|if
condition|(
name|pos
operator|==
literal|null
operator|||
name|includePOS
argument_list|(
name|pos
index|[
name|currentToken
index|]
argument_list|)
condition|)
block|{
comment|//process this token
if|if
condition|(
name|chunkSpans
operator|!=
literal|null
operator|&&
name|chunkPos
operator|<
name|chunkSpans
operator|.
name|length
condition|)
block|{
comment|//consume unused chunks (chunks use token index as start/end)
for|for
control|(
init|;
name|chunkSpans
index|[
name|chunkPos
index|]
operator|.
name|getEnd
argument_list|()
operator|<
name|currentToken
condition|;
name|chunkPos
operator|++
control|)
empty_stmt|;
name|current
operator|=
name|chunkSpans
index|[
name|chunkPos
index|]
expr_stmt|;
comment|//use the current chunk
name|chunkPos
operator|++
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|pos
operator|!=
literal|null
condition|)
block|{
comment|//if no Chunker is used
comment|//build chunks based on POS tags. For that we have a list
comment|//of tags that are followed (backwards and forwards)
name|int
name|start
init|=
name|currentToken
decl_stmt|;
while|while
condition|(
name|start
operator|-
literal|1
operator|>
name|consumed
operator|&&
name|followPOS
argument_list|(
name|pos
index|[
name|start
operator|-
literal|1
index|]
argument_list|)
condition|)
block|{
name|start
operator|--
expr_stmt|;
comment|//follow backwards until consumed
block|}
name|int
name|end
init|=
name|currentToken
decl_stmt|;
while|while
condition|(
name|end
operator|+
literal|1
operator|<
name|tokens
operator|.
name|length
operator|&&
name|followPOS
argument_list|(
name|pos
index|[
name|end
operator|+
literal|1
index|]
argument_list|)
condition|)
block|{
name|end
operator|++
expr_stmt|;
comment|//follow forwards until consumed
block|}
name|current
operator|=
operator|new
name|Span
argument_list|(
name|start
argument_list|,
name|end
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|//if no chunker and no POS tags just use the current token
name|current
operator|=
operator|new
name|Span
argument_list|(
name|currentToken
argument_list|,
name|currentToken
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|//ignore tokens with POS tags that are not included
name|current
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|current
operator|!=
literal|null
condition|)
block|{
name|consumed
operator|=
name|currentToken
expr_stmt|;
comment|//set consumed to the current token
comment|//calculate the search string and search tokens for the currently
comment|//active chunk
name|StringBuilder
name|labelBuilder
init|=
literal|null
decl_stmt|;
name|boolean
name|first
init|=
literal|true
decl_stmt|;
name|int
name|startIndex
init|=
name|current
operator|.
name|getStart
argument_list|()
decl_stmt|;
name|int
name|endIndex
init|=
name|current
operator|.
name|getEnd
argument_list|()
decl_stmt|;
comment|//we need also the tokens to filter results that may be included
comment|//because of the use of Tokenizers, Stemmers ...
name|List
argument_list|<
name|String
argument_list|>
name|searchTokens
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|(
name|current
operator|.
name|length
argument_list|()
operator|+
literal|1
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|j
init|=
name|current
operator|.
name|getStart
argument_list|()
init|;
name|j
operator|<=
name|current
operator|.
name|getEnd
argument_list|()
condition|;
name|j
operator|++
control|)
block|{
if|if
condition|(
operator|(
name|pos
operator|==
literal|null
operator|&&
name|tokens
index|[
name|j
index|]
operator|.
name|length
argument_list|()
operator|>=
name|minSearchTokenLength
operator|)
operator|||
operator|(
name|pos
operator|!=
literal|null
operator|&&
name|includePOS
argument_list|(
name|pos
index|[
name|j
index|]
argument_list|)
operator|)
condition|)
block|{
if|if
condition|(
operator|!
name|first
condition|)
block|{
name|labelBuilder
operator|.
name|append
argument_list|(
literal|' '
argument_list|)
expr_stmt|;
name|endIndex
operator|=
name|j
expr_stmt|;
comment|//update end
block|}
else|else
block|{
name|labelBuilder
operator|=
operator|new
name|StringBuilder
argument_list|()
expr_stmt|;
name|startIndex
operator|=
name|j
expr_stmt|;
comment|//set start
name|endIndex
operator|=
name|j
expr_stmt|;
comment|//set end
block|}
name|labelBuilder
operator|.
name|append
argument_list|(
name|tokens
index|[
name|j
index|]
argument_list|)
expr_stmt|;
name|searchTokens
operator|.
name|add
argument_list|(
name|tokens
index|[
name|j
index|]
argument_list|)
expr_stmt|;
name|first
operator|=
literal|false
expr_stmt|;
block|}
block|}
name|String
name|searchString
init|=
name|labelBuilder
operator|!=
literal|null
condition|?
name|labelBuilder
operator|.
name|toString
argument_list|()
else|:
literal|null
decl_stmt|;
if|if
condition|(
name|searchString
operator|!=
literal|null
operator|&&
operator|!
name|suggestionCache
operator|.
name|containsKey
argument_list|(
name|searchString
argument_list|)
condition|)
block|{
name|Suggestion
name|suggestion
init|=
name|suggestionCache
operator|.
name|get
argument_list|(
name|searchString
argument_list|)
decl_stmt|;
if|if
condition|(
name|suggestion
operator|!=
literal|null
condition|)
block|{
comment|//create TextAnnotation for this selection and add it to
comment|//the suggestions.
name|suggestion
operator|.
name|addLinked
argument_list|(
name|createTextAnnotation
argument_list|(
name|offset
argument_list|,
name|sentence
argument_list|,
name|tokenSpans
argument_list|,
name|ci
argument_list|,
name|startIndex
argument_list|,
name|endIndex
argument_list|,
name|suggestion
operator|.
name|getTextAnnotationTypes
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"processed: Entity {} is now mentioned {} times"
argument_list|,
name|searchString
argument_list|,
name|suggestion
operator|.
name|getLinkedTextAnnotations
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|//new word without an suggestion (suggestion == null)
name|List
argument_list|<
name|Representation
argument_list|>
name|suggestions
init|=
name|searchSuggestions
argument_list|(
name|site
argument_list|,
name|ci
argument_list|,
name|searchTokens
argument_list|,
name|searchString
argument_list|,
name|language
argument_list|,
name|sentence
argument_list|,
name|tokenSpans
argument_list|,
name|offset
argument_list|,
name|startIndex
argument_list|,
name|endIndex
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|suggestions
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|//we need to parse the types to get the dc:type
comment|//values for the TextAnnotations
name|Set
argument_list|<
name|UriRef
argument_list|>
name|textAnnotationTypes
init|=
operator|new
name|HashSet
argument_list|<
name|UriRef
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|Representation
name|rep
range|:
name|suggestions
control|)
block|{
name|Iterator
argument_list|<
name|Reference
argument_list|>
name|types
init|=
name|rep
operator|.
name|getReferences
argument_list|(
name|NamespaceEnum
operator|.
name|rdf
operator|+
literal|"type"
argument_list|)
decl_stmt|;
name|log
operator|.
name|info
argument_list|(
literal|"> Entity {}"
operator|+
name|rep
operator|.
name|getId
argument_list|()
argument_list|)
expr_stmt|;
while|while
condition|(
name|types
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|Reference
name|type
init|=
name|types
operator|.
name|next
argument_list|()
decl_stmt|;
name|log
operator|.
name|info
argument_list|(
literal|"  - type {}"
argument_list|,
name|type
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|UriRef
name|textAnnotationType
init|=
name|DEFAULT_ENTITY_TYPE_MAPPINGS
operator|.
name|get
argument_list|(
name|type
operator|.
name|getReference
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|textAnnotationType
operator|!=
literal|null
condition|)
block|{
name|textAnnotationTypes
operator|.
name|add
argument_list|(
name|textAnnotationType
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|UriRef
name|textAnnotation
init|=
name|createTextAnnotation
argument_list|(
name|offset
argument_list|,
name|sentence
argument_list|,
name|tokenSpans
argument_list|,
name|ci
argument_list|,
name|startIndex
argument_list|,
name|endIndex
argument_list|,
name|textAnnotationTypes
argument_list|)
decl_stmt|;
comment|//create a new suggestion
name|suggestion
operator|=
operator|new
name|Suggestion
argument_list|(
name|searchString
argument_list|,
name|textAnnotation
argument_list|,
name|suggestions
argument_list|,
name|textAnnotationTypes
argument_list|)
expr_stmt|;
comment|//mark the current selection as "consumed"
name|consumed
operator|=
name|current
operator|.
name|getEnd
argument_list|()
expr_stmt|;
comment|//also set the current token to the last consumed
comment|//to prevent processing of consumed tokens
name|currentToken
operator|=
name|current
operator|.
name|getEnd
argument_list|()
expr_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"processed: First mention of Entity {} "
argument_list|,
name|searchString
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|log
operator|.
name|debug
argument_list|(
literal|"processed: No suggestion for Entity {} "
argument_list|,
name|searchString
argument_list|)
expr_stmt|;
comment|//will add NULL to the suggestion cache and therefore
comment|//blacklist this "searchString"
block|}
comment|//NULL values are added to blacklist "searchStrings"
name|suggestionCache
operator|.
name|put
argument_list|(
name|searchString
argument_list|,
name|suggestion
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|log
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
comment|//ignore but do some debugging
if|if
condition|(
name|searchString
operator|!=
literal|null
condition|)
block|{
name|log
operator|.
name|debug
argument_list|(
literal|"ignore: {} already processed with no suggestions"
argument_list|,
name|searchString
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|log
operator|.
name|debug
argument_list|(
literal|"ignore {}"
argument_list|,
operator|new
name|Span
argument_list|(
name|tokenSpans
index|[
name|current
operator|.
name|getStart
argument_list|()
index|]
operator|.
name|getStart
argument_list|()
argument_list|,
name|tokenSpans
index|[
name|current
operator|.
name|getEnd
argument_list|()
index|]
operator|.
name|getEnd
argument_list|()
argument_list|)
operator|.
name|getCoveredText
argument_list|(
name|sentence
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
name|log
operator|.
name|debug
argument_list|(
literal|"ignore '{}'{}"
argument_list|,
name|tokens
index|[
name|currentToken
index|]
argument_list|,
operator|(
name|pos
operator|!=
literal|null
condition|?
literal|'_'
operator|+
name|pos
index|[
name|currentToken
index|]
else|:
literal|""
operator|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|void
name|wirteEntityEnhancements
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|Suggestion
argument_list|>
name|suggestionsCache
parameter_list|,
name|ContentItem
name|ci
parameter_list|,
name|String
name|nameField
parameter_list|,
name|String
name|language
parameter_list|)
block|{
for|for
control|(
name|Suggestion
name|suggestion
range|:
name|suggestionsCache
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|suggestion
operator|!=
literal|null
condition|)
block|{
comment|//this map contains NULL values -> ignore them
comment|//create EntityAnnotations for all the suggested Representations
name|Collection
argument_list|<
name|UriRef
argument_list|>
name|related
decl_stmt|;
if|if
condition|(
name|suggestion
operator|.
name|getLinkedTextAnnotations
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|related
operator|=
name|Collections
operator|.
name|singleton
argument_list|(
operator|(
name|UriRef
operator|)
name|suggestion
operator|.
name|getTextAnnotation
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|related
operator|=
operator|new
name|ArrayList
argument_list|<
name|UriRef
argument_list|>
argument_list|(
name|suggestion
operator|.
name|getLinkedTextAnnotations
argument_list|()
operator|.
name|size
argument_list|()
operator|+
literal|1
argument_list|)
expr_stmt|;
name|related
operator|.
name|add
argument_list|(
name|suggestion
operator|.
name|getTextAnnotation
argument_list|()
argument_list|)
expr_stmt|;
name|related
operator|.
name|addAll
argument_list|(
name|suggestion
operator|.
name|getLinkedTextAnnotations
argument_list|()
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|Representation
name|rep
range|:
name|suggestion
operator|.
name|getSuggestions
argument_list|()
control|)
block|{
name|EnhancementRDFUtils
operator|.
name|writeEntityAnnotation
argument_list|(
name|this
argument_list|,
name|literalFactory
argument_list|,
name|ci
argument_list|,
name|related
argument_list|,
name|rep
argument_list|,
name|nameField
argument_list|,
name|language
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**      * Searches the {@link ReferencedSite} or the {@link Entityhub} (depending      * on the configuration) for Entities corresponding to the search string.      * Results are compaired to the search tokens (to avoid false positives      * based on tokenizers and stemming).      * @param site      * @param ci      * @param searchTokens      * @param searchString      * @param language      * @param sentence      * @param tokenSpans      * @param offset      * @param startIndex      * @param endIndex      * @param ciId      * @return The Entities suggested for the parsed searchString. An empty list      * indicates that no entities where found      * @throws EngineException      */
specifier|private
name|List
argument_list|<
name|Representation
argument_list|>
name|searchSuggestions
parameter_list|(
name|ReferencedSite
name|site
parameter_list|,
name|ContentItem
name|ci
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|searchTokens
parameter_list|,
name|String
name|searchString
parameter_list|,
name|String
name|language
parameter_list|,
name|String
name|sentence
parameter_list|,
name|Span
index|[]
name|tokenSpans
parameter_list|,
name|int
name|offset
parameter_list|,
name|int
name|startIndex
parameter_list|,
name|int
name|endIndex
parameter_list|)
throws|throws
name|EngineException
block|{
name|List
argument_list|<
name|Representation
argument_list|>
name|processedResults
decl_stmt|;
name|FieldQuery
name|query
init|=
name|site
operator|!=
literal|null
condition|?
name|site
operator|.
name|getQueryFactory
argument_list|()
operator|.
name|createFieldQuery
argument_list|()
else|:
name|entityhub
operator|.
name|getQueryFactory
argument_list|()
operator|.
name|createFieldQuery
argument_list|()
decl_stmt|;
name|query
operator|.
name|addSelectedField
argument_list|(
name|nameField
argument_list|)
expr_stmt|;
name|query
operator|.
name|addSelectedField
argument_list|(
name|NamespaceEnum
operator|.
name|rdfs
operator|+
literal|"comment"
argument_list|)
expr_stmt|;
name|query
operator|.
name|addSelectedField
argument_list|(
name|NamespaceEnum
operator|.
name|rdf
operator|+
literal|"type"
argument_list|)
expr_stmt|;
name|query
operator|.
name|addSelectedField
argument_list|(
name|NamespaceEnum
operator|.
name|rdfs
operator|+
literal|"seeAlso"
argument_list|)
expr_stmt|;
name|query
operator|.
name|setConstraint
argument_list|(
name|nameField
argument_list|,
operator|new
name|TextConstraint
argument_list|(
name|searchString
argument_list|)
argument_list|)
expr_stmt|;
comment|//,language));
comment|//select 5 times the number of suggestion to allow some post
comment|//filtering
comment|//TODO: convert this to additional queries with offset
name|query
operator|.
name|setLimit
argument_list|(
name|Integer
operator|.
name|valueOf
argument_list|(
name|maxSuggestions
operator|*
literal|5
argument_list|)
argument_list|)
expr_stmt|;
name|QueryResultList
argument_list|<
name|Representation
argument_list|>
name|result
decl_stmt|;
try|try
block|{
name|result
operator|=
name|site
operator|!=
literal|null
condition|?
name|site
operator|.
name|find
argument_list|(
name|query
argument_list|)
else|:
name|entityhub
operator|.
name|find
argument_list|(
name|query
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|EntityhubException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|EngineException
argument_list|(
name|this
argument_list|,
name|ci
argument_list|,
name|String
operator|.
name|format
argument_list|(
literal|"Unable to search for Entity wiht label '%s@%s'"
argument_list|,
name|searchString
argument_list|,
name|language
argument_list|)
argument_list|,
name|e
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|result
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|processedResults
operator|=
operator|new
name|ArrayList
argument_list|<
name|Representation
argument_list|>
argument_list|(
name|maxSuggestions
argument_list|)
expr_stmt|;
for|for
control|(
name|Iterator
argument_list|<
name|Representation
argument_list|>
name|it
init|=
name|result
operator|.
name|iterator
argument_list|()
init|;
name|it
operator|.
name|hasNext
argument_list|()
operator|&&
name|processedResults
operator|.
name|size
argument_list|()
operator|<
name|maxSuggestions
condition|;
control|)
block|{
name|Representation
name|rep
init|=
name|it
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|checkLabels
argument_list|(
name|rep
operator|.
name|getText
argument_list|(
name|nameField
argument_list|)
argument_list|,
name|language
argument_list|,
name|searchTokens
argument_list|)
condition|)
block|{
comment|//based on the configuration we might need to do things for
comment|//redirects (rdfs:seeAlso links)
name|rep
operator|=
name|processRedirects
argument_list|(
name|site
argument_list|,
name|rep
argument_list|,
name|query
operator|.
name|getSelectedFields
argument_list|()
argument_list|)
expr_stmt|;
name|processedResults
operator|.
name|add
argument_list|(
name|rep
argument_list|)
expr_stmt|;
block|}
comment|//else ignore this result
block|}
block|}
else|else
block|{
name|processedResults
operator|=
name|Collections
operator|.
name|emptyList
argument_list|()
expr_stmt|;
block|}
return|return
name|processedResults
return|;
block|}
specifier|public
specifier|static
enum|enum
name|RedirectProcessingState
block|{
name|IGNORE
block|,
name|ADD_VALUES
block|,
name|FOLLOW
block|}
comment|/**      * @param site      * @param rep      * @param fields      */
specifier|private
name|Representation
name|processRedirects
parameter_list|(
name|ReferencedSite
name|site
parameter_list|,
name|Representation
name|rep
parameter_list|,
name|Collection
argument_list|<
name|String
argument_list|>
name|fields
parameter_list|)
block|{
name|Iterator
argument_list|<
name|Reference
argument_list|>
name|redirects
init|=
name|rep
operator|.
name|getReferences
argument_list|(
name|NamespaceEnum
operator|.
name|rdfs
operator|+
literal|"seeAlso"
argument_list|)
decl_stmt|;
switch|switch
condition|(
name|redirectState
operator|==
literal|null
condition|?
name|RedirectProcessingState
operator|.
name|IGNORE
else|:
name|redirectState
condition|)
block|{
case|case
name|ADD_VALUES
case|:
while|while
condition|(
name|redirects
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|Reference
name|redirect
init|=
name|redirects
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|redirect
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|Entity
name|redirectedEntity
init|=
name|site
operator|!=
literal|null
condition|?
name|site
operator|.
name|getEntity
argument_list|(
name|redirect
operator|.
name|getReference
argument_list|()
argument_list|)
else|:
name|entityhub
operator|.
name|getEntity
argument_list|(
name|redirect
operator|.
name|getReference
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|redirectedEntity
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|String
name|field
range|:
name|fields
control|)
block|{
name|rep
operator|.
name|add
argument_list|(
name|field
argument_list|,
name|redirectedEntity
operator|.
name|getRepresentation
argument_list|()
operator|.
name|get
argument_list|(
name|field
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|EntityhubException
name|e
parameter_list|)
block|{
name|log
operator|.
name|info
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Unable to follow redirect to '%s' for Entity '%s'"
argument_list|,
name|redirect
operator|.
name|getReference
argument_list|()
argument_list|,
name|rep
operator|.
name|getId
argument_list|()
argument_list|)
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|rep
return|;
case|case
name|FOLLOW
case|:
while|while
condition|(
name|redirects
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|Reference
name|redirect
init|=
name|redirects
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|redirect
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|Entity
name|redirectedEntity
init|=
name|site
operator|!=
literal|null
condition|?
name|site
operator|.
name|getEntity
argument_list|(
name|redirect
operator|.
name|getReference
argument_list|()
argument_list|)
else|:
name|entityhub
operator|.
name|getEntity
argument_list|(
name|redirect
operator|.
name|getReference
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|redirectedEntity
operator|!=
literal|null
condition|)
block|{
return|return
name|redirectedEntity
operator|.
name|getRepresentation
argument_list|()
return|;
block|}
block|}
catch|catch
parameter_list|(
name|EntityhubException
name|e
parameter_list|)
block|{
name|log
operator|.
name|info
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Unable to follow redirect to '%s' for Entity '%s'"
argument_list|,
name|redirect
operator|.
name|getReference
argument_list|()
argument_list|,
name|rep
operator|.
name|getId
argument_list|()
argument_list|)
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|rep
return|;
comment|//no redirect found
default|default:
return|return
name|rep
return|;
block|}
block|}
comment|/**      * Checks if the labels of an Entity confirm to the searchTokens. Because of      * Stemming an Tokenizers might be used for indexing the Dictionary this need      * to be done on the client side.      * @param labels the labels to check      * @param language the language      * @param searchTokens the required tokens      * @return<code>true</code> if a label was acceptable or<code>false</code>      * if no label was found      */
specifier|private
name|boolean
name|checkLabels
parameter_list|(
name|Iterator
argument_list|<
name|Text
argument_list|>
name|labels
parameter_list|,
name|String
name|language
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|searchTokens
parameter_list|)
block|{
while|while
condition|(
name|labels
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|Text
name|label
init|=
name|labels
operator|.
name|next
argument_list|()
decl_stmt|;
comment|//NOTE: I use here startWith language because I want 'en-GB' labels accepted for 'en'
if|if
condition|(
name|label
operator|.
name|getLanguage
argument_list|()
operator|==
literal|null
operator|||
name|label
operator|.
name|getLanguage
argument_list|()
operator|.
name|startsWith
argument_list|(
name|language
argument_list|)
condition|)
block|{
name|String
name|text
init|=
name|label
operator|.
name|getText
argument_list|()
operator|.
name|toLowerCase
argument_list|()
decl_stmt|;
if|if
condition|(
name|searchTokens
operator|.
name|size
argument_list|()
operator|>
literal|1
condition|)
block|{
name|int
name|foundTokens
init|=
literal|0
decl_stmt|;
for|for
control|(
name|String
name|token
range|:
name|searchTokens
control|)
block|{
if|if
condition|(
name|text
operator|.
name|indexOf
argument_list|(
name|token
operator|.
name|toLowerCase
argument_list|()
argument_list|)
operator|>=
literal|0
condition|)
block|{
name|foundTokens
operator|++
expr_stmt|;
block|}
block|}
if|if
condition|(
name|foundTokens
operator|==
name|searchTokens
operator|.
name|size
argument_list|()
operator|||
name|foundTokens
operator|>=
name|minFoundTokens
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
else|else
block|{
comment|//for single searchToken queries there are often results with
comment|//multiple words. We need to filter those
comment|//e.g. for persons only referenced by the given or family name
if|if
condition|(
name|text
operator|.
name|equalsIgnoreCase
argument_list|(
name|searchTokens
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
block|}
block|}
return|return
literal|false
return|;
block|}
comment|/**      * @param sentenceOffset      * @param sentence      * @param tokenSpans      * @param metadata      * @param contentItemId      * @param startTokenIndex      * @param endTokenIndex      * @param dcTypes      * @return      */
specifier|private
name|UriRef
name|createTextAnnotation
parameter_list|(
name|int
name|sentenceOffset
parameter_list|,
name|String
name|sentence
parameter_list|,
name|Span
index|[]
name|tokenSpans
parameter_list|,
name|ContentItem
name|ci
parameter_list|,
name|int
name|startTokenIndex
parameter_list|,
name|int
name|endTokenIndex
parameter_list|,
name|Set
argument_list|<
name|UriRef
argument_list|>
name|dcTypes
parameter_list|)
block|{
name|MGraph
name|metadata
init|=
name|ci
operator|.
name|getMetadata
argument_list|()
decl_stmt|;
name|UriRef
name|contentItemId
init|=
name|ci
operator|.
name|getUri
argument_list|()
decl_stmt|;
name|UriRef
name|textAnnotation
init|=
name|EnhancementEngineHelper
operator|.
name|createTextEnhancement
argument_list|(
name|metadata
argument_list|,
name|this
argument_list|,
name|contentItemId
argument_list|)
decl_stmt|;
name|int
name|startChar
init|=
name|tokenSpans
index|[
name|startTokenIndex
index|]
operator|.
name|getStart
argument_list|()
decl_stmt|;
name|int
name|endChar
init|=
name|tokenSpans
index|[
name|endTokenIndex
index|]
operator|.
name|getEnd
argument_list|()
decl_stmt|;
name|metadata
operator|.
name|add
argument_list|(
operator|new
name|TripleImpl
argument_list|(
name|textAnnotation
argument_list|,
name|Properties
operator|.
name|ENHANCER_START
argument_list|,
name|literalFactory
operator|.
name|createTypedLiteral
argument_list|(
name|sentenceOffset
operator|+
name|startChar
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|metadata
operator|.
name|add
argument_list|(
operator|new
name|TripleImpl
argument_list|(
name|textAnnotation
argument_list|,
name|Properties
operator|.
name|ENHANCER_END
argument_list|,
name|literalFactory
operator|.
name|createTypedLiteral
argument_list|(
name|sentenceOffset
operator|+
name|endChar
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|metadata
operator|.
name|add
argument_list|(
operator|new
name|TripleImpl
argument_list|(
name|textAnnotation
argument_list|,
name|Properties
operator|.
name|ENHANCER_SELECTED_TEXT
argument_list|,
operator|new
name|PlainLiteralImpl
argument_list|(
operator|new
name|Span
argument_list|(
name|startChar
argument_list|,
name|endChar
argument_list|)
operator|.
name|getCoveredText
argument_list|(
name|sentence
argument_list|)
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|metadata
operator|.
name|add
argument_list|(
operator|new
name|TripleImpl
argument_list|(
name|textAnnotation
argument_list|,
name|Properties
operator|.
name|ENHANCER_SELECTION_CONTEXT
argument_list|,
operator|new
name|PlainLiteralImpl
argument_list|(
name|sentence
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
for|for
control|(
name|UriRef
name|type
range|:
name|dcTypes
control|)
block|{
name|metadata
operator|.
name|add
argument_list|(
operator|new
name|TripleImpl
argument_list|(
name|textAnnotation
argument_list|,
name|Properties
operator|.
name|DC_TYPE
argument_list|,
name|type
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|textAnnotation
return|;
block|}
comment|/**      * Set of POS tags used to build chunks of no {@link Chunker} is used.      * NOTE that all tags starting with 'N' (Nouns) are included anyway      */
specifier|public
specifier|static
specifier|final
name|Set
argument_list|<
name|String
argument_list|>
name|followPosSet
init|=
name|Collections
operator|.
name|unmodifiableSet
argument_list|(
operator|new
name|TreeSet
argument_list|<
name|String
argument_list|>
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
literal|"#"
argument_list|,
literal|"$"
argument_list|,
literal|" "
argument_list|,
literal|"("
argument_list|,
literal|")"
argument_list|,
literal|","
argument_list|,
literal|"."
argument_list|,
literal|":"
argument_list|,
literal|"``"
argument_list|,
literal|"POS"
argument_list|,
literal|"CD"
argument_list|,
literal|"IN"
argument_list|,
literal|"FW"
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
comment|//,"''")));
comment|/**      * Set of POS tags used for searches.      * NOTE that all tags starting with 'N' (Nouns) are included anyway      */
specifier|public
specifier|static
specifier|final
name|Set
argument_list|<
name|String
argument_list|>
name|searchPosSet
init|=
name|Collections
operator|.
name|unmodifiableSet
argument_list|(
operator|new
name|TreeSet
argument_list|<
name|String
argument_list|>
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
literal|"FW"
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
comment|//,"''")));
comment|/**      * TODO: This might be language specific!      * @param pos      * @return      */
specifier|private
name|boolean
name|followPOS
parameter_list|(
name|String
name|pos
parameter_list|)
block|{
return|return
name|pos
operator|.
name|charAt
argument_list|(
literal|0
argument_list|)
operator|==
literal|'N'
operator|||
name|followPosSet
operator|.
name|contains
argument_list|(
name|pos
argument_list|)
return|;
block|}
specifier|private
name|boolean
name|includePOS
parameter_list|(
name|String
name|pos
parameter_list|)
block|{
return|return
name|pos
operator|.
name|charAt
argument_list|(
literal|0
argument_list|)
operator|==
literal|'N'
operator|||
name|searchPosSet
operator|.
name|contains
argument_list|(
name|pos
argument_list|)
return|;
block|}
comment|/**      * @param language      * @return      */
specifier|private
name|Tokenizer
name|initTokenizer
parameter_list|(
name|String
name|language
parameter_list|)
block|{
name|Tokenizer
name|tokenizer
decl_stmt|;
if|if
condition|(
name|useSimpleTokenizer
condition|)
block|{
name|tokenizer
operator|=
name|SimpleTokenizer
operator|.
name|INSTANCE
expr_stmt|;
block|}
else|else
block|{
name|tokenizer
operator|=
name|openNLP
operator|.
name|getTokenizer
argument_list|(
name|language
argument_list|)
expr_stmt|;
block|}
return|return
name|tokenizer
return|;
block|}
comment|/**      * @param language      * @return      */
specifier|private
name|POSTaggerME
name|initTagger
parameter_list|(
name|String
name|language
parameter_list|)
block|{
name|POSTaggerME
name|posTagger
decl_stmt|;
try|try
block|{
name|POSModel
name|posModel
init|=
name|openNLP
operator|.
name|getPartOfSpeachModel
argument_list|(
name|language
argument_list|)
decl_stmt|;
if|if
condition|(
name|posModel
operator|!=
literal|null
condition|)
block|{
name|posTagger
operator|=
operator|new
name|POSTaggerME
argument_list|(
name|posModel
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|log
operator|.
name|debug
argument_list|(
literal|"No POS Model for language {}"
argument_list|,
name|language
argument_list|)
expr_stmt|;
name|posTagger
operator|=
literal|null
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|log
operator|.
name|info
argument_list|(
literal|"Unable to load POS Model for language "
operator|+
name|language
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|posTagger
operator|=
literal|null
expr_stmt|;
block|}
return|return
name|posTagger
return|;
block|}
comment|/**      * @param language      * @return      */
specifier|private
name|SentenceDetector
name|initSentence
parameter_list|(
name|String
name|language
parameter_list|)
block|{
name|SentenceDetector
name|sentDetect
decl_stmt|;
try|try
block|{
name|SentenceModel
name|sentModel
init|=
name|openNLP
operator|.
name|getSentenceModel
argument_list|(
name|language
argument_list|)
decl_stmt|;
if|if
condition|(
name|sentModel
operator|!=
literal|null
condition|)
block|{
name|sentDetect
operator|=
operator|new
name|SentenceDetectorME
argument_list|(
name|sentModel
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|log
operator|.
name|debug
argument_list|(
literal|"No Sentence Detection Model for language {}"
argument_list|,
name|language
argument_list|)
expr_stmt|;
name|sentDetect
operator|=
literal|null
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|log
operator|.
name|info
argument_list|(
literal|"Unable to load Sentence Detection Model for language "
operator|+
name|language
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|sentDetect
operator|=
literal|null
expr_stmt|;
block|}
return|return
name|sentDetect
return|;
block|}
comment|/**      * @param language      */
specifier|private
name|ChunkerME
name|initChunker
parameter_list|(
name|String
name|language
parameter_list|)
block|{
name|ChunkerME
name|chunker
decl_stmt|;
try|try
block|{
name|ChunkerModel
name|chunkerModel
init|=
name|openNLP
operator|.
name|getChunkerModel
argument_list|(
name|language
argument_list|)
decl_stmt|;
if|if
condition|(
name|chunkerModel
operator|!=
literal|null
condition|)
block|{
name|chunker
operator|=
operator|new
name|ChunkerME
argument_list|(
name|chunkerModel
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|log
operator|.
name|debug
argument_list|(
literal|"No Chunker Model for language {}"
argument_list|,
name|language
argument_list|)
expr_stmt|;
name|chunker
operator|=
literal|null
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|log
operator|.
name|info
argument_list|(
literal|"Unable to load Chunker Model for language "
operator|+
name|language
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|chunker
operator|=
literal|null
expr_stmt|;
block|}
return|return
name|chunker
return|;
block|}
annotation|@
name|Override
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|Object
argument_list|>
name|getServiceProperties
parameter_list|()
block|{
return|return
name|Collections
operator|.
name|unmodifiableMap
argument_list|(
name|Collections
operator|.
name|singletonMap
argument_list|(
name|ENHANCEMENT_ENGINE_ORDERING
argument_list|,
operator|(
name|Object
operator|)
name|defaultOrder
argument_list|)
argument_list|)
return|;
block|}
block|}
end_class

end_unit

