begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|refactor
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|BufferedReader
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStreamReader
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Dictionary
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Enumeration
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|clerezza
operator|.
name|rdf
operator|.
name|core
operator|.
name|MGraph
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|clerezza
operator|.
name|rdf
operator|.
name|core
operator|.
name|Resource
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|clerezza
operator|.
name|rdf
operator|.
name|core
operator|.
name|Triple
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|clerezza
operator|.
name|rdf
operator|.
name|core
operator|.
name|TripleCollection
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|clerezza
operator|.
name|rdf
operator|.
name|core
operator|.
name|UriRef
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|clerezza
operator|.
name|rdf
operator|.
name|core
operator|.
name|impl
operator|.
name|SimpleMGraph
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|Activate
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|Component
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|ConfigurationPolicy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|Property
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|Reference
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|Service
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|commons
operator|.
name|owl
operator|.
name|transformation
operator|.
name|OWLAPIToClerezzaConverter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|refactor
operator|.
name|dereferencer
operator|.
name|Dereferencer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|refactor
operator|.
name|dereferencer
operator|.
name|IDereferencer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|servicesapi
operator|.
name|ContentItem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|servicesapi
operator|.
name|EngineException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|servicesapi
operator|.
name|EnhancementEngine
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|servicesapi
operator|.
name|ServiceProperties
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|servicesapi
operator|.
name|helper
operator|.
name|AbstractEnhancementEngine
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|core
operator|.
name|utils
operator|.
name|OsgiUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|model
operator|.
name|clerezza
operator|.
name|RdfRepresentation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|model
operator|.
name|clerezza
operator|.
name|RdfValueFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|servicesapi
operator|.
name|model
operator|.
name|Entity
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|servicesapi
operator|.
name|model
operator|.
name|Representation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|servicesapi
operator|.
name|site
operator|.
name|ReferencedSiteManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|ontologymanager
operator|.
name|ontonet
operator|.
name|api
operator|.
name|DuplicateIDException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|ontologymanager
operator|.
name|ontonet
operator|.
name|api
operator|.
name|ONManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|ontologymanager
operator|.
name|ontonet
operator|.
name|api
operator|.
name|io
operator|.
name|OntologyInputSource
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|ontologymanager
operator|.
name|ontonet
operator|.
name|api
operator|.
name|ontology
operator|.
name|OntologyScope
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|ontologymanager
operator|.
name|ontonet
operator|.
name|api
operator|.
name|ontology
operator|.
name|OntologyScopeFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|ontologymanager
operator|.
name|ontonet
operator|.
name|api
operator|.
name|ontology
operator|.
name|OntologySpace
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|ontologymanager
operator|.
name|ontonet
operator|.
name|api
operator|.
name|ontology
operator|.
name|ScopeRegistry
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|ontologymanager
operator|.
name|ontonet
operator|.
name|api
operator|.
name|ontology
operator|.
name|UnmodifiableOntologyCollectorException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|ontologymanager
operator|.
name|ontonet
operator|.
name|api
operator|.
name|session
operator|.
name|Session
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|ontologymanager
operator|.
name|ontonet
operator|.
name|api
operator|.
name|session
operator|.
name|SessionLimitException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|ontologymanager
operator|.
name|ontonet
operator|.
name|api
operator|.
name|session
operator|.
name|SessionManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|rules
operator|.
name|base
operator|.
name|api
operator|.
name|NoSuchRecipeException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|rules
operator|.
name|base
operator|.
name|api
operator|.
name|Recipe
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|rules
operator|.
name|base
operator|.
name|api
operator|.
name|Rule
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|rules
operator|.
name|base
operator|.
name|api
operator|.
name|RuleStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|rules
operator|.
name|base
operator|.
name|api
operator|.
name|util
operator|.
name|RuleList
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|rules
operator|.
name|refactor
operator|.
name|api
operator|.
name|Refactorer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|rules
operator|.
name|refactor
operator|.
name|api
operator|.
name|RefactoringException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|osgi
operator|.
name|service
operator|.
name|cm
operator|.
name|ConfigurationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|osgi
operator|.
name|service
operator|.
name|component
operator|.
name|ComponentContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|osgi
operator|.
name|service
operator|.
name|component
operator|.
name|ComponentFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|osgi
operator|.
name|service
operator|.
name|component
operator|.
name|ComponentInstance
import|;
end_import

begin_import
import|import
name|org
operator|.
name|semanticweb
operator|.
name|owlapi
operator|.
name|apibinding
operator|.
name|OWLManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|semanticweb
operator|.
name|owlapi
operator|.
name|model
operator|.
name|IRI
import|;
end_import

begin_import
import|import
name|org
operator|.
name|semanticweb
operator|.
name|owlapi
operator|.
name|model
operator|.
name|OWLOntology
import|;
end_import

begin_import
import|import
name|org
operator|.
name|semanticweb
operator|.
name|owlapi
operator|.
name|model
operator|.
name|OWLOntologyCreationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|semanticweb
operator|.
name|owlapi
operator|.
name|model
operator|.
name|OWLOntologyManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|semanticweb
operator|.
name|owlapi
operator|.
name|model
operator|.
name|OWLOntologySetProvider
import|;
end_import

begin_import
import|import
name|org
operator|.
name|semanticweb
operator|.
name|owlapi
operator|.
name|util
operator|.
name|OWLOntologyMerger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/**  *   * This an engine to post-process the enhancements. Its main goal is to refactor the RDF produced by the  * enhancement applying some vocabulary related to a specific task.  *   * To do that, exploit a Refactor recipe and an ontology scope of OntoNet.  *   * The first implementation is targeted to SEO use case. * It retrieves data by dereferencing the entities, *  * includes the DBpedia ontology * refactor the data using the google rich snippets vocabulary.  *   * @author andrea.nuzzolese, alberto.musetti  *   */
end_comment

begin_class
annotation|@
name|Component
argument_list|(
name|configurationFactory
operator|=
literal|true
argument_list|,
name|policy
operator|=
name|ConfigurationPolicy
operator|.
name|REQUIRE
argument_list|,
name|specVersion
operator|=
literal|"1.1"
argument_list|,
name|metatype
operator|=
literal|true
argument_list|,
name|immediate
operator|=
literal|true
argument_list|,
name|inherit
operator|=
literal|true
argument_list|)
annotation|@
name|Service
annotation|@
name|Properties
argument_list|(
name|value
operator|=
block|{
annotation|@
name|Property
argument_list|(
name|name
operator|=
name|EnhancementEngine
operator|.
name|PROPERTY_NAME
argument_list|)
block|}
argument_list|)
specifier|public
class|class
name|RefactorEnhancementEngine
extends|extends
name|AbstractEnhancementEngine
argument_list|<
name|RuntimeException
argument_list|,
name|RuntimeException
argument_list|>
implements|implements
name|EnhancementEngine
implements|,
name|ServiceProperties
block|{
comment|/*      * TODO This are the scope and recipe IDs to be used by this implementation In future implementation this      * will be configurable      */
annotation|@
name|Property
argument_list|()
specifier|public
specifier|static
specifier|final
name|String
name|SCOPE
init|=
name|RefactorEnhancementEngineConf
operator|.
name|SCOPE
decl_stmt|;
annotation|@
name|Property
argument_list|()
specifier|public
specifier|static
specifier|final
name|String
name|RECIPE_LOCATION
init|=
name|RefactorEnhancementEngineConf
operator|.
name|RECIPE_LOCATION
decl_stmt|;
annotation|@
name|Property
argument_list|()
specifier|public
specifier|static
specifier|final
name|String
name|RECIPE_ID
init|=
name|RefactorEnhancementEngineConf
operator|.
name|RECIPE_ID
decl_stmt|;
annotation|@
name|Property
argument_list|(
name|cardinality
operator|=
literal|1000
argument_list|)
specifier|public
specifier|static
specifier|final
name|String
name|SCOPE_CORE_ONTOLOGY
init|=
name|RefactorEnhancementEngineConf
operator|.
name|SCOPE_CORE_ONTOLOGY
decl_stmt|;
annotation|@
name|Property
argument_list|()
specifier|public
specifier|static
specifier|final
name|String
name|APPEND_OTHER_ENHANCEMENT_GRAPHS
init|=
name|RefactorEnhancementEngineConf
operator|.
name|APPEND_OTHER_ENHANCEMENT_GRAPHS
decl_stmt|;
annotation|@
name|Property
argument_list|()
specifier|public
specifier|static
specifier|final
name|String
name|USE_ENTITY_HUB
init|=
name|RefactorEnhancementEngineConf
operator|.
name|USE_ENTITY_HUB
decl_stmt|;
annotation|@
name|Reference
name|ONManager
name|onManager
decl_stmt|;
annotation|@
name|Reference
name|SessionManager
name|sessionManager
decl_stmt|;
annotation|@
name|Reference
name|ReferencedSiteManager
name|referencedSiteManager
decl_stmt|;
annotation|@
name|Reference
name|RuleStore
name|ruleStore
decl_stmt|;
annotation|@
name|Reference
name|Refactorer
name|refactorer
decl_stmt|;
specifier|private
name|RefactorEnhancementEngineConf
name|engineConfiguration
decl_stmt|;
specifier|private
name|ComponentInstance
name|refactorEngineComponentInstance
decl_stmt|;
specifier|private
name|OntologyScope
name|scope
decl_stmt|;
specifier|private
specifier|final
name|Logger
name|log
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|getClass
argument_list|()
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|Object
name|lock
init|=
operator|new
name|Object
argument_list|()
decl_stmt|;
specifier|private
name|ComponentContext
name|context
decl_stmt|;
annotation|@
name|Override
specifier|public
name|int
name|canEnhance
parameter_list|(
name|ContentItem
name|ci
parameter_list|)
throws|throws
name|EngineException
block|{
comment|/*          * The Refactor can enhance only content items that are previously enhanced by other enhancement          * engines, as it must be the last engine in the chain.          *           * Works only if some enhancement has been produced.          */
name|MGraph
name|mGraph
init|=
name|ci
operator|.
name|getMetadata
argument_list|()
decl_stmt|;
if|if
condition|(
name|mGraph
operator|!=
literal|null
condition|)
block|{
return|return
name|ENHANCE_SYNCHRONOUS
return|;
block|}
else|else
block|{
return|return
name|CANNOT_ENHANCE
return|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|computeEnhancements
parameter_list|(
name|ContentItem
name|ci
parameter_list|)
throws|throws
name|EngineException
block|{
comment|/*          * Retrieve the graph          */
specifier|final
name|MGraph
name|mGraph
init|=
name|ci
operator|.
name|getMetadata
argument_list|()
decl_stmt|;
comment|/*          * We filter the entities recognized by the engines          */
name|UriRef
name|fiseEntityReference
init|=
operator|new
name|UriRef
argument_list|(
literal|"http://fise.iks-project.eu/ontology/entity-reference"
argument_list|)
decl_stmt|;
name|Iterator
argument_list|<
name|Triple
argument_list|>
name|tripleIt
init|=
name|mGraph
operator|.
name|filter
argument_list|(
literal|null
argument_list|,
name|fiseEntityReference
argument_list|,
literal|null
argument_list|)
decl_stmt|;
comment|/*          * Now we prepare the OntoNet environment. First we create the OntoNet session in which run the whole          */
comment|// String sessionID = null;
name|Session
name|tmpSession
init|=
literal|null
decl_stmt|;
try|try
block|{
name|tmpSession
operator|=
name|sessionManager
operator|.
name|createSession
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|SessionLimitException
name|e1
parameter_list|)
block|{
comment|// TODO Auto-generated catch block
name|e1
operator|.
name|printStackTrace
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|tmpSession
operator|!=
literal|null
condition|)
block|{
specifier|final
name|Session
name|session
init|=
name|tmpSession
decl_stmt|;
comment|// final String sessionIdentifier = sessionID;
comment|/*              * We retrieve the session space              */
comment|// OntologySpace sessionSpace = scope.getSessionSpace(sessionIdentifier);
name|log
operator|.
name|debug
argument_list|(
literal|"The session space is "
operator|+
name|session
argument_list|)
expr_stmt|;
while|while
condition|(
name|tripleIt
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|Triple
name|triple
init|=
name|tripleIt
operator|.
name|next
argument_list|()
decl_stmt|;
name|Resource
name|entityReference
init|=
name|triple
operator|.
name|getObject
argument_list|()
decl_stmt|;
comment|/*                  * the entity uri                  */
specifier|final
name|String
name|entityReferenceString
init|=
name|entityReference
operator|.
name|toString
argument_list|()
operator|.
name|replace
argument_list|(
literal|"<"
argument_list|,
literal|""
argument_list|)
operator|.
name|replace
argument_list|(
literal|">"
argument_list|,
literal|""
argument_list|)
decl_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Trying to resolve entity "
operator|+
name|entityReferenceString
argument_list|)
expr_stmt|;
comment|/**                  * We fetch the entity in the OntologyInputSource object                  */
try|try
block|{
specifier|final
name|IRI
name|fetchedIri
init|=
name|IRI
operator|.
name|create
argument_list|(
name|entityReferenceString
argument_list|)
decl_stmt|;
comment|/*                      * The RDF graph of an entity is fetched via the EntityHub. The getEntityOntology is a                      * method the do the job of asking the entity to the EntityHub and wrap the RDF graph into                      * an OWLOntology.                      */
name|OWLOntology
name|fetched
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|engineConfiguration
operator|.
name|isEntityHubUsed
argument_list|()
condition|)
block|{
name|fetched
operator|=
name|getEntityOntology
argument_list|(
name|entityReferenceString
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Dereferencer
name|dereferencer
init|=
operator|new
name|Dereferencer
argument_list|()
decl_stmt|;
try|try
block|{
name|fetched
operator|=
name|OWLManager
operator|.
name|createOWLOntologyManager
argument_list|()
operator|.
name|loadOntologyFromOntologyDocument
argument_list|(
name|dereferencer
operator|.
name|resolve
argument_list|(
name|entityReferenceString
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|OWLOntologyCreationException
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"An error occurred while trying to create the ontology related to the entity "
operator|+
name|entityReferenceString
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"The entity "
operator|+
name|entityReferenceString
operator|+
literal|" does not exist or is unreachable"
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|fetched
operator|!=
literal|null
condition|)
block|{
specifier|final
name|OWLOntology
name|fetchedFinal
init|=
name|fetched
decl_stmt|;
name|OntologyInputSource
name|ontologySource
init|=
operator|new
name|OntologyInputSource
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|hasRootOntology
parameter_list|()
block|{
return|return
operator|(
name|fetchedFinal
operator|!=
literal|null
operator|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|hasPhysicalIRI
parameter_list|()
block|{
return|return
literal|true
return|;
block|}
annotation|@
name|Override
specifier|public
name|OWLOntology
name|getRootOntology
parameter_list|()
block|{
return|return
name|fetchedFinal
return|;
block|}
annotation|@
name|Override
specifier|public
name|IRI
name|getPhysicalIRI
parameter_list|()
block|{
return|return
name|fetchedIri
return|;
block|}
annotation|@
name|Override
specifier|public
name|Set
argument_list|<
name|OWLOntology
argument_list|>
name|getImports
parameter_list|(
name|boolean
name|direct
parameter_list|)
block|{
comment|// TODO Auto-generated method stub
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|getStorageKey
parameter_list|()
block|{
comment|// TODO Auto-generated method stub
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|Object
name|getTriplesProvider
parameter_list|()
block|{
comment|// TODO Auto-generated method stub
return|return
literal|null
return|;
block|}
block|}
decl_stmt|;
name|session
operator|.
name|addOntology
argument_list|(
name|ontologySource
argument_list|)
expr_stmt|;
block|}
name|log
operator|.
name|debug
argument_list|(
literal|"Added "
operator|+
name|entityReferenceString
operator|+
literal|" to the session space of scope "
operator|+
name|engineConfiguration
operator|.
name|getScope
argument_list|()
argument_list|,
name|this
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|UnmodifiableOntologyCollectorException
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"Cannot load the entity"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*              * Now we merge the RDF from the T-box - the ontologies - and the A-box - the RDF data fetched              */
specifier|final
name|OWLOntologyManager
name|man
init|=
name|OWLManager
operator|.
name|createOWLOntologyManager
argument_list|()
decl_stmt|;
name|OWLOntologySetProvider
name|provider
init|=
operator|new
name|OWLOntologySetProvider
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Set
argument_list|<
name|OWLOntology
argument_list|>
name|getOntologies
parameter_list|()
block|{
name|Set
argument_list|<
name|OWLOntology
argument_list|>
name|ontologies
init|=
operator|new
name|HashSet
argument_list|<
name|OWLOntology
argument_list|>
argument_list|()
decl_stmt|;
name|ontologies
operator|.
name|addAll
argument_list|(
name|session
operator|.
name|getOntologies
argument_list|(
literal|true
argument_list|)
argument_list|)
expr_stmt|;
comment|/*                      * We add to the set the graph containing the metadata generated by previous enhancement                      * engines. It is important becaus we want to menage during the refactoring also some                      * information fron that graph. As the graph is provided as a Clerezza MGraph, we first                      * need to convert it to an OWLAPI OWLOntology. There is no chance that the mGraph could                      * be null as it was previously controlled by the JobManager through the canEnhance method                      * and the computeEnhancement is always called iff the former returns true.                      */
name|OWLOntology
name|fiseMetadataOntology
init|=
name|OWLAPIToClerezzaConverter
operator|.
name|clerezzaGraphToOWLOntology
argument_list|(
name|mGraph
argument_list|)
decl_stmt|;
name|ontologies
operator|.
name|add
argument_list|(
name|fiseMetadataOntology
argument_list|)
expr_stmt|;
return|return
name|ontologies
return|;
block|}
block|}
decl_stmt|;
comment|/*              * We merge all the ontologies from the session space of the scope into a single ontology that              * will be used for the refactoring.              */
name|OWLOntologyMerger
name|merger
init|=
operator|new
name|OWLOntologyMerger
argument_list|(
name|provider
argument_list|)
decl_stmt|;
name|OWLOntology
name|ontology
decl_stmt|;
try|try
block|{
name|ontology
operator|=
name|merger
operator|.
name|createMergedOntology
argument_list|(
name|man
argument_list|,
name|IRI
operator|.
name|create
argument_list|(
literal|"http://fise.iks-project.eu/dulcifier/integrity-check"
argument_list|)
argument_list|)
expr_stmt|;
comment|/*                  * To perform the refactoring of the ontology to a given vocabulary we use the Stanbol                  * Refactor.                  */
name|log
operator|.
name|debug
argument_list|(
literal|"Refactoring recipe IRI is : "
operator|+
name|engineConfiguration
operator|.
name|getRecipeId
argument_list|()
argument_list|)
expr_stmt|;
comment|/*                  * We pass the ontology and the recipe IRI to the Refactor that returns the refactored graph                  * expressed by using the given vocabulary.                  */
try|try
block|{
name|Recipe
name|recipe
init|=
name|ruleStore
operator|.
name|getRecipe
argument_list|(
name|IRI
operator|.
name|create
argument_list|(
name|engineConfiguration
operator|.
name|getRecipeId
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Rules in the recipe are : "
operator|+
name|recipe
operator|.
name|getkReSRuleList
argument_list|()
operator|.
name|size
argument_list|()
argument_list|,
name|this
argument_list|)
expr_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"The ontology to be refactor is : "
operator|+
name|ontology
argument_list|,
name|this
argument_list|)
expr_stmt|;
name|ontology
operator|=
name|refactorer
operator|.
name|ontologyRefactoring
argument_list|(
name|ontology
argument_list|,
name|IRI
operator|.
name|create
argument_list|(
name|engineConfiguration
operator|.
name|getRecipeId
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|RefactoringException
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"The refactoring engine failed the execution."
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchRecipeException
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"The recipe with ID "
operator|+
name|engineConfiguration
operator|.
name|getRecipeId
argument_list|()
operator|+
literal|" does not exists"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
name|log
operator|.
name|debug
argument_list|(
literal|"Merged ontologies in "
operator|+
name|ontology
argument_list|)
expr_stmt|;
comment|/*                  * The new generated ontology is converted to Clarezza format and than added os substitued to                  * the old mGraph.                  */
if|if
condition|(
name|engineConfiguration
operator|.
name|isInGraphAppendMode
argument_list|()
condition|)
block|{
name|mGraph
operator|.
name|addAll
argument_list|(
name|OWLAPIToClerezzaConverter
operator|.
name|owlOntologyToClerezzaTriples
argument_list|(
name|ontology
argument_list|)
argument_list|)
expr_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Metadata of the content passd have been substituted"
argument_list|,
name|this
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mGraph
operator|.
name|removeAll
argument_list|(
name|mGraph
argument_list|)
expr_stmt|;
name|mGraph
operator|.
name|addAll
argument_list|(
name|OWLAPIToClerezzaConverter
operator|.
name|owlOntologyToClerezzaTriples
argument_list|(
name|ontology
argument_list|)
argument_list|)
expr_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Metadata of the content is appended to the existent one"
argument_list|,
name|this
argument_list|)
expr_stmt|;
block|}
comment|/*                  * The session needs to be destroyed, as it is no more useful.                  */
name|sessionManager
operator|.
name|destroySession
argument_list|(
name|session
operator|.
name|getID
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|OWLOntologyCreationException
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"Cannot create the ontology for the refactoring"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// /**
comment|// * Setup the KReS session
comment|// *
comment|// * @return
comment|// */
comment|// private String createAndAddSessionSpaceToScope() {
comment|// /*
comment|// * Retrieve the session manager
comment|// */
comment|// // SessionManager sessionManager = onManager.getSessionManager();
comment|// log.debug("Starting create session for the dulcifier");
comment|//
comment|// /*
comment|// * Create and setup the session. TODO FIXME This is an operation that should be made easier for
comment|// * developers to do through the API
comment|// */
comment|// Session session = sessionManager.createSession();
comment|// // OntologySpaceFactory ontologySpaceFactory = onManager.getOntologySpaceFactory();
comment|// // OntologySpace sessionSpace = ontologySpaceFactory.createSessionOntologySpace(scope.getID());
comment|// // try {
comment|// // scope.addSessionSpace(sessionSpace, session.getID());
comment|// // } catch (UnmodifiableOntologySpaceException e) {
comment|// // log.error("Failed to add session space to unmodifiable scope " + scope, e);
comment|// // }
comment|//
comment|// /*
comment|// * Finally, we return the session ID to be used by the caller
comment|// */
comment|// log.debug("Session " + session.getID() + " created", this);
comment|// return session.getID();
comment|// }
comment|/**      * To create the input source necesary to load the ontology inside the scope.      *       * @param uri      *            -- A resolvable string uri.      * @return An OntologyInputSource      */
specifier|private
name|OntologyInputSource
name|oisForScope
parameter_list|(
specifier|final
name|String
name|uri
parameter_list|)
block|{
comment|/*          * The scope factory needs an OntologyInputSource as input for the core ontology space. We want to use          * the dbpedia ontology as core ontology of our scope.          */
name|OntologyInputSource
name|ois
init|=
operator|new
name|OntologyInputSource
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|hasRootOntology
parameter_list|()
block|{
return|return
literal|true
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|hasPhysicalIRI
parameter_list|()
block|{
return|return
literal|false
return|;
block|}
annotation|@
name|Override
specifier|public
name|OWLOntology
name|getRootOntology
parameter_list|()
block|{
try|try
block|{
comment|/*                      * The input stream for the dbpedia ontology is obtained through the dereferencer                      * component.                      */
comment|// inputStream = dereferencer.resolve(uri);
name|OWLOntologyManager
name|manager
init|=
name|OWLManager
operator|.
name|createOWLOntologyManager
argument_list|()
decl_stmt|;
return|return
name|manager
operator|.
name|loadOntologyFromOntologyDocument
argument_list|(
name|IRI
operator|.
name|create
argument_list|(
name|uri
argument_list|)
argument_list|)
return|;
comment|// return getEntityOntology(uri);
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"Cannot load the ontology "
operator|+
name|uri
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
comment|/** If some errors occur **/
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|IRI
name|getPhysicalIRI
parameter_list|()
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|Set
argument_list|<
name|OWLOntology
argument_list|>
name|getImports
parameter_list|(
name|boolean
name|direct
parameter_list|)
block|{
comment|// TODO Auto-generated method stub
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|getStorageKey
parameter_list|()
block|{
comment|// TODO Auto-generated method stub
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|Object
name|getTriplesProvider
parameter_list|()
block|{
comment|// TODO Auto-generated method stub
return|return
literal|null
return|;
block|}
block|}
decl_stmt|;
return|return
name|ois
return|;
block|}
comment|/**      * Activating the component      *       * @param context      */
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
annotation|@
name|Activate
specifier|protected
name|void
name|activate
parameter_list|(
specifier|final
name|ComponentContext
name|context
parameter_list|)
throws|throws
name|ConfigurationException
block|{
name|super
operator|.
name|activate
argument_list|(
name|context
argument_list|)
expr_stmt|;
name|this
operator|.
name|context
operator|=
name|context
expr_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|Object
argument_list|>
name|config
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|Object
argument_list|>
argument_list|()
decl_stmt|;
name|Dictionary
argument_list|<
name|String
argument_list|,
name|Object
argument_list|>
name|properties
init|=
operator|(
name|Dictionary
argument_list|<
name|String
argument_list|,
name|Object
argument_list|>
operator|)
name|context
operator|.
name|getProperties
argument_list|()
decl_stmt|;
comment|// copy the properties to a map
for|for
control|(
name|Enumeration
argument_list|<
name|String
argument_list|>
name|e
init|=
name|properties
operator|.
name|keys
argument_list|()
init|;
name|e
operator|.
name|hasMoreElements
argument_list|()
condition|;
control|)
block|{
name|String
name|key
init|=
name|e
operator|.
name|nextElement
argument_list|()
decl_stmt|;
name|config
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|properties
operator|.
name|get
argument_list|(
name|key
argument_list|)
argument_list|)
expr_stmt|;
name|log
operator|.
name|info
argument_list|(
literal|"Configuration property: "
operator|+
name|key
operator|+
literal|" :- "
operator|+
name|properties
operator|.
name|get
argument_list|(
name|key
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|engineConfiguration
operator|=
operator|new
name|DefaultRefactorEnhancementEngineConf
argument_list|(
name|properties
argument_list|)
expr_stmt|;
name|initEngine
argument_list|(
name|engineConfiguration
argument_list|)
expr_stmt|;
name|log
operator|.
name|info
argument_list|(
literal|"Activated Refactor Enhancement Engine"
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|initEngine
parameter_list|(
name|RefactorEnhancementEngineConf
name|engineConfiguration
parameter_list|)
block|{
comment|/*          * Get the Scope Factory from the ONM of KReS that allows to create new scopes          */
name|OntologyScopeFactory
name|scopeFactory
init|=
name|onManager
operator|.
name|getOntologyScopeFactory
argument_list|()
decl_stmt|;
comment|/*          * Adding ontologies to the scope core ontology. 1) Get all the ontologies from the property. 2)          * Create a base scope with an empity ontology. 3) Retrieve the ontology space from the scope. 4) Add          * the ontologies to the scope via ontology space.          */
comment|// Step 1
name|String
index|[]
name|coreScopeOntologySet
init|=
name|engineConfiguration
operator|.
name|getScopeCoreOntology
argument_list|()
decl_stmt|;
comment|/*          * String[] coreScopeOntologySet; if (obj instanceof String[]) { coreScopeOntologySet = (String[])          * obj; } else { String[] aux = new String[1]; aux[0] = (String) obj; coreScopeOntologySet = aux; }          */
comment|// Step 2
name|OntologyInputSource
name|oisbase
init|=
operator|new
name|OntologyInputSource
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|hasRootOntology
parameter_list|()
block|{
return|return
literal|true
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|hasPhysicalIRI
parameter_list|()
block|{
return|return
literal|false
return|;
block|}
annotation|@
name|Override
specifier|public
name|OWLOntology
name|getRootOntology
parameter_list|()
block|{
try|try
block|{
comment|/*                      * The input stream for the dbpedia ontology is obtained through the dereferencer                      * component.                      */
name|OWLOntologyManager
name|manager
init|=
name|OWLManager
operator|.
name|createOWLOntologyManager
argument_list|()
decl_stmt|;
return|return
name|manager
operator|.
name|createOntology
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|OWLOntologyCreationException
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"Cannot create the scope with empity ontology."
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"Cannot create the scope with empity ontology."
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
comment|/** If some errors occur **/
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|IRI
name|getPhysicalIRI
parameter_list|()
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|Set
argument_list|<
name|OWLOntology
argument_list|>
name|getImports
parameter_list|(
name|boolean
name|direct
parameter_list|)
block|{
comment|// TODO Auto-generated method stub
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|getStorageKey
parameter_list|()
block|{
comment|// TODO Auto-generated method stub
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|Object
name|getTriplesProvider
parameter_list|()
block|{
comment|// TODO Auto-generated method stub
return|return
literal|null
return|;
block|}
block|}
decl_stmt|;
comment|// IRI dulcifierScopeIRI = IRI.create((String) context.getProperties().get(SCOPE));
name|String
name|scopeId
init|=
name|engineConfiguration
operator|.
name|getScope
argument_list|()
decl_stmt|;
comment|/*          * The scope is created by the ScopeFactory or loaded from the scope registry of KReS          */
try|try
block|{
name|scope
operator|=
name|scopeFactory
operator|.
name|createOntologyScope
argument_list|(
name|scopeId
comment|/* dulcifierScopeIRI */
argument_list|,
name|oisbase
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|DuplicateIDException
name|e
parameter_list|)
block|{
name|ScopeRegistry
name|scopeRegistry
init|=
name|onManager
operator|.
name|getScopeRegistry
argument_list|()
decl_stmt|;
name|scope
operator|=
name|scopeRegistry
operator|.
name|getScope
argument_list|(
name|scopeId
comment|/* dulcifierScopeIRI */
argument_list|)
expr_stmt|;
block|}
comment|/*          * Step 3          */
name|OntologySpace
name|ontologySpace
init|=
name|scope
operator|.
name|getCoreSpace
argument_list|()
decl_stmt|;
comment|/*          * Step 4          */
name|ontologySpace
operator|.
name|tearDown
argument_list|()
expr_stmt|;
for|for
control|(
name|int
name|o
init|=
literal|0
init|;
name|o
operator|<
name|coreScopeOntologySet
operator|.
name|length
condition|;
name|o
operator|++
control|)
block|{
name|OntologyInputSource
name|ois
init|=
name|oisForScope
argument_list|(
name|coreScopeOntologySet
index|[
name|o
index|]
argument_list|)
decl_stmt|;
try|try
block|{
name|ontologySpace
operator|.
name|addOntology
argument_list|(
name|ois
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|UnmodifiableOntologyCollectorException
name|ex
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"Unmodifiable Ontology SpaceException."
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
block|}
name|ontologySpace
operator|.
name|setUp
argument_list|()
expr_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"The set of ontologies loaded in the core scope space is: "
operator|+
name|ontologySpace
operator|.
name|getOntologies
argument_list|(
literal|true
argument_list|)
operator|+
literal|"\nN.B. The root.owl ontology is the first (on the list) ontology added when the scope is created."
argument_list|)
expr_stmt|;
comment|/*          * The first thing to do is to create a recipe in the rule store that can be used by the engine to          * refactor the enhancement graphs.          */
name|log
operator|.
name|debug
argument_list|(
literal|"Start create the Recipe"
argument_list|,
name|this
argument_list|)
expr_stmt|;
name|ruleStore
operator|.
name|addRecipe
argument_list|(
name|IRI
operator|.
name|create
argument_list|(
name|engineConfiguration
operator|.
name|getRecipeId
argument_list|()
argument_list|)
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"The recipe has been created"
argument_list|,
name|this
argument_list|)
expr_stmt|;
comment|/*          * The set of rule to put in the recipe can be provided by the user. A default set of rules is          * provided in /META-INF/default/seo_rules.sem. Use the property engine.refactor in the felix console          * to pass to the engine your set of rules.          */
name|String
name|recipeLocation
init|=
name|engineConfiguration
operator|.
name|getRecipeLocation
argument_list|()
decl_stmt|;
name|InputStream
name|recipeStream
init|=
literal|null
decl_stmt|;
name|String
name|recipeString
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|recipeLocation
operator|!=
literal|null
operator|&&
operator|!
name|recipeLocation
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|IDereferencer
name|dereferencer
init|=
operator|new
name|Dereferencer
argument_list|()
decl_stmt|;
try|try
block|{
name|recipeStream
operator|=
name|dereferencer
operator|.
name|resolve
argument_list|(
name|recipeLocation
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"Recipe Stream is null."
argument_list|,
name|this
argument_list|)
expr_stmt|;
block|}
name|log
operator|.
name|debug
argument_list|(
literal|"Loaded recipe from an external source."
argument_list|,
name|this
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|recipeStream
operator|=
name|RefactorEnhancementEngine
operator|.
name|class
operator|.
name|getResourceAsStream
argument_list|(
literal|"/META-INF/default/seo_rules.sem"
argument_list|)
expr_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Loaded default recipe."
argument_list|,
name|this
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|recipeStream
operator|!=
literal|null
condition|)
block|{
name|recipeString
operator|=
literal|""
expr_stmt|;
name|BufferedReader
name|reader
init|=
operator|new
name|BufferedReader
argument_list|(
operator|new
name|InputStreamReader
argument_list|(
name|recipeStream
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|line
init|=
literal|null
decl_stmt|;
try|try
block|{
while|while
condition|(
operator|(
name|line
operator|=
name|reader
operator|.
name|readLine
argument_list|()
operator|)
operator|!=
literal|null
condition|)
block|{
name|recipeString
operator|+=
name|line
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|// TODO Auto-generated catch block
name|e
operator|.
name|printStackTrace
argument_list|()
expr_stmt|;
block|}
block|}
name|log
operator|.
name|debug
argument_list|(
literal|"Recipe: "
operator|+
name|recipeString
argument_list|,
name|this
argument_list|)
expr_stmt|;
comment|/*          * step 3          */
try|try
block|{
comment|// ruleStore.addRuleToRecipe(recipeIRI.toString(), kReSRuleSyntax);
name|ruleStore
operator|.
name|addRuleToRecipe
argument_list|(
name|engineConfiguration
operator|.
name|getRecipeId
argument_list|()
argument_list|,
name|recipeString
argument_list|)
expr_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Added rules to recipe "
operator|+
name|engineConfiguration
operator|.
name|getRecipeId
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchRecipeException
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"The recipe does not exists: "
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
specifier|protected
name|void
name|createRefactorEngineComponent
parameter_list|(
name|ComponentFactory
name|factory
parameter_list|)
block|{
comment|// both create*** methods sync on the searcherAndDereferencerLock to avoid
comment|// multiple component instances because of concurrent calls
synchronized|synchronized
init|(
name|this
operator|.
name|lock
init|)
block|{
if|if
condition|(
name|refactorEngineComponentInstance
operator|==
literal|null
condition|)
block|{
name|this
operator|.
name|refactorEngineComponentInstance
operator|=
name|factory
operator|.
name|newInstance
argument_list|(
name|OsgiUtils
operator|.
name|copyConfig
argument_list|(
name|context
operator|.
name|getProperties
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|protected
name|void
name|deactivate
parameter_list|(
name|ComponentContext
name|context
parameter_list|)
block|{
comment|/*          * Deactivating the dulcifier. The procedure require: 1) get all the rules from the recipe 2) remove          * the recipe. 3) remove the single rule. 4) tear down the scope ontologySpace and the scope itself.          */
try|try
block|{
comment|/*              * step 1: get all the rule              */
name|log
operator|.
name|debug
argument_list|(
literal|"Removing recipe "
operator|+
name|engineConfiguration
operator|.
name|getRecipeId
argument_list|()
operator|+
literal|" from RuleStore."
argument_list|,
name|this
argument_list|)
expr_stmt|;
name|RuleList
name|recipeRuleList
init|=
name|ruleStore
operator|.
name|getRecipe
argument_list|(
name|IRI
operator|.
name|create
argument_list|(
name|engineConfiguration
operator|.
name|getRecipeId
argument_list|()
argument_list|)
argument_list|)
operator|.
name|getkReSRuleList
argument_list|()
decl_stmt|;
comment|/*              * step 2: remove the recipe              */
if|if
condition|(
name|ruleStore
operator|.
name|removeRecipe
argument_list|(
name|IRI
operator|.
name|create
argument_list|(
name|engineConfiguration
operator|.
name|getRecipeId
argument_list|()
argument_list|)
argument_list|)
condition|)
block|{
name|log
operator|.
name|debug
argument_list|(
literal|"The recipe "
operator|+
name|engineConfiguration
operator|.
name|getRecipeId
argument_list|()
operator|+
literal|" has been removed correctly"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|log
operator|.
name|error
argument_list|(
literal|"The recipe "
operator|+
name|engineConfiguration
operator|.
name|getRecipeId
argument_list|()
operator|+
literal|" can not be removed"
argument_list|)
expr_stmt|;
block|}
comment|/*              * step 3: remove the rules              */
for|for
control|(
name|Rule
name|rule
range|:
name|recipeRuleList
control|)
block|{
if|if
condition|(
name|ruleStore
operator|.
name|removeRule
argument_list|(
name|rule
argument_list|)
condition|)
block|{
name|log
operator|.
name|debug
argument_list|(
literal|"The rule "
operator|+
name|rule
operator|.
name|getRuleName
argument_list|()
operator|+
literal|" has been removed correctly"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|log
operator|.
name|error
argument_list|(
literal|"The rule "
operator|+
name|rule
operator|.
name|getRuleName
argument_list|()
operator|+
literal|" can not be removed"
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*              * step 4:              */
name|scope
operator|.
name|getCoreSpace
argument_list|()
operator|.
name|tearDown
argument_list|()
expr_stmt|;
name|scope
operator|.
name|tearDown
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchRecipeException
name|ex
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"The recipe "
operator|+
name|engineConfiguration
operator|.
name|getRecipeId
argument_list|()
operator|+
literal|" doesn't exist"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
name|log
operator|.
name|info
argument_list|(
literal|"Deactivated Refactor Enhancement Engine"
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|Object
argument_list|>
name|getServiceProperties
parameter_list|()
block|{
return|return
name|Collections
operator|.
name|unmodifiableMap
argument_list|(
name|Collections
operator|.
name|singletonMap
argument_list|(
name|ServiceProperties
operator|.
name|ENHANCEMENT_ENGINE_ORDERING
argument_list|,
operator|(
name|Object
operator|)
name|ServiceProperties
operator|.
name|ORDERING_POST_PROCESSING
argument_list|)
argument_list|)
return|;
block|}
comment|/**      * Fetch the OWLOntology containing the graph associated to an entity from Linked Data. It uses the Entity      * Hub for accessing LOD and fetching entities.      *       * @param entityURI      *            {@link String}      * @return the {@link OWLOntology} of the entity      */
specifier|private
name|OWLOntology
name|getEntityOntology
parameter_list|(
name|String
name|entityURI
parameter_list|)
block|{
name|OWLOntology
name|fetchedOntology
init|=
literal|null
decl_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Asking entity: "
operator|+
name|entityURI
argument_list|)
expr_stmt|;
comment|/*          * Ask to the entityhub the fetch the entity.          */
name|Entity
name|entitySign
init|=
name|referencedSiteManager
operator|.
name|getEntity
argument_list|(
name|entityURI
argument_list|)
decl_stmt|;
comment|/*          * Wrap the entity graph into an owl ontology.          */
name|MGraph
name|entityMGraph
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|entitySign
operator|!=
literal|null
condition|)
block|{
name|Representation
name|entityRepresentation
init|=
name|entitySign
operator|.
name|getRepresentation
argument_list|()
decl_stmt|;
name|RdfRepresentation
name|entityRdfRepresentation
init|=
name|RdfValueFactory
operator|.
name|getInstance
argument_list|()
operator|.
name|toRdfRepresentation
argument_list|(
name|entityRepresentation
argument_list|)
decl_stmt|;
name|TripleCollection
name|tripleCollection
init|=
name|entityRdfRepresentation
operator|.
name|getRdfGraph
argument_list|()
decl_stmt|;
name|entityMGraph
operator|=
operator|new
name|SimpleMGraph
argument_list|()
expr_stmt|;
name|entityMGraph
operator|.
name|addAll
argument_list|(
name|tripleCollection
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|entityMGraph
operator|!=
literal|null
condition|)
block|{
comment|/*              * OWLOntologyManager manager = OWLManager.createOWLOntologyManager(); final OWLOntology fetched =              * manager.loadOntologyFromOntologyDocument(dereferencer.resolve(entityReferenceString));              */
name|fetchedOntology
operator|=
name|OWLAPIToClerezzaConverter
operator|.
name|clerezzaGraphToOWLOntology
argument_list|(
name|entityMGraph
argument_list|)
expr_stmt|;
block|}
return|return
name|fetchedOntology
return|;
block|}
block|}
end_class

end_unit

