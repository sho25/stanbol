begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|refactor
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|BufferedReader
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStreamReader
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|clerezza
operator|.
name|rdf
operator|.
name|core
operator|.
name|MGraph
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|clerezza
operator|.
name|rdf
operator|.
name|core
operator|.
name|Resource
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|clerezza
operator|.
name|rdf
operator|.
name|core
operator|.
name|Triple
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|clerezza
operator|.
name|rdf
operator|.
name|core
operator|.
name|TripleCollection
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|clerezza
operator|.
name|rdf
operator|.
name|core
operator|.
name|UriRef
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|clerezza
operator|.
name|rdf
operator|.
name|core
operator|.
name|impl
operator|.
name|SimpleMGraph
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|Component
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|Property
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|Reference
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|felix
operator|.
name|scr
operator|.
name|annotations
operator|.
name|Service
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|refactor
operator|.
name|dereferencer
operator|.
name|Dereferencer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|refactor
operator|.
name|dereferencer
operator|.
name|IDereferencer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|servicesapi
operator|.
name|ContentItem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|servicesapi
operator|.
name|EngineException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|servicesapi
operator|.
name|EnhancementEngine
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|servicesapi
operator|.
name|ServiceProperties
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|model
operator|.
name|clerezza
operator|.
name|RdfRepresentation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|model
operator|.
name|clerezza
operator|.
name|RdfValueFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|servicesapi
operator|.
name|model
operator|.
name|Entity
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|servicesapi
operator|.
name|model
operator|.
name|Representation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|entityhub
operator|.
name|servicesapi
operator|.
name|site
operator|.
name|ReferencedSiteManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|ontologymanager
operator|.
name|ontonet
operator|.
name|api
operator|.
name|DuplicateIDException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|ontologymanager
operator|.
name|ontonet
operator|.
name|api
operator|.
name|ONManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|ontologymanager
operator|.
name|ontonet
operator|.
name|api
operator|.
name|io
operator|.
name|OntologyInputSource
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|ontologymanager
operator|.
name|ontonet
operator|.
name|api
operator|.
name|ontology
operator|.
name|OntologyScope
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|ontologymanager
operator|.
name|ontonet
operator|.
name|api
operator|.
name|ontology
operator|.
name|OntologyScopeFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|ontologymanager
operator|.
name|ontonet
operator|.
name|api
operator|.
name|ontology
operator|.
name|OntologySpace
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|ontologymanager
operator|.
name|ontonet
operator|.
name|api
operator|.
name|ontology
operator|.
name|ScopeRegistry
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|ontologymanager
operator|.
name|ontonet
operator|.
name|api
operator|.
name|ontology
operator|.
name|UnmodifiableOntologyCollectorException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|ontologymanager
operator|.
name|ontonet
operator|.
name|api
operator|.
name|session
operator|.
name|Session
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|ontologymanager
operator|.
name|ontonet
operator|.
name|api
operator|.
name|session
operator|.
name|SessionManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|owl
operator|.
name|transformation
operator|.
name|OWLAPIToClerezzaConverter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|rules
operator|.
name|base
operator|.
name|api
operator|.
name|NoSuchRecipeException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|rules
operator|.
name|base
operator|.
name|api
operator|.
name|Recipe
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|rules
operator|.
name|base
operator|.
name|api
operator|.
name|Rule
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|rules
operator|.
name|base
operator|.
name|api
operator|.
name|RuleStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|rules
operator|.
name|base
operator|.
name|api
operator|.
name|util
operator|.
name|RuleList
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|rules
operator|.
name|refactor
operator|.
name|api
operator|.
name|Refactorer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|rules
operator|.
name|refactor
operator|.
name|api
operator|.
name|RefactoringException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|osgi
operator|.
name|service
operator|.
name|component
operator|.
name|ComponentContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|semanticweb
operator|.
name|owlapi
operator|.
name|apibinding
operator|.
name|OWLManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|semanticweb
operator|.
name|owlapi
operator|.
name|model
operator|.
name|IRI
import|;
end_import

begin_import
import|import
name|org
operator|.
name|semanticweb
operator|.
name|owlapi
operator|.
name|model
operator|.
name|OWLOntology
import|;
end_import

begin_import
import|import
name|org
operator|.
name|semanticweb
operator|.
name|owlapi
operator|.
name|model
operator|.
name|OWLOntologyCreationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|semanticweb
operator|.
name|owlapi
operator|.
name|model
operator|.
name|OWLOntologyManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|semanticweb
operator|.
name|owlapi
operator|.
name|model
operator|.
name|OWLOntologySetProvider
import|;
end_import

begin_import
import|import
name|org
operator|.
name|semanticweb
operator|.
name|owlapi
operator|.
name|util
operator|.
name|OWLOntologyMerger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/**  *   * This an engine to post-process the enhancements. Its main goal is to refactor the RDF produced by the  * enhancement applying some vocabulary related to a specific task.  *   * To do that, exploit a Refactor recipe and an ontology scope of OntoNet.  *   * The first implementation is targeted to SEO use case. * It retrieves data by dereferencing the entities, *  * includes the DBpedia ontology * refactor the data using the google rich snippets vocabulary.  *   * @author andrea.nuzzolese  *   */
end_comment

begin_class
annotation|@
name|Component
argument_list|(
name|immediate
operator|=
literal|true
argument_list|,
name|metatype
operator|=
literal|true
argument_list|)
annotation|@
name|Service
argument_list|(
name|EnhancementEngine
operator|.
name|class
argument_list|)
specifier|public
class|class
name|RefactorEnhancementEngine
implements|implements
name|EnhancementEngine
implements|,
name|ServiceProperties
block|{
comment|/*      * TODO This are the scope and recipe IDs to be used by this implementation In future implementation this      * will be configurable      */
annotation|@
name|Property
argument_list|(
name|value
operator|=
literal|"refactor-engine"
argument_list|)
specifier|public
specifier|static
specifier|final
name|String
name|SCOPE
init|=
literal|"engine.refactor.scope"
decl_stmt|;
annotation|@
name|Property
argument_list|(
name|value
operator|=
literal|""
argument_list|)
specifier|public
specifier|static
specifier|final
name|String
name|RECIPE_URI
init|=
literal|"engine.refactor.recipe"
decl_stmt|;
annotation|@
name|Property
argument_list|(
name|value
operator|=
block|{
literal|"http://ontologydesignpatterns.org/ont/iks/kres/dbpedia_demo.owl"
block|,
literal|""
block|}
argument_list|,
name|cardinality
operator|=
literal|1000
argument_list|,
name|description
operator|=
literal|"To fix a set of resolvable ontology URIs for the scope's ontologies."
argument_list|)
specifier|public
specifier|static
specifier|final
name|String
name|SCOPE_CORE_ONTOLOGY
init|=
literal|"engine.refactor.scope.core.ontology"
decl_stmt|;
annotation|@
name|Property
argument_list|(
name|boolValue
operator|=
literal|true
argument_list|,
name|description
operator|=
literal|"If true: the previously generated RDF is deleted and substituted with the new one. If false: the new one is appended to the old RDF. Possible value: true or false."
argument_list|)
specifier|public
specifier|static
specifier|final
name|String
name|APPEND_OTHER_ENHANCEMENT_GRAPHS
init|=
literal|"engine.refactor.append.graphs"
decl_stmt|;
annotation|@
name|Property
argument_list|(
name|boolValue
operator|=
literal|true
argument_list|,
name|description
operator|=
literal|"If true: entities are fetched via the EntityHub. If false: entities are fetched on-line. Possible value: true or false."
argument_list|)
specifier|public
specifier|static
specifier|final
name|String
name|USAGE_OF_ENTITY_HUB
init|=
literal|"engine.refactor.entityhub"
decl_stmt|;
annotation|@
name|Reference
name|ONManager
name|onManager
decl_stmt|;
annotation|@
name|Reference
name|ReferencedSiteManager
name|referencedSiteManager
decl_stmt|;
annotation|@
name|Reference
name|RuleStore
name|ruleStore
decl_stmt|;
annotation|@
name|Reference
name|Refactorer
name|refactorer
decl_stmt|;
specifier|private
name|OntologyScope
name|scope
decl_stmt|;
specifier|private
name|IRI
name|recipeIRI
decl_stmt|;
specifier|private
name|boolean
name|graph_append
decl_stmt|;
specifier|private
name|boolean
name|useEntityHub
decl_stmt|;
specifier|private
specifier|final
name|Logger
name|log
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|getClass
argument_list|()
argument_list|)
decl_stmt|;
annotation|@
name|Override
specifier|public
name|int
name|canEnhance
parameter_list|(
name|ContentItem
name|ci
parameter_list|)
throws|throws
name|EngineException
block|{
comment|/*          * Dulcifier can enhance only content items that are previously enhanced by other enhancement engines,          * as it must be the last engine in the chain.          *           * Works only if some enhancement has been produced.          */
name|MGraph
name|mGraph
init|=
name|ci
operator|.
name|getMetadata
argument_list|()
decl_stmt|;
if|if
condition|(
name|mGraph
operator|!=
literal|null
condition|)
block|{
return|return
name|ENHANCE_SYNCHRONOUS
return|;
block|}
else|else
block|{
return|return
name|CANNOT_ENHANCE
return|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|computeEnhancements
parameter_list|(
name|ContentItem
name|ci
parameter_list|)
throws|throws
name|EngineException
block|{
comment|/*          * Retrieve the graph          */
specifier|final
name|MGraph
name|mGraph
init|=
name|ci
operator|.
name|getMetadata
argument_list|()
decl_stmt|;
comment|/*          * We filter the entities recognized by the engines          */
name|UriRef
name|fiseEntityReference
init|=
operator|new
name|UriRef
argument_list|(
literal|"http://fise.iks-project.eu/ontology/entity-reference"
argument_list|)
decl_stmt|;
name|Iterator
argument_list|<
name|Triple
argument_list|>
name|tripleIt
init|=
name|mGraph
operator|.
name|filter
argument_list|(
literal|null
argument_list|,
name|fiseEntityReference
argument_list|,
literal|null
argument_list|)
decl_stmt|;
comment|/*          * Now we prepare the OntoNet environment. First we create the OntoNet session in which run the whole          */
specifier|final
name|String
name|sessionIRI
init|=
name|createAndAddSessionSpaceToScope
argument_list|()
decl_stmt|;
comment|/*          * We retrieve the session space          */
name|OntologySpace
name|sessionSpace
init|=
name|scope
operator|.
name|getSessionSpace
argument_list|(
name|sessionIRI
argument_list|)
decl_stmt|;
while|while
condition|(
name|tripleIt
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|Triple
name|triple
init|=
name|tripleIt
operator|.
name|next
argument_list|()
decl_stmt|;
name|Resource
name|entityReference
init|=
name|triple
operator|.
name|getObject
argument_list|()
decl_stmt|;
comment|/*              * the entity uri              */
specifier|final
name|String
name|entityReferenceString
init|=
name|entityReference
operator|.
name|toString
argument_list|()
operator|.
name|replace
argument_list|(
literal|"<"
argument_list|,
literal|""
argument_list|)
operator|.
name|replace
argument_list|(
literal|">"
argument_list|,
literal|""
argument_list|)
decl_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Trying to resolve entity "
operator|+
name|entityReferenceString
argument_list|)
expr_stmt|;
comment|/**              * We fetch the entity in the OntologyInputSource object              */
try|try
block|{
specifier|final
name|IRI
name|fetchedIri
init|=
name|IRI
operator|.
name|create
argument_list|(
name|entityReferenceString
argument_list|)
decl_stmt|;
comment|/*                  * The RDF graph of an entity is fetched via the EntityHub. The getEntityOntology is a method                  * the do the job of asking the entity to the EntityHub and wrap the RDF graph into an                  * OWLOntology.                  */
name|OWLOntology
name|fetched
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|useEntityHub
condition|)
block|{
name|fetched
operator|=
name|getEntityOntology
argument_list|(
name|entityReferenceString
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Dereferencer
name|dereferencer
init|=
operator|new
name|Dereferencer
argument_list|()
decl_stmt|;
try|try
block|{
name|fetched
operator|=
name|OWLManager
operator|.
name|createOWLOntologyManager
argument_list|()
operator|.
name|loadOntologyFromOntologyDocument
argument_list|(
name|dereferencer
operator|.
name|resolve
argument_list|(
name|entityReferenceString
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|OWLOntologyCreationException
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"An error occurred while trying to create the ontology related to the entity "
operator|+
name|entityReferenceString
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"The entity "
operator|+
name|entityReferenceString
operator|+
literal|" does not exist or is unreachable"
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|fetched
operator|!=
literal|null
condition|)
block|{
specifier|final
name|OWLOntology
name|fetchedFinal
init|=
name|fetched
decl_stmt|;
name|OntologyInputSource
name|ontologySource
init|=
operator|new
name|OntologyInputSource
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|hasRootOntology
parameter_list|()
block|{
return|return
operator|(
name|fetchedFinal
operator|!=
literal|null
operator|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|hasPhysicalIRI
parameter_list|()
block|{
return|return
literal|true
return|;
block|}
annotation|@
name|Override
specifier|public
name|OWLOntology
name|getRootOntology
parameter_list|()
block|{
return|return
name|fetchedFinal
return|;
block|}
annotation|@
name|Override
specifier|public
name|IRI
name|getPhysicalIRI
parameter_list|()
block|{
return|return
name|fetchedIri
return|;
block|}
annotation|@
name|Override
specifier|public
name|Set
argument_list|<
name|OWLOntology
argument_list|>
name|getImports
parameter_list|(
name|boolean
name|direct
parameter_list|)
block|{
comment|// TODO Auto-generated method stub
return|return
literal|null
return|;
block|}
block|}
decl_stmt|;
name|sessionSpace
operator|.
name|addOntology
argument_list|(
name|ontologySource
argument_list|)
expr_stmt|;
block|}
name|log
operator|.
name|debug
argument_list|(
literal|"Added "
operator|+
name|entityReferenceString
operator|+
literal|" to the session space of scope "
operator|+
name|scope
operator|.
name|getID
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
name|this
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|UnmodifiableOntologyCollectorException
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"Cannot load the entity"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*          * Now we merge the RDF from the T-box - the ontologies - and the A-box - the RDF data fetched          */
specifier|final
name|OWLOntologyManager
name|man
init|=
name|OWLManager
operator|.
name|createOWLOntologyManager
argument_list|()
decl_stmt|;
name|OWLOntologySetProvider
name|provider
init|=
operator|new
name|OWLOntologySetProvider
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Set
argument_list|<
name|OWLOntology
argument_list|>
name|getOntologies
parameter_list|()
block|{
name|Set
argument_list|<
name|OWLOntology
argument_list|>
name|ontologies
init|=
operator|new
name|HashSet
argument_list|<
name|OWLOntology
argument_list|>
argument_list|()
decl_stmt|;
name|OntologySpace
name|sessionSpace
init|=
name|scope
operator|.
name|getSessionSpace
argument_list|(
name|sessionIRI
argument_list|)
decl_stmt|;
name|ontologies
operator|.
name|addAll
argument_list|(
name|sessionSpace
operator|.
name|getOntologies
argument_list|(
literal|true
argument_list|)
argument_list|)
expr_stmt|;
comment|/*                  * We add to the set the graph containing the metadata generated by previous enhancement                  * engines. It is important becaus we want to menage during the refactoring also some                  * information fron that graph. As the graph is provided as a Clerezza MGraph, we first need                  * to convert it to an OWLAPI OWLOntology. There is no chance that the mGraph could be null as                  * it was previously controlled by the JobManager through the canEnhance method and the                  * computeEnhancement is always called iff the former returns true.                  */
name|OWLOntology
name|fiseMetadataOntology
init|=
name|OWLAPIToClerezzaConverter
operator|.
name|clerezzaGraphToOWLOntology
argument_list|(
name|mGraph
argument_list|)
decl_stmt|;
name|ontologies
operator|.
name|add
argument_list|(
name|fiseMetadataOntology
argument_list|)
expr_stmt|;
return|return
name|ontologies
return|;
block|}
block|}
decl_stmt|;
comment|/*          * We merge all the ontologies from the session space of the scope into a single ontology that will be          * used for the refactoring.          */
name|OWLOntologyMerger
name|merger
init|=
operator|new
name|OWLOntologyMerger
argument_list|(
name|provider
argument_list|)
decl_stmt|;
name|OWLOntology
name|ontology
decl_stmt|;
try|try
block|{
name|ontology
operator|=
name|merger
operator|.
name|createMergedOntology
argument_list|(
name|man
argument_list|,
name|IRI
operator|.
name|create
argument_list|(
literal|"http://fise.iks-project.eu/dulcifier/integrity-check"
argument_list|)
argument_list|)
expr_stmt|;
comment|/*              * To perform the refactoring of the ontology to a given vocabulary we use the Stanbol Refactor.              */
name|log
operator|.
name|debug
argument_list|(
literal|"Refactoring recipe IRI is : "
operator|+
name|recipeIRI
argument_list|)
expr_stmt|;
comment|/*              * We pass the ontology and the recipe IRI to the Refactor that returns the refactored graph              * expressed by using the given vocabulary.              */
try|try
block|{
name|Recipe
name|recipe
init|=
name|ruleStore
operator|.
name|getRecipe
argument_list|(
name|recipeIRI
argument_list|)
decl_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Rules in the recipe are : "
operator|+
name|recipe
operator|.
name|getkReSRuleList
argument_list|()
operator|.
name|size
argument_list|()
argument_list|,
name|this
argument_list|)
expr_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"The ontology to be refactor is : "
operator|+
name|ontology
argument_list|,
name|this
argument_list|)
expr_stmt|;
name|ontology
operator|=
name|refactorer
operator|.
name|ontologyRefactoring
argument_list|(
name|ontology
argument_list|,
name|recipeIRI
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|RefactoringException
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"The refactoring engine failed the execution."
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchRecipeException
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"The recipe with ID "
operator|+
name|recipeIRI
operator|+
literal|" does not exists"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
name|log
operator|.
name|debug
argument_list|(
literal|"Merged ontologies in "
operator|+
name|ontology
argument_list|)
expr_stmt|;
comment|/*              * The new generated ontology is converted to Clarezza format and than added os substitued to the              * old mGraph.              */
if|if
condition|(
name|graph_append
condition|)
block|{
name|mGraph
operator|.
name|addAll
argument_list|(
name|OWLAPIToClerezzaConverter
operator|.
name|owlOntologyToClerezzaTriples
argument_list|(
name|ontology
argument_list|)
argument_list|)
expr_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Metadata of the content passd have been substituted"
argument_list|,
name|this
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mGraph
operator|.
name|removeAll
argument_list|(
name|mGraph
argument_list|)
expr_stmt|;
name|mGraph
operator|.
name|addAll
argument_list|(
name|OWLAPIToClerezzaConverter
operator|.
name|owlOntologyToClerezzaTriples
argument_list|(
name|ontology
argument_list|)
argument_list|)
expr_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Metadata of the content is appended to the existent one"
argument_list|,
name|this
argument_list|)
expr_stmt|;
block|}
comment|/*              * The session needs to be destroyed, as it is no more useful.              */
name|onManager
operator|.
name|getSessionManager
argument_list|()
operator|.
name|destroySession
argument_list|(
name|sessionIRI
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|OWLOntologyCreationException
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"Cannot create the ontology for the refactoring"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Setup the KReS session      *       * @return      */
specifier|private
name|String
name|createAndAddSessionSpaceToScope
parameter_list|()
block|{
comment|/*          * Retrieve the session manager          */
name|SessionManager
name|sessionManager
init|=
name|onManager
operator|.
name|getSessionManager
argument_list|()
decl_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Starting create session for the dulcifier"
argument_list|)
expr_stmt|;
comment|/*          * Create and setup the session. TODO FIXME This is an operation that should be made easier for          * developers to do through the API          */
name|Session
name|session
init|=
name|sessionManager
operator|.
name|createSession
argument_list|()
decl_stmt|;
comment|// OntologySpaceFactory ontologySpaceFactory = onManager.getOntologySpaceFactory();
comment|// OntologySpace sessionSpace = ontologySpaceFactory.createSessionOntologySpace(scope.getID());
comment|// try {
comment|// scope.addSessionSpace(sessionSpace, session.getID());
comment|// } catch (UnmodifiableOntologySpaceException e) {
comment|// log.error("Failed to add session space to unmodifiable scope " + scope, e);
comment|// }
comment|/*          * Finally, we return the session ID to be used by the caller          */
name|log
operator|.
name|debug
argument_list|(
literal|"Session "
operator|+
name|session
operator|.
name|getID
argument_list|()
operator|+
literal|" created"
argument_list|,
name|this
argument_list|)
expr_stmt|;
return|return
name|session
operator|.
name|getID
argument_list|()
return|;
block|}
comment|/**      * To create the input source necesary to load the ontology inside the scope.      *       * @param uri      *            -- A resolvable string uri.      * @return An OntologyInputSource      */
specifier|private
name|OntologyInputSource
name|oisForScope
parameter_list|(
specifier|final
name|String
name|uri
parameter_list|)
block|{
comment|/*          * The scope factory needs an OntologyInputSource as input for the core ontology space. We want to use          * the dbpedia ontology as core ontology of our scope.          */
name|OntologyInputSource
name|ois
init|=
operator|new
name|OntologyInputSource
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|hasRootOntology
parameter_list|()
block|{
return|return
literal|true
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|hasPhysicalIRI
parameter_list|()
block|{
return|return
literal|false
return|;
block|}
annotation|@
name|Override
specifier|public
name|OWLOntology
name|getRootOntology
parameter_list|()
block|{
try|try
block|{
comment|/*                      * The input stream for the dbpedia ontology is obtained through the dereferencer                      * component.                      */
comment|// inputStream = dereferencer.resolve(uri);
name|OWLOntologyManager
name|manager
init|=
name|OWLManager
operator|.
name|createOWLOntologyManager
argument_list|()
decl_stmt|;
return|return
name|manager
operator|.
name|loadOntologyFromOntologyDocument
argument_list|(
name|IRI
operator|.
name|create
argument_list|(
name|uri
argument_list|)
argument_list|)
return|;
comment|// return getEntityOntology(uri);
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"Cannot load the ontology "
operator|+
name|uri
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
comment|/** If some errors occur **/
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|IRI
name|getPhysicalIRI
parameter_list|()
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|Set
argument_list|<
name|OWLOntology
argument_list|>
name|getImports
parameter_list|(
name|boolean
name|direct
parameter_list|)
block|{
comment|// TODO Auto-generated method stub
return|return
literal|null
return|;
block|}
block|}
decl_stmt|;
return|return
name|ois
return|;
block|}
comment|/**      * Activating the component      *       * @param context      */
specifier|protected
name|void
name|activate
parameter_list|(
name|ComponentContext
name|context
parameter_list|)
block|{
comment|/*          * Read property to indicate if the the new eanchment metada must be append to the existing mGraph          */
name|graph_append
operator|=
operator|(
operator|(
name|Boolean
operator|)
name|context
operator|.
name|getProperties
argument_list|()
operator|.
name|get
argument_list|(
name|APPEND_OTHER_ENHANCEMENT_GRAPHS
argument_list|)
operator|)
operator|.
name|booleanValue
argument_list|()
expr_stmt|;
name|useEntityHub
operator|=
operator|(
operator|(
name|Boolean
operator|)
name|context
operator|.
name|getProperties
argument_list|()
operator|.
name|get
argument_list|(
name|USAGE_OF_ENTITY_HUB
argument_list|)
operator|)
operator|.
name|booleanValue
argument_list|()
expr_stmt|;
comment|/*          * Get the Scope Factory from the ONM of KReS that allows to create new scopes          */
name|OntologyScopeFactory
name|scopeFactory
init|=
name|onManager
operator|.
name|getOntologyScopeFactory
argument_list|()
decl_stmt|;
comment|/*          * Adding ontologies to the scope core ontology. 1) Get all the ontologies from the property. 2)          * Create a base scope with an empity ontology. 3) Retrieve the ontology space from the scope. 4) Add          * the ontologies to the scope via ontology space.          */
comment|// Step 1
name|Object
name|obj
init|=
name|context
operator|.
name|getProperties
argument_list|()
operator|.
name|get
argument_list|(
name|SCOPE_CORE_ONTOLOGY
argument_list|)
decl_stmt|;
name|String
index|[]
name|coreScopeOntologySet
decl_stmt|;
if|if
condition|(
name|obj
operator|instanceof
name|String
index|[]
condition|)
block|{
name|coreScopeOntologySet
operator|=
operator|(
name|String
index|[]
operator|)
name|obj
expr_stmt|;
block|}
else|else
block|{
name|String
index|[]
name|aux
init|=
operator|new
name|String
index|[
literal|1
index|]
decl_stmt|;
name|aux
index|[
literal|0
index|]
operator|=
operator|(
name|String
operator|)
name|obj
expr_stmt|;
name|coreScopeOntologySet
operator|=
name|aux
expr_stmt|;
block|}
comment|// Step 2
name|OntologyInputSource
name|oisbase
init|=
operator|new
name|OntologyInputSource
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|hasRootOntology
parameter_list|()
block|{
return|return
literal|true
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|hasPhysicalIRI
parameter_list|()
block|{
return|return
literal|false
return|;
block|}
annotation|@
name|Override
specifier|public
name|OWLOntology
name|getRootOntology
parameter_list|()
block|{
try|try
block|{
comment|/*                      * The input stream for the dbpedia ontology is obtained through the dereferencer                      * component.                      */
name|OWLOntologyManager
name|manager
init|=
name|OWLManager
operator|.
name|createOWLOntologyManager
argument_list|()
decl_stmt|;
return|return
name|manager
operator|.
name|createOntology
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|OWLOntologyCreationException
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"Cannot create the scope with empity ontology."
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"Cannot create the scope with empity ontology."
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
comment|/** If some errors occur **/
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|IRI
name|getPhysicalIRI
parameter_list|()
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|Set
argument_list|<
name|OWLOntology
argument_list|>
name|getImports
parameter_list|(
name|boolean
name|direct
parameter_list|)
block|{
comment|// TODO Auto-generated method stub
return|return
literal|null
return|;
block|}
block|}
decl_stmt|;
comment|// IRI dulcifierScopeIRI = IRI.create((String) context.getProperties().get(SCOPE));
name|String
name|scopeId
init|=
operator|(
name|String
operator|)
name|context
operator|.
name|getProperties
argument_list|()
operator|.
name|get
argument_list|(
name|SCOPE
argument_list|)
decl_stmt|;
comment|/*          * The scope is created by the ScopeFactory or loaded from the scope registry of KReS          */
try|try
block|{
name|scope
operator|=
name|scopeFactory
operator|.
name|createOntologyScope
argument_list|(
name|scopeId
comment|/* dulcifierScopeIRI */
argument_list|,
name|oisbase
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|DuplicateIDException
name|e
parameter_list|)
block|{
name|ScopeRegistry
name|scopeRegistry
init|=
name|onManager
operator|.
name|getScopeRegistry
argument_list|()
decl_stmt|;
name|scope
operator|=
name|scopeRegistry
operator|.
name|getScope
argument_list|(
name|scopeId
comment|/* dulcifierScopeIRI */
argument_list|)
expr_stmt|;
block|}
comment|/*          * Step 3          */
name|OntologySpace
name|ontologySpace
init|=
name|scope
operator|.
name|getCoreSpace
argument_list|()
decl_stmt|;
comment|/*          * Step 4          */
name|ontologySpace
operator|.
name|tearDown
argument_list|()
expr_stmt|;
for|for
control|(
name|int
name|o
init|=
literal|0
init|;
name|o
operator|<
name|coreScopeOntologySet
operator|.
name|length
condition|;
name|o
operator|++
control|)
block|{
name|OntologyInputSource
name|ois
init|=
name|oisForScope
argument_list|(
name|coreScopeOntologySet
index|[
name|o
index|]
argument_list|)
decl_stmt|;
try|try
block|{
name|ontologySpace
operator|.
name|addOntology
argument_list|(
name|ois
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|UnmodifiableOntologyCollectorException
name|ex
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"Unmodifiable Ontology SpaceException."
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
block|}
name|ontologySpace
operator|.
name|setUp
argument_list|()
expr_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"The set of ontologies loaded in the core scope space is: "
operator|+
name|ontologySpace
operator|.
name|getOntologies
argument_list|(
literal|true
argument_list|)
operator|+
literal|"\nN.B. The root.owl ontology is the first (on the list) ontology added when the scope is created."
argument_list|)
expr_stmt|;
comment|/*          * The first thing to do is to create a recipe in the rule store that can be used by the engine to          * refactor the enhancement graphs.          */
name|recipeIRI
operator|=
name|IRI
operator|.
name|create
argument_list|(
operator|(
name|String
operator|)
name|context
operator|.
name|getProperties
argument_list|()
operator|.
name|get
argument_list|(
name|RECIPE_URI
argument_list|)
argument_list|)
expr_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Start create the Recipe"
argument_list|,
name|this
argument_list|)
expr_stmt|;
name|ruleStore
operator|.
name|addRecipe
argument_list|(
name|recipeIRI
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"The recipe has been created"
argument_list|,
name|this
argument_list|)
expr_stmt|;
comment|/*          * The set of rule to put in the recipe can be provided by the user. A default set of rules is          * provided in /META-INF/default/seo_rules.sem. Use the property engine.refactor in the felix console          * to pass to the engine your set of rules.          */
name|String
name|recipeURI
init|=
operator|(
name|String
operator|)
name|context
operator|.
name|getProperties
argument_list|()
operator|.
name|get
argument_list|(
name|RECIPE_URI
argument_list|)
decl_stmt|;
name|InputStream
name|recipeStream
init|=
literal|null
decl_stmt|;
name|String
name|recipeString
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|recipeURI
operator|!=
literal|null
operator|&&
operator|!
name|recipeURI
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|IDereferencer
name|dereferencer
init|=
operator|new
name|Dereferencer
argument_list|()
decl_stmt|;
try|try
block|{
name|recipeStream
operator|=
name|dereferencer
operator|.
name|resolve
argument_list|(
name|recipeURI
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
comment|// TODO Auto-generated catch block
name|e
operator|.
name|printStackTrace
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
name|recipeStream
operator|=
name|RefactorEnhancementEngine
operator|.
name|class
operator|.
name|getResourceAsStream
argument_list|(
literal|"/META-INF/default/seo_rules.sem"
argument_list|)
expr_stmt|;
block|}
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Refactorer engine recipe stream "
operator|+
name|recipeStream
argument_list|)
expr_stmt|;
if|if
condition|(
name|recipeStream
operator|!=
literal|null
condition|)
block|{
name|recipeString
operator|=
literal|""
expr_stmt|;
name|BufferedReader
name|reader
init|=
operator|new
name|BufferedReader
argument_list|(
operator|new
name|InputStreamReader
argument_list|(
name|recipeStream
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|line
init|=
literal|null
decl_stmt|;
try|try
block|{
while|while
condition|(
operator|(
name|line
operator|=
name|reader
operator|.
name|readLine
argument_list|()
operator|)
operator|!=
literal|null
condition|)
block|{
name|recipeString
operator|+=
name|line
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|// TODO Auto-generated catch block
name|e
operator|.
name|printStackTrace
argument_list|()
expr_stmt|;
block|}
block|}
comment|/*          * step 3          */
try|try
block|{
comment|// ruleStore.addRuleToRecipe(recipeIRI.toString(), kReSRuleSyntax);
name|ruleStore
operator|.
name|addRuleToRecipe
argument_list|(
name|recipeIRI
operator|.
name|toString
argument_list|()
argument_list|,
name|recipeString
argument_list|)
expr_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Added rules to recipe "
operator|+
name|recipeIRI
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchRecipeException
name|e
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"The recipe does not exists: "
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
name|log
operator|.
name|info
argument_list|(
literal|"Activated Dulcifier engine"
argument_list|)
expr_stmt|;
block|}
specifier|protected
name|void
name|deactivate
parameter_list|(
name|ComponentContext
name|context
parameter_list|)
block|{
comment|/*          * Deactivating the dulcifier. The procedure require: 1) get all the rules from the recipe 2) remove          * the recipe. 3) remove the single rule. 4) tear down the scope ontologySpace and the scope itself.          */
try|try
block|{
comment|/*              * step 1: get all the rule              */
name|RuleList
name|recipeRuleList
init|=
name|ruleStore
operator|.
name|getRecipe
argument_list|(
name|recipeIRI
argument_list|)
operator|.
name|getkReSRuleList
argument_list|()
decl_stmt|;
comment|/*              * step 2: remove the recipe              */
if|if
condition|(
name|ruleStore
operator|.
name|removeRecipe
argument_list|(
name|recipeIRI
argument_list|)
condition|)
block|{
name|log
operator|.
name|info
argument_list|(
literal|"The recipe "
operator|+
name|recipeIRI
operator|+
literal|" has been removed correctly"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|log
operator|.
name|error
argument_list|(
literal|"The recipe "
operator|+
name|recipeIRI
operator|+
literal|" can not be removed"
argument_list|)
expr_stmt|;
block|}
comment|/*              * step 3: remove the rules              */
for|for
control|(
name|Rule
name|rule
range|:
name|recipeRuleList
control|)
block|{
if|if
condition|(
name|ruleStore
operator|.
name|removeRule
argument_list|(
name|rule
argument_list|)
condition|)
block|{
name|log
operator|.
name|info
argument_list|(
literal|"The rule "
operator|+
name|rule
operator|.
name|getRuleName
argument_list|()
operator|+
literal|" has been removed correctly"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|log
operator|.
name|error
argument_list|(
literal|"The rule "
operator|+
name|rule
operator|.
name|getRuleName
argument_list|()
operator|+
literal|" can not be removed"
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*              * step 4:              */
name|scope
operator|.
name|getCoreSpace
argument_list|()
operator|.
name|tearDown
argument_list|()
expr_stmt|;
name|scope
operator|.
name|tearDown
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchRecipeException
name|ex
parameter_list|)
block|{
name|log
operator|.
name|error
argument_list|(
literal|"The recipe "
operator|+
name|recipeIRI
operator|+
literal|" doesn't exist"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
name|log
operator|.
name|info
argument_list|(
literal|"Deactivated Dulcifier engine"
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|Object
argument_list|>
name|getServiceProperties
parameter_list|()
block|{
return|return
name|Collections
operator|.
name|unmodifiableMap
argument_list|(
name|Collections
operator|.
name|singletonMap
argument_list|(
name|ServiceProperties
operator|.
name|ENHANCEMENT_ENGINE_ORDERING
argument_list|,
operator|(
name|Object
operator|)
name|ServiceProperties
operator|.
name|ORDERING_POST_PROCESSING
argument_list|)
argument_list|)
return|;
block|}
comment|/**      * Fetch the OWLOntology containing the graph associated to an entity from Linked Data. It uses the Entity      * Hub for accessing LOD and fetching entities.      *       * @param entityURI      *            {@link String}      * @return the {@link OWLOntology} of the entity      */
specifier|private
name|OWLOntology
name|getEntityOntology
parameter_list|(
name|String
name|entityURI
parameter_list|)
block|{
name|OWLOntology
name|fetchedOntology
init|=
literal|null
decl_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Asking entity: "
operator|+
name|entityURI
argument_list|)
expr_stmt|;
comment|/*          * Ask to the entityhub the fetch the entity.          */
name|Entity
name|entitySign
init|=
name|referencedSiteManager
operator|.
name|getEntity
argument_list|(
name|entityURI
argument_list|)
decl_stmt|;
comment|/*          * Wrap the entity graph into an owl ontology.          */
name|MGraph
name|entityMGraph
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|entitySign
operator|!=
literal|null
condition|)
block|{
name|Representation
name|entityRepresentation
init|=
name|entitySign
operator|.
name|getRepresentation
argument_list|()
decl_stmt|;
name|RdfRepresentation
name|entityRdfRepresentation
init|=
name|RdfValueFactory
operator|.
name|getInstance
argument_list|()
operator|.
name|toRdfRepresentation
argument_list|(
name|entityRepresentation
argument_list|)
decl_stmt|;
name|TripleCollection
name|tripleCollection
init|=
name|entityRdfRepresentation
operator|.
name|getRdfGraph
argument_list|()
decl_stmt|;
name|entityMGraph
operator|=
operator|new
name|SimpleMGraph
argument_list|()
expr_stmt|;
name|entityMGraph
operator|.
name|addAll
argument_list|(
name|tripleCollection
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|entityMGraph
operator|!=
literal|null
condition|)
block|{
comment|/*              * OWLOntologyManager manager = OWLManager.createOWLOntologyManager(); final OWLOntology fetched =              * manager.loadOntologyFromOntologyDocument(dereferencer.resolve(entityReferenceString));              */
name|fetchedOntology
operator|=
name|OWLAPIToClerezzaConverter
operator|.
name|clerezzaGraphToOWLOntology
argument_list|(
name|entityMGraph
argument_list|)
expr_stmt|;
block|}
return|return
name|fetchedOntology
return|;
block|}
block|}
end_class

end_unit

