begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/* * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements.  See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the "License"); you may not use this file except in compliance with * the License.  You may obtain a copy of the License at * *     http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */
end_comment

begin_comment
comment|/**  *   */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|entitylinking
operator|.
name|impl
package|;
end_package

begin_import
import|import static
name|java
operator|.
name|util
operator|.
name|Collections
operator|.
name|disjoint
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|NlpAnnotations
operator|.
name|PHRASE_ANNOTATION
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|NlpAnnotations
operator|.
name|POS_ANNOTATION
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|EnumSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|collections
operator|.
name|Predicate
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|collections
operator|.
name|iterators
operator|.
name|FilterIterator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|entitylinking
operator|.
name|config
operator|.
name|EntityLinkerConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|engines
operator|.
name|entitylinking
operator|.
name|config
operator|.
name|LanguageProcessingConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|NlpAnnotations
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|AnalysedText
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|Chunk
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|Section
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|Sentence
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|Span
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|Span
operator|.
name|SpanTypeEnum
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|Token
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|model
operator|.
name|annotation
operator|.
name|Value
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|morpho
operator|.
name|MorphoFeatures
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|phrase
operator|.
name|PhraseTag
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|stanbol
operator|.
name|enhancer
operator|.
name|nlp
operator|.
name|pos
operator|.
name|PosTag
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_class
specifier|public
class|class
name|ProcessingState
block|{
specifier|private
specifier|final
name|Logger
name|log
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|ProcessingState
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/**      * Iterator over the sentences (might be      * the whole {@link AnalysedText} if no sentences are      * defined).      */
specifier|private
specifier|final
name|Iterator
argument_list|<
name|?
extends|extends
name|Section
argument_list|>
name|sections
decl_stmt|;
comment|/**      * The sentence currently processed      */
specifier|private
name|Section
name|section
decl_stmt|;
comment|/**      * Holds the {@link Token}s of the current {@link #sentence}       * to allow fast index based access.      */
specifier|private
name|List
argument_list|<
name|TokenData
argument_list|>
name|tokens
init|=
operator|new
name|ArrayList
argument_list|<
name|TokenData
argument_list|>
argument_list|(
literal|64
argument_list|)
decl_stmt|;
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
specifier|private
name|Iterator
argument_list|<
name|TokenData
argument_list|>
name|processableTokensIterator
init|=
name|Collections
operator|.
name|EMPTY_LIST
operator|.
name|iterator
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|EnumSet
argument_list|<
name|SpanTypeEnum
argument_list|>
name|enclosedSpanTypes
decl_stmt|;
comment|/**      * The current token      */
specifier|private
name|TokenData
name|token
decl_stmt|;
comment|/**      * The position of the last consumed position      */
specifier|private
name|int
name|consumedIndex
init|=
operator|-
literal|1
decl_stmt|;
comment|/**      * The language of the text      */
specifier|private
name|String
name|language
decl_stmt|;
specifier|protected
specifier|final
name|LanguageProcessingConfig
name|tpc
decl_stmt|;
specifier|protected
specifier|final
name|EntityLinkerConfig
name|elc
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Predicate
name|PROCESSABLE_TOKEN_OREDICATE
init|=
operator|new
name|Predicate
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|evaluate
parameter_list|(
name|Object
name|object
parameter_list|)
block|{
return|return
operator|(
operator|(
name|TokenData
operator|)
name|object
operator|)
operator|.
name|isProcessable
return|;
block|}
block|}
decl_stmt|;
specifier|public
name|ProcessingState
parameter_list|(
name|AnalysedText
name|at
parameter_list|,
name|String
name|language
parameter_list|,
name|LanguageProcessingConfig
name|tpc
parameter_list|,
name|EntityLinkerConfig
name|elc
parameter_list|)
block|{
if|if
condition|(
name|at
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"The parsed AnalysedText MUST NOT be NULL!"
argument_list|)
throw|;
block|}
if|if
condition|(
name|language
operator|==
literal|null
operator|||
name|language
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"The parsed Language MUST NOT be NULL nor empty!"
argument_list|)
throw|;
block|}
if|if
condition|(
name|tpc
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"The parsed TextProcessingConfig MUST NOT be NULL!"
argument_list|)
throw|;
block|}
if|if
condition|(
name|elc
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"The parsed EntityLinkerConfig MUST NOT be NULL!"
argument_list|)
throw|;
block|}
name|this
operator|.
name|tpc
operator|=
name|tpc
expr_stmt|;
name|this
operator|.
name|elc
operator|=
name|elc
expr_stmt|;
name|enclosedSpanTypes
operator|=
name|EnumSet
operator|.
name|of
argument_list|(
name|SpanTypeEnum
operator|.
name|Token
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|tpc
operator|.
name|isIgnoreChunks
argument_list|()
condition|)
block|{
name|enclosedSpanTypes
operator|.
name|add
argument_list|(
name|SpanTypeEnum
operator|.
name|Chunk
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|language
operator|=
name|language
expr_stmt|;
comment|//prefer to iterate over sentences
name|Iterator
argument_list|<
name|Sentence
argument_list|>
name|sentences
init|=
name|at
operator|.
name|getSentences
argument_list|()
decl_stmt|;
name|this
operator|.
name|sections
operator|=
name|sentences
operator|.
name|hasNext
argument_list|()
condition|?
name|sentences
else|:
name|Collections
operator|.
name|singleton
argument_list|(
name|at
argument_list|)
operator|.
name|iterator
argument_list|()
expr_stmt|;
comment|//init the first sentence
name|initNextSentence
argument_list|()
expr_stmt|;
block|}
comment|/**      * Getter for the current section. This is typically a {@link Sentence}      * but might also be the whole {@link AnalysedText} in case no sentence      * annotations are available      * @return the currently processed {@link Section}      */
specifier|public
specifier|final
name|Section
name|getSentence
parameter_list|()
block|{
return|return
name|section
return|;
block|}
comment|/**      * Getter for the current token      * @return the token for the currently processed word      */
specifier|public
name|TokenData
name|getToken
parameter_list|()
block|{
return|return
name|token
return|;
block|}
comment|/**      * Getter for the Tokens of the currently processed section      * @return the Tokens of the currently processed section      */
specifier|public
name|List
argument_list|<
name|TokenData
argument_list|>
name|getTokens
parameter_list|()
block|{
return|return
name|tokens
return|;
block|}
comment|/**      * Getter for the last consumed index      * @return the index of the last consumed token      */
specifier|public
specifier|final
name|int
name|getConsumedIndex
parameter_list|()
block|{
return|return
name|consumedIndex
return|;
block|}
comment|/**      * Getter for the language of the current Token (based on the current      * sentence)      * @return the language      */
specifier|public
specifier|final
name|String
name|getLanguage
parameter_list|()
block|{
return|return
name|language
return|;
block|}
comment|//    /**
comment|//     * Getter for the next {@link Token} to be processed. Calling {@link #next()}
comment|//     * is guaranteed to skip all tokens in between {@link #getTokenIndex()}
comment|//     * and {@link #getNextToken()}, but it might even skip more tokens (e.g.
comment|//     * in case that the token referenced by {@link #getNextToken()} is not
comment|//     * within a {@link Chunk}
comment|//     * @return the nextToken
comment|//     */
comment|//    public final int getNextToken() {
comment|//        return nextToken;
comment|//    }
comment|/**      * The index of an consumed Token. The consumed index MUST BE equals or      * greater as {@link #getTokenIndex()}. If the consumed index is set to a      * value greater that {@link #getTokenIndex()} than consumed tokens are      * skipped on the next call to {@link #next()}      * @param pos the position of the last consumed token.      */
specifier|public
name|void
name|setConsumed
parameter_list|(
name|int
name|pos
parameter_list|)
block|{
if|if
condition|(
name|pos
operator|>=
name|token
operator|.
name|index
condition|)
block|{
name|this
operator|.
name|consumedIndex
operator|=
name|pos
expr_stmt|;
comment|//            this.nextToken = pos+1;
block|}
else|else
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"The lastConsumedPos "
operator|+
name|pos
operator|+
literal|" MUST BE equals or gerater than the current Pos "
operator|+
name|token
operator|.
name|index
argument_list|)
throw|;
block|}
block|}
comment|/**      * Moves the state to next processable token after the index #nextToken      * @return<code>true</code> if there are further elements to process or      *<code>false</code> if there are no further elements to process.      */
specifier|public
name|boolean
name|next
parameter_list|()
block|{
while|while
condition|(
name|processableTokensIterator
operator|.
name|hasNext
argument_list|()
operator|||
name|initNextSentence
argument_list|()
condition|)
block|{
name|TokenData
name|token
init|=
name|processableTokensIterator
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|token
operator|.
name|index
operator|>
name|consumedIndex
condition|)
block|{
name|this
operator|.
name|token
operator|=
name|token
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
return|return
literal|false
return|;
block|}
comment|/**      * Correctly initialise {@link #sentence}, {@link #chunks}, {@link #chunk}      * and {@link #tokenIndex} for the next element of {@link #sections}. If      * no further sentences are to process it simple sets {@link #sentence},       * {@link #chunks}, {@link #chunk} and {@link #tokenIndex} to<code>null</code>      */
specifier|private
name|boolean
name|initNextSentence
parameter_list|()
block|{
name|section
operator|=
literal|null
expr_stmt|;
name|processableTokensIterator
operator|=
literal|null
expr_stmt|;
name|consumedIndex
operator|=
operator|-
literal|1
expr_stmt|;
name|boolean
name|foundProcessable
init|=
literal|false
decl_stmt|;
while|while
condition|(
operator|!
name|foundProcessable
operator|&&
name|sections
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|section
operator|=
name|sections
operator|.
name|next
argument_list|()
expr_stmt|;
name|tokens
operator|.
name|clear
argument_list|()
expr_stmt|;
comment|//clear token for each section (STANBOL-818)
name|Iterator
argument_list|<
name|Span
argument_list|>
name|enclosed
init|=
name|section
operator|.
name|getEnclosed
argument_list|(
name|enclosedSpanTypes
argument_list|)
decl_stmt|;
name|ChunkData
name|activeChunk
init|=
literal|null
decl_stmt|;
while|while
condition|(
name|enclosed
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|Span
name|span
init|=
name|enclosed
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|span
operator|.
name|getType
argument_list|()
operator|==
name|SpanTypeEnum
operator|.
name|Chunk
condition|)
block|{
name|ChunkData
name|chunkData
init|=
operator|new
name|ChunkData
argument_list|(
operator|(
name|Chunk
operator|)
name|span
argument_list|)
decl_stmt|;
if|if
condition|(
name|chunkData
operator|.
name|isProcessable
condition|)
block|{
if|if
condition|(
name|activeChunk
operator|!=
literal|null
condition|)
block|{
comment|//current Chunk not yet closed -> overlapping chunks!
if|if
condition|(
name|activeChunk
operator|.
name|getEndChar
argument_list|()
operator|<
name|span
operator|.
name|getEnd
argument_list|()
condition|)
block|{
comment|//merge partly overlapping chunks
name|log
operator|.
name|info
argument_list|(
literal|"   - merge overlapping and processable Chunks {}<-> {}"
argument_list|,
name|activeChunk
operator|.
name|merged
operator|==
literal|null
condition|?
name|activeChunk
operator|.
name|chunk
else|:
name|activeChunk
operator|.
name|merged
argument_list|,
name|span
argument_list|)
expr_stmt|;
name|activeChunk
operator|.
name|merged
operator|=
operator|(
name|Chunk
operator|)
name|span
expr_stmt|;
comment|//set this one as last merged
block|}
comment|//ignore completely covered chunks
block|}
else|else
block|{
comment|// a new Chunk starts
name|activeChunk
operator|=
name|chunkData
expr_stmt|;
name|activeChunk
operator|.
name|startToken
operator|=
name|tokens
operator|.
name|size
argument_list|()
expr_stmt|;
if|if
condition|(
name|log
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|log
operator|.
name|debug
argument_list|(
literal|">> Chunk: (type:{}, startPos: {}) text: '{}'"
argument_list|,
operator|new
name|Object
index|[]
block|{
name|activeChunk
operator|.
name|chunk
operator|.
name|getType
argument_list|()
block|,
name|activeChunk
operator|.
name|startToken
block|,
name|activeChunk
operator|.
name|chunk
operator|.
name|getSpan
argument_list|()
block|}
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|//else ignore chunks that are not processable
block|}
elseif|else
if|if
condition|(
name|span
operator|.
name|getType
argument_list|()
operator|==
name|SpanTypeEnum
operator|.
name|Token
condition|)
block|{
name|TokenData
name|tokenData
init|=
operator|new
name|TokenData
argument_list|(
name|tokens
operator|.
name|size
argument_list|()
argument_list|,
operator|(
name|Token
operator|)
name|span
argument_list|,
name|activeChunk
argument_list|)
decl_stmt|;
if|if
condition|(
name|log
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|log
operator|.
name|debug
argument_list|(
literal|"> Token {}: {} (pos:{}) chunk: '{}' | morpho: {}"
argument_list|,
operator|new
name|Object
index|[]
block|{
name|tokenData
operator|.
name|index
block|,
name|tokenData
operator|.
name|token
block|,
name|tokenData
operator|.
name|token
operator|.
name|getAnnotations
argument_list|(
name|POS_ANNOTATION
argument_list|)
block|,
name|tokenData
operator|.
name|inChunk
operator|!=
literal|null
condition|?
name|tokenData
operator|.
name|inChunk
operator|.
name|chunk
operator|.
name|getSpan
argument_list|()
else|:
literal|"none"
block|,
name|tokenData
operator|.
name|morpho
operator|!=
literal|null
condition|?
name|tokenData
operator|.
name|morpho
else|:
literal|"none"
block|}
argument_list|)
expr_stmt|;
block|}
name|tokens
operator|.
name|add
argument_list|(
name|tokenData
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|foundProcessable
condition|)
block|{
name|foundProcessable
operator|=
name|tokenData
operator|.
name|isProcessable
expr_stmt|;
block|}
if|if
condition|(
name|activeChunk
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|tokenData
operator|.
name|isMatchable
condition|)
block|{
name|activeChunk
operator|.
name|matchableCount
operator|++
expr_stmt|;
block|}
if|if
condition|(
name|span
operator|.
name|getEnd
argument_list|()
operator|>=
name|activeChunk
operator|.
name|getEndChar
argument_list|()
condition|)
block|{
comment|//this is the last token in the current chunk
name|activeChunk
operator|.
name|endToken
operator|=
name|tokens
operator|.
name|size
argument_list|()
operator|-
literal|1
expr_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"   - end Chunk@pos: {}"
argument_list|,
name|activeChunk
operator|.
name|endToken
argument_list|)
expr_stmt|;
if|if
condition|(
name|tpc
operator|.
name|isLinkMultiMatchableTokensInChunk
argument_list|()
operator|&&
name|activeChunk
operator|.
name|matchableCount
operator|>
literal|1
condition|)
block|{
name|log
operator|.
name|debug
argument_list|(
literal|"   - multi-matchable Chunk:"
argument_list|)
expr_stmt|;
comment|//mark the last of two immediate following matchable
comment|//tokens as processable
for|for
control|(
name|int
name|i
init|=
name|activeChunk
operator|.
name|endToken
operator|-
literal|1
init|;
name|i
operator|>=
name|activeChunk
operator|.
name|startToken
operator|+
literal|1
condition|;
name|i
operator|--
control|)
block|{
name|TokenData
name|ct
init|=
name|tokens
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|TokenData
name|pt
init|=
name|tokens
operator|.
name|get
argument_list|(
name|i
operator|-
literal|1
argument_list|)
decl_stmt|;
if|if
condition|(
name|ct
operator|.
name|isMatchable
operator|&&
name|pt
operator|.
name|isMatchable
condition|)
block|{
if|if
condition|(
operator|!
name|ct
operator|.
name|isProcessable
condition|)
block|{
comment|//if not already processable
name|log
operator|.
name|debug
argument_list|(
literal|"> convert Token {}: {} (pos:{}) from matchable to processable"
argument_list|,
operator|new
name|Object
index|[]
block|{
name|i
block|,
name|ct
operator|.
name|token
operator|.
name|getSpan
argument_list|()
block|,
name|ct
operator|.
name|token
operator|.
name|getAnnotations
argument_list|(
name|POS_ANNOTATION
argument_list|)
block|}
argument_list|)
expr_stmt|;
name|ct
operator|.
name|isProcessable
operator|=
literal|true
expr_stmt|;
if|if
condition|(
operator|!
name|foundProcessable
condition|)
block|{
name|foundProcessable
operator|=
literal|true
expr_stmt|;
block|}
block|}
name|i
operator|--
expr_stmt|;
comment|//mark both (ct& pt) as processed
block|}
block|}
block|}
name|activeChunk
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
block|}
if|if
condition|(
name|activeChunk
operator|!=
literal|null
condition|)
block|{
comment|//close the last chunk (if not done)
name|activeChunk
operator|.
name|endToken
operator|=
name|tokens
operator|.
name|size
argument_list|()
operator|-
literal|1
expr_stmt|;
block|}
block|}
name|processableTokensIterator
operator|=
operator|new
name|FilterIterator
argument_list|(
name|tokens
operator|.
name|iterator
argument_list|()
argument_list|,
name|PROCESSABLE_TOKEN_OREDICATE
argument_list|)
expr_stmt|;
return|return
name|foundProcessable
return|;
block|}
comment|/**      * Getter for the text covered by the next tokenCount tokens relative to      * {@link #token}. It uses the {@link #textCache} to lookup/store such texts.      * Given the Tokens      *<pre>      *    [This, is, an, Example]      *</pre>      * and the parameter<code>3</code> this method will return      *<pre>      *     This is an      *</pre>      * @param tokenCount the number of tokens to be included relative to       * {@link #tokenIndex}      * @return the text covered by the span start of {@link #token} to end of      * token at<code>{@link #tokenIndex}+tokenCount</code>.      */
specifier|public
name|String
name|getTokenText
parameter_list|(
name|int
name|start
parameter_list|,
name|int
name|tokenCount
parameter_list|)
block|{
name|int
name|offset
init|=
name|section
operator|.
name|getStart
argument_list|()
decl_stmt|;
return|return
name|section
operator|.
name|getSpan
argument_list|()
operator|.
name|substring
argument_list|(
name|tokens
operator|.
name|get
argument_list|(
name|start
argument_list|)
operator|.
name|token
operator|.
name|getStart
argument_list|()
operator|-
name|offset
argument_list|,
name|tokens
operator|.
name|get
argument_list|(
name|start
operator|+
operator|(
name|tokenCount
operator|-
literal|1
operator|)
argument_list|)
operator|.
name|token
operator|.
name|getEnd
argument_list|()
operator|-
name|offset
argument_list|)
return|;
block|}
comment|//    /**
comment|//     */
comment|//    protected boolean getProcessablePosTag(Token token) {
comment|//        for(Value<PosTag> posAnnotation : token.getAnnotations(POS_ANNOTATION)){
comment|//            // check three possible match
comment|//            //  1. the LexicalCategory matches
comment|//            //  2. the Pos matches
comment|//            //  3. the String tag matches
comment|//            PosTag posTag = posAnnotation.value();
comment|////            log.debug("   ... check PosAnntation {} (lc:{}|pos:{}|tag:{}",
comment|////                new Object[]{posAnnotation,posTag.getCategories(),
comment|////                             posTag.getPosHierarch(),posTag.getTag()});
comment|//            if((!Collections.disjoint(tpc.getProcessedLexicalCategories(),
comment|//                    posTag.getCategories())) ||
comment|//                (!Collections.disjoint(tpc.getProcessedPos(),
comment|//                    posTag.getPosHierarchy())) ||
comment|//                tpc.getProcessedPosTags().contains(
comment|//                    posTag.getTag())){
comment|//                if(posAnnotation.probability()>= tpc.getMinPosAnnotationProbability()){
comment|//                    return true;
comment|//                } // else probability to low for inclusion
comment|//            } else if(posAnnotation.probability()>= tpc.getMinExcludePosAnnotationProbability()){
comment|//                return false;
comment|//            } // else probability to low for exclusion
comment|//        }
comment|//        return token.getSpan().length()>= elc.getMinSearchTokenLength();
comment|//    }
comment|// Both
comment|//    protected boolean isMatchableToken(Token token){
comment|//        for(Value<PosTag> posAnnotation : token.getAnnotations(POS_ANNOTATION)){
comment|//            PosTag posTag = posAnnotation.value();
comment|//            if(posTag.isMapped()){
comment|//                if(!Collections.disjoint(tpc.getMatchableLexicalCategories(),
comment|//                    posTag.getCategories())){
comment|//                    if(posAnnotation.probability()>= tpc.getMinPosAnnotationProbability()){
comment|//                        return true;
comment|//                    } // else probability to low for inclusion
comment|//                } else if(posAnnotation.probability()>= tpc.getMinExcludePosAnnotationProbability()){
comment|//                    return false;
comment|//                } // else probability to low for exclusion
comment|//            } //else not matched ... search next one
comment|//        }
comment|//        return token.getSpan().length()>= elc.getMinSearchTokenLength();
comment|//    }
comment|//
comment|//
comment|//    protected boolean isProcesableChunk(Chunk chunk){
comment|//        for(Value<PhraseTag> phraseAnnotation : chunk.getAnnotations(PHRASE_ANNOTATION)){
comment|//            if(tpc.getProcessedPhraseCategories().contains(
comment|//                phraseAnnotation.value().getCategory()) ||
comment|//                tpc.getProcessedPhraseTags().contains(
comment|//                    phraseAnnotation.value().getTag())){
comment|//                if(phraseAnnotation.probability()>= tpc.getMinPhraseAnnotationProbability()){
comment|//                    return true;
comment|//                } // else probability to low for inclusion
comment|//            } else if(phraseAnnotation.probability()>= tpc.getMinExcludePhraseAnnotationProbability()){
comment|//                return false;
comment|//            } // else probability to low for exclusion
comment|//        }
comment|//        //neither a clear accept/reject ...
comment|//        return true;
comment|//    }
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|'['
argument_list|)
operator|.
name|append
argument_list|(
name|token
operator|.
name|index
argument_list|)
operator|.
name|append
argument_list|(
literal|','
argument_list|)
operator|.
name|append
argument_list|(
name|token
operator|.
name|token
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|"] chunk: "
argument_list|)
expr_stmt|;
if|if
condition|(
name|token
operator|.
name|inChunk
operator|==
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|"none"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|sb
operator|.
name|append
argument_list|(
name|token
operator|.
name|inChunk
operator|.
name|chunk
argument_list|)
expr_stmt|;
if|if
condition|(
name|token
operator|.
name|inChunk
operator|.
name|merged
operator|!=
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|"(merged with "
argument_list|)
operator|.
name|append
argument_list|(
name|token
operator|.
name|inChunk
operator|.
name|merged
argument_list|)
operator|.
name|append
argument_list|(
literal|')'
argument_list|)
expr_stmt|;
block|}
block|}
name|sb
operator|.
name|append
argument_list|(
literal|"| sentence: "
argument_list|)
expr_stmt|;
if|if
condition|(
name|section
operator|==
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|"none"
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|section
operator|.
name|getSpan
argument_list|()
operator|.
name|length
argument_list|()
operator|>
literal|45
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|section
operator|.
name|getSpan
argument_list|()
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
literal|45
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|" ..."
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|sb
operator|.
name|append
argument_list|(
name|section
operator|.
name|getSpan
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**      * Internally used to store additional Metadata for Tokens of the current Sentence      *<p>      * Checks if the parsed {@link Token} is processable. This decision is taken first based on the POS      * annotation ( Lexical Category, POS tag) and second on the      * {@link EntityLinkerConfig#getMinSearchTokenLength()} if no POS annotations are available or the      * probability of the POS annotations is to low.      *<p>      * Since STANBOL-685two POS Probabilities are used<ul>      *<li> {@link LanguageProcessingConfig#getMinPosAnnotationProbability()} for accepting POS tags that are      * processed - included in {@link LanguageProcessingConfig#getLinkedLexicalCategories()} or      * {@link LanguageProcessingConfig#getLinkedPosTags()}.      *<li> {@link LanguageProcessingConfig#getMinExcludePosAnnotationProbability()} for those that are not      * processed. By default the exclusion probability is set to half of the inclusion one.      *</ul>      * Assuming that the<code>minPosTypePropb=0.667</code> a      *<ul>      *<li>noun with the prop 0.8 would result in returning<code>true</code>      *<li>noun with prop 0.5 would return<code>null</code>      *<li>verb with prop 0.4 would return<code>false</code>      *<li>verb with prop 0.3 would return<code>null</code>      *</ul>      * This algorithm makes it less likely that the {@link EntityLinkerConfig#getMinSearchTokenLength()} needs      * to be used as fallback for Tokens (what typically still provides better estimations as the token      * length).      *<p>      * (see also STANBOL-685 even that this Issue refers a version of this Engine that has not yet used the      * Stanbol NLP processing chain)      *       * @param token      *            the {@link Token} to check.      * @return<code>true</code> if the parsed token needs to be processed. Otherwise<code>false</code>      */
class|class
name|TokenData
block|{
comment|/** The Token */
specifier|final
name|Token
name|token
decl_stmt|;
comment|/** The index of the Token within the current Section (Sentence) */
specifier|final
name|int
name|index
decl_stmt|;
comment|/** If this Token should be linked with the Vocabulary */
name|boolean
name|isProcessable
decl_stmt|;
comment|/** If this Token should be used for multi word searches in the Vocabulary */
name|boolean
name|isMatchable
decl_stmt|;
comment|/** if this Token has an alpha or numeric char */
specifier|final
name|boolean
name|hasAlphaNumeric
decl_stmt|;
comment|/** the chunk of this Token */
specifier|final
name|ChunkData
name|inChunk
decl_stmt|;
comment|/** the morphological features of the Token (selected based on the POS Tag) */
specifier|final
name|MorphoFeatures
name|morpho
decl_stmt|;
comment|/**          * Constructs and initializes meta data needed for linking based           * on the current tokens (and its NLP annotation)          * @param index the index of the Token within the current section          * @param token the token          * @param chunk the current chunk or<code>null</code> if none          */
name|TokenData
parameter_list|(
name|int
name|index
parameter_list|,
name|Token
name|token
parameter_list|,
name|ChunkData
name|chunk
parameter_list|)
block|{
comment|//(0) init fields
name|this
operator|.
name|token
operator|=
name|token
expr_stmt|;
name|this
operator|.
name|index
operator|=
name|index
expr_stmt|;
name|this
operator|.
name|inChunk
operator|=
name|chunk
expr_stmt|;
name|this
operator|.
name|hasAlphaNumeric
operator|=
name|Utils
operator|.
name|hasAlphaNumericChar
argument_list|(
name|token
operator|.
name|getSpan
argument_list|()
argument_list|)
expr_stmt|;
name|PosTag
name|selectedPosTag
init|=
literal|null
decl_stmt|;
name|boolean
name|matchedPosTag
init|=
literal|false
decl_stmt|;
comment|//matched any of the POS annotations
comment|//(1) check if this Token should be linked against the Vocabulary (isProcessable)
name|boolean
name|upperCase
init|=
name|index
operator|>
literal|0
operator|&&
name|Character
operator|.
name|isUpperCase
argument_list|(
name|token
operator|.
name|getSpan
argument_list|()
operator|.
name|codePointAt
argument_list|(
literal|0
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|tpc
operator|.
name|isLinkUpperCaseTokens
argument_list|()
operator|&&
name|upperCase
condition|)
block|{
name|isProcessable
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
comment|//else use POS tag& token length
for|for
control|(
name|Value
argument_list|<
name|PosTag
argument_list|>
name|posAnnotation
range|:
name|token
operator|.
name|getAnnotations
argument_list|(
name|POS_ANNOTATION
argument_list|)
control|)
block|{
comment|// check three possible match
comment|//  1. the LexicalCategory matches
comment|//  2. the Pos matches
comment|//  3. the String tag matches
name|PosTag
name|posTag
init|=
name|posAnnotation
operator|.
name|value
argument_list|()
decl_stmt|;
if|if
condition|(
operator|(
operator|!
name|disjoint
argument_list|(
name|tpc
operator|.
name|getLinkedLexicalCategories
argument_list|()
argument_list|,
name|posTag
operator|.
name|getCategories
argument_list|()
argument_list|)
operator|)
operator|||
operator|(
operator|!
name|disjoint
argument_list|(
name|tpc
operator|.
name|getLinkedPos
argument_list|()
argument_list|,
name|posTag
operator|.
name|getPosHierarchy
argument_list|()
argument_list|)
operator|)
operator|||
name|tpc
operator|.
name|getLinkedPosTags
argument_list|()
operator|.
name|contains
argument_list|(
name|posTag
operator|.
name|getTag
argument_list|()
argument_list|)
condition|)
block|{
if|if
condition|(
name|posAnnotation
operator|.
name|probability
argument_list|()
operator|>=
name|tpc
operator|.
name|getMinPosAnnotationProbability
argument_list|()
condition|)
block|{
name|selectedPosTag
operator|=
name|posTag
expr_stmt|;
name|isProcessable
operator|=
literal|true
expr_stmt|;
name|matchedPosTag
operator|=
literal|true
expr_stmt|;
break|break;
block|}
comment|// else probability to low for inclusion
block|}
elseif|else
if|if
condition|(
name|posAnnotation
operator|.
name|probability
argument_list|()
operator|>=
name|tpc
operator|.
name|getMinExcludePosAnnotationProbability
argument_list|()
condition|)
block|{
name|selectedPosTag
operator|=
name|posTag
expr_stmt|;
comment|//also rejected PosTags are selected
name|matchedPosTag
operator|=
literal|true
expr_stmt|;
name|isProcessable
operator|=
literal|false
expr_stmt|;
break|break;
block|}
comment|// else probability to low for exclusion
block|}
if|if
condition|(
operator|!
name|matchedPosTag
condition|)
block|{
comment|//not matched against a POS Tag ...
comment|// ... fall back to the token length
name|isProcessable
operator|=
name|token
operator|.
name|getSpan
argument_list|()
operator|.
name|length
argument_list|()
operator|>=
name|elc
operator|.
name|getMinSearchTokenLength
argument_list|()
expr_stmt|;
block|}
block|}
comment|//(2) check if this token should be considered to match labels of suggestions
if|if
condition|(
name|isProcessable
condition|)
block|{
comment|//processable tokens are also matchable
name|isMatchable
operator|=
literal|true
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|tpc
operator|.
name|isMatchUpperCaseTokens
argument_list|()
operator|&&
name|upperCase
condition|)
block|{
comment|//match upper case tokens regardless of POS and length
name|isMatchable
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
comment|//check POS and length to see if token is matchable
name|matchedPosTag
operator|=
literal|false
expr_stmt|;
comment|//reset to false!
for|for
control|(
name|Value
argument_list|<
name|PosTag
argument_list|>
name|posAnnotation
range|:
name|token
operator|.
name|getAnnotations
argument_list|(
name|POS_ANNOTATION
argument_list|)
control|)
block|{
name|PosTag
name|posTag
init|=
name|posAnnotation
operator|.
name|value
argument_list|()
decl_stmt|;
if|if
condition|(
name|posTag
operator|.
name|isMapped
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|Collections
operator|.
name|disjoint
argument_list|(
name|tpc
operator|.
name|getMatchedLexicalCategories
argument_list|()
argument_list|,
name|posTag
operator|.
name|getCategories
argument_list|()
argument_list|)
condition|)
block|{
if|if
condition|(
name|posAnnotation
operator|.
name|probability
argument_list|()
operator|>=
name|tpc
operator|.
name|getMinPosAnnotationProbability
argument_list|()
condition|)
block|{
comment|//override selectedPosTag if present
name|selectedPosTag
operator|=
name|posTag
expr_stmt|;
comment|//mark the matchable as selected PosTag
name|isMatchable
operator|=
literal|true
expr_stmt|;
name|matchedPosTag
operator|=
literal|true
expr_stmt|;
break|break;
block|}
comment|// else probability to low for inclusion
block|}
elseif|else
if|if
condition|(
name|posAnnotation
operator|.
name|probability
argument_list|()
operator|>=
name|tpc
operator|.
name|getMinExcludePosAnnotationProbability
argument_list|()
condition|)
block|{
if|if
condition|(
name|selectedPosTag
operator|==
literal|null
condition|)
block|{
comment|//do not override existing values
name|selectedPosTag
operator|=
name|posTag
expr_stmt|;
comment|//also rejected PosTags are selected
block|}
name|isMatchable
operator|=
literal|false
expr_stmt|;
name|matchedPosTag
operator|=
literal|true
expr_stmt|;
break|break;
block|}
comment|// else probability to low for exclusion
block|}
comment|//else not matched ... search next one
block|}
if|if
condition|(
operator|!
name|matchedPosTag
condition|)
block|{
comment|//not matched against POS tag ...
comment|//fall back to the token length
name|isMatchable
operator|=
name|token
operator|.
name|getSpan
argument_list|()
operator|.
name|length
argument_list|()
operator|>=
name|elc
operator|.
name|getMinSearchTokenLength
argument_list|()
expr_stmt|;
block|}
block|}
comment|//(3) check for morpho analyses
if|if
condition|(
name|selectedPosTag
operator|==
literal|null
condition|)
block|{
comment|//token is not processable or matchable
comment|//we need to set the selectedPoas tag to the first POS annotation
name|Value
argument_list|<
name|PosTag
argument_list|>
name|posAnnotation
init|=
name|token
operator|.
name|getAnnotation
argument_list|(
name|POS_ANNOTATION
argument_list|)
decl_stmt|;
if|if
condition|(
name|posAnnotation
operator|!=
literal|null
condition|)
block|{
name|selectedPosTag
operator|=
name|posAnnotation
operator|.
name|value
argument_list|()
expr_stmt|;
block|}
block|}
name|List
argument_list|<
name|Value
argument_list|<
name|MorphoFeatures
argument_list|>
argument_list|>
name|morphoAnnotations
init|=
name|token
operator|.
name|getAnnotations
argument_list|(
name|NlpAnnotations
operator|.
name|MORPHO_ANNOTATION
argument_list|)
decl_stmt|;
if|if
condition|(
name|selectedPosTag
operator|==
literal|null
condition|)
block|{
comment|//no POS information ... use the first morpho annotation
name|morpho
operator|=
name|morphoAnnotations
operator|.
name|isEmpty
argument_list|()
condition|?
literal|null
else|:
name|morphoAnnotations
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|value
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|//select the correct morpho annotation based on the POS tag
name|MorphoFeatures
name|mf
init|=
literal|null
decl_stmt|;
name|selectMorphoFeature
label|:
for|for
control|(
name|Value
argument_list|<
name|MorphoFeatures
argument_list|>
name|morphoAnnotation
range|:
name|morphoAnnotations
control|)
block|{
for|for
control|(
name|PosTag
name|posTag
range|:
name|morphoAnnotation
operator|.
name|value
argument_list|()
operator|.
name|getPosList
argument_list|()
control|)
block|{
if|if
condition|(
operator|!
name|disjoint
argument_list|(
name|selectedPosTag
operator|.
name|getCategories
argument_list|()
argument_list|,
name|posTag
operator|.
name|getCategories
argument_list|()
argument_list|)
condition|)
block|{
name|mf
operator|=
name|morphoAnnotation
operator|.
name|value
argument_list|()
expr_stmt|;
break|break
name|selectMorphoFeature
break|;
comment|//stop after finding the first one
block|}
block|}
block|}
name|morpho
operator|=
name|mf
expr_stmt|;
block|}
block|}
comment|/**          * Getter for the text as used for searching/matching          * Entities in the linked vocabulary. If           * {@link EntityLinkerConfig#isLemmaMatching()} is          * enabled this will return the          * {@link MorphoFeatures#getLemma()} (if available).           * Otherwise the {@link Token#getSpan()} is returned          * @return the text of the token as to be used for          * matching. Guaranteed to be NOT NULL.          */
specifier|public
name|String
name|getTokenText
parameter_list|()
block|{
if|if
condition|(
name|elc
operator|.
name|isLemmaMatching
argument_list|()
operator|&&
name|morpho
operator|!=
literal|null
condition|)
block|{
return|return
name|morpho
operator|.
name|getLemma
argument_list|()
return|;
block|}
else|else
block|{
return|return
name|token
operator|.
name|getSpan
argument_list|()
return|;
block|}
block|}
block|}
comment|/**       * Represents a Chunk (group of tokens) used as context for EntityLinking.      * Typically a single {@link ChunkData#chunk} is used, but in case of      * overlapping and {@link ChunkData#isProcessable processable} chunks      * multiple {@link Chunk}s might be merged to a single {@link ChunkData}      * instance. In such cases {@link ChunkData#chunk} represents the      * first and {@link ChunkData#merged} the last of the merged chunks.<p>      * {@link ChunkData#startToken} and {@link ChunkData#endToken} represent      * the covered [start,end) {@link Token} indices relative to the current      * sections (typically a {@link Sentence}). {@link ChunkData#getStartChar()}      * and {@link ChunkData#getEndChar()} are the absolute [start,end) character      * indices within the {@link AnalysedText#getSpan()}      */
class|class
name|ChunkData
block|{
specifier|protected
specifier|final
specifier|static
name|boolean
name|DEFAULT_PROCESSABLE_STATE
init|=
literal|true
decl_stmt|;
comment|/** if the Chunk is processable */
specifier|final
name|boolean
name|isProcessable
decl_stmt|;
comment|/** the Chunk */
specifier|final
name|Chunk
name|chunk
decl_stmt|;
comment|/**           * In case multiple overlapping and processable {@link Chunk}s the          * section selected by the chunks are merged. While {@link #chunk}          * holds the original chunk (the first) this variable holds the          * last merged one. Enclosed chunks (in case more than two are          * merged) are not available via this class, but can be retrieved          * by iterating over the {@link AnalysedText} content part.          */
name|Chunk
name|merged
decl_stmt|;
comment|/** the start token index relative to the current section (sentence) */
name|int
name|startToken
decl_stmt|;
comment|/** the end token index relative to the current section (sentence) */
name|int
name|endToken
decl_stmt|;
comment|/**          * The number of processable Tokens enclosed by this Chunk          */
name|int
name|processableCount
decl_stmt|;
comment|/**          * The number of matchable Tokens enclosed by this Chunk          */
name|int
name|matchableCount
decl_stmt|;
comment|/**          * constructs and initializes the meta data for the parsed {@link Chunk}          * @param chunk          */
name|ChunkData
parameter_list|(
name|Chunk
name|chunk
parameter_list|)
block|{
name|this
operator|.
name|chunk
operator|=
name|chunk
expr_stmt|;
name|Boolean
name|process
init|=
literal|null
decl_stmt|;
for|for
control|(
name|Value
argument_list|<
name|PhraseTag
argument_list|>
name|phraseAnnotation
range|:
name|chunk
operator|.
name|getAnnotations
argument_list|(
name|PHRASE_ANNOTATION
argument_list|)
control|)
block|{
if|if
condition|(
name|tpc
operator|.
name|getProcessedPhraseCategories
argument_list|()
operator|.
name|contains
argument_list|(
name|phraseAnnotation
operator|.
name|value
argument_list|()
operator|.
name|getCategory
argument_list|()
argument_list|)
operator|||
name|tpc
operator|.
name|getProcessedPhraseTags
argument_list|()
operator|.
name|contains
argument_list|(
name|phraseAnnotation
operator|.
name|value
argument_list|()
operator|.
name|getTag
argument_list|()
argument_list|)
condition|)
block|{
if|if
condition|(
name|phraseAnnotation
operator|.
name|probability
argument_list|()
operator|>=
name|tpc
operator|.
name|getMinPhraseAnnotationProbability
argument_list|()
condition|)
block|{
name|process
operator|=
literal|true
expr_stmt|;
break|break;
block|}
comment|// else probability to low for inclusion
block|}
elseif|else
if|if
condition|(
name|phraseAnnotation
operator|.
name|probability
argument_list|()
operator|>=
name|tpc
operator|.
name|getMinExcludePhraseAnnotationProbability
argument_list|()
condition|)
block|{
name|process
operator|=
literal|false
expr_stmt|;
break|break;
block|}
comment|// else probability to low for exclusion
block|}
name|isProcessable
operator|=
name|process
operator|==
literal|null
condition|?
name|DEFAULT_PROCESSABLE_STATE
else|:
name|process
expr_stmt|;
block|}
comment|/**          * Getter for the start character position          * @return the start character position of the selected text span.          */
specifier|public
name|int
name|getStartChar
parameter_list|()
block|{
return|return
name|chunk
operator|.
name|getStart
argument_list|()
return|;
block|}
comment|/**          * Getter for the end character position of the text selected by          * possible multiple {@link #merged} chunks.          * @return the end character position considering possible {@link #merged}          * chunks.          */
specifier|public
name|int
name|getEndChar
parameter_list|()
block|{
return|return
name|merged
operator|==
literal|null
condition|?
name|chunk
operator|.
name|getEnd
argument_list|()
else|:
name|merged
operator|.
name|getEnd
argument_list|()
return|;
block|}
block|}
block|}
end_class

end_unit

